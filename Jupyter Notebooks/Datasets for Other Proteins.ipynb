{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e987f6",
   "metadata": {},
   "source": [
    "# Datasets for Other Proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1562fa",
   "metadata": {},
   "source": [
    "This notebook formats data for the additional protein data used. It is used for part 2 of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9570362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from Bio import SeqIO\n",
    "from io import StringIO\n",
    "import Bio.PDB.Polypeptide\n",
    "import re\n",
    "from scipy.stats import kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "784b8db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import secStrucFormatting as ssf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b3e5253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting jupyter notebook viewing options\n",
    "max_rows = 1000\n",
    "max_cols = 1000\n",
    "pd.set_option(\"display.max_rows\", max_rows, \"display.max_columns\", max_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9259280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "# - orig_df: original dataframe with all mutations and \"positions_split\" column which has mutation positions in split list\n",
    "#            as ints\n",
    "# - sec_st_df: new dataframe with all rows that have mutations in the secondary structure of protein\n",
    "# - mixed_df: new dataframe with all rows that have mutations in both in and out of the secondary stucture of the protein\n",
    "# - start: (inclusive) index where the domain of the protein in PDB file starts\n",
    "# - end: (inclusive) index where the domain of the protein in PDB file ends\n",
    "def get_ss_dataset(orig_df, bool_ss_list, domain_start_index):\n",
    "    \n",
    "    has_sec_str = []\n",
    "    \n",
    "    for val in orig_df[\"positions_split\"]:\n",
    "        # list of boolean values that are true if all mutation positions in line are sec. strc.\n",
    "        all_pos_sec_struc = []\n",
    "        \n",
    "        for position in val:\n",
    "            if (bool_ss_list[position - domain_start_index] == False): # line up ss_indexes w/ position\n",
    "                all_pos_sec_struc.append(False)\n",
    "            else:\n",
    "                all_pos_sec_struc.append(True)\n",
    "        \n",
    "        if (all_pos_sec_struc.count(False) == 0):\n",
    "            has_only_sec_str = True\n",
    "        else:\n",
    "            has_only_sec_str = False\n",
    "        \n",
    "        has_sec_str.append(has_only_sec_str)\n",
    "        all_pos_sec_struc.clear()\n",
    "        \n",
    "    orig_df['has_sec_str'] = has_sec_str\n",
    "    print(orig_df)\n",
    "    condition = orig_df['has_sec_str'] == True\n",
    "    rows = orig_df.loc[condition, :]\n",
    "    \n",
    "    sec_str_df = pd.DataFrame(columns=orig_df.columns)\n",
    "    sec_str_df = sec_str_df.append(rows, ignore_index=True)\n",
    "    sec_str_df = sec_str_df.drop(['has_sec_str'], axis=1)\n",
    "    orig_df = orig_df.drop(['has_sec_str'], axis=1)\n",
    "    \n",
    "    return sec_str_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "348b521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_not_ss_dataset(orig_df, bool_ss_list, domain_start_index):\n",
    "    is_not_sec_str = []\n",
    "    \n",
    "    for val in orig_df[\"positions_split\"]:\n",
    "        \n",
    "        all_pos_sec_struc = []\n",
    "        \n",
    "        for position in val:\n",
    "            # print(position - domain_start_index)\n",
    "            # print(str(position) + \" \" + str(domain_start_index))\n",
    "            if (bool_ss_list[position - domain_start_index] == False):\n",
    "                all_pos_sec_struc.append(False)\n",
    "            else:\n",
    "                all_pos_sec_struc.append(True)\n",
    "    \n",
    "        \n",
    "        if (all_pos_sec_struc.count(True) == 0):\n",
    "            has_no_sec_str = True\n",
    "        else:\n",
    "            has_no_sec_str = False\n",
    "        \n",
    "        is_not_sec_str.append(has_no_sec_str)\n",
    "        all_pos_sec_struc.clear()\n",
    "        \n",
    "    orig_df['is_not_sec_str'] = is_not_sec_str\n",
    "     \n",
    "    condition = orig_df['is_not_sec_str'] == True\n",
    "    rows = orig_df.loc[condition, :]\n",
    "    \n",
    "    not_sec_str_df = pd.DataFrame(columns=orig_df.columns)\n",
    "    not_sec_str_df = not_sec_str_df.append(rows, ignore_index=True)\n",
    "    not_sec_str_df = not_sec_str_df.drop(['is_not_sec_str'], axis=1)\n",
    "    orig_df = orig_df.drop(['is_not_sec_str'], axis=1)\n",
    "    \n",
    "    return not_sec_str_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20238c54",
   "metadata": {},
   "source": [
    "### Metadata from compiled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a37e58cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DATABASE', 'PROTEIN', 'UNIPROT_ID', 'MUTATION', 'SOURCE', 'PBD_WILD',\n",
      "       'PBD_CHAIN_MUTATION', 'pH', 'T_(C)', 'Tm_(C)', 'dTm_(C)',\n",
      "       'dH_(kcal/mol)', 'dG_(kcal/mol)', 'ddG_(kcal/mol)',\n",
      "       'ddG_H2O_(kcal/mol)', 'STATE', 'REVERSIBILITY', 'PUBMED_ID',\n",
      "       'REFERENCE', 'MUTATED_CHAIN', 'KINGDOM', 'PBD_MUTANT', 'MEASURE',\n",
      "       'METHOD', 'POSITION', 'WILD_TYPE_RES', 'MUTATED_RES', 'IS_CURATED',\n",
      "       'CONSERVATION', 'NOTES', 'DATASETS'],\n",
      "      dtype='object')\n",
      "Lysozyme                                                   2897\n",
      "Immunoglobulin G-binding protein G                         1996\n",
      "Thermonuclease                                             1586\n",
      "Staphylococcal nuclease                                    1457\n",
      "Endolysin                                                  1110\n",
      "Ribonuclease                                                983\n",
      "Ribonuclease HI                                             710\n",
      "Guanine nucleotide-binding protein G(i) subunit alpha-1     704\n",
      "Myoglobin                                                   615\n",
      "Dihydrofolate reductase                                     459\n",
      "Name: PROTEIN, dtype: int64\n",
      "       DATABASE   PROTEIN UNIPROT_ID           MUTATION  \\\n",
      "57     Protherm  Lysozyme     P00698          wild-type   \n",
      "97     Protherm  Lysozyme     P00720          wild-type   \n",
      "98     Protherm  Lysozyme     P00720               L46A   \n",
      "99     Protherm  Lysozyme     P00720              L118A   \n",
      "100    Protherm  Lysozyme     P00720              L121A   \n",
      "...         ...       ...        ...                ...   \n",
      "35874  Protherm  Lysozyme     P00720              W138Y   \n",
      "35875  Protherm  Lysozyme     P61626               I77Y   \n",
      "35876  Protherm  Lysozyme     P00720  W138Y W126Y W158Y   \n",
      "35877  Protherm  Lysozyme     P00720  W138Y W126Y W158Y   \n",
      "35878  Protherm  Lysozyme     P00720  W138Y W126Y W158Y   \n",
      "\n",
      "                                           SOURCE PBD_WILD  \\\n",
      "57                        Gallus gallus (Chicken)     4LYZ   \n",
      "97     Enterobacteria phage T4 (Bacteriophage T4)     2LZM   \n",
      "98     Enterobacteria phage T4 (Bacteriophage T4)     2LZM   \n",
      "99     Enterobacteria phage T4 (Bacteriophage T4)     2LZM   \n",
      "100    Enterobacteria phage T4 (Bacteriophage T4)     2LZM   \n",
      "...                                           ...      ...   \n",
      "35874  Enterobacteria phage T4 (Bacteriophage T4)     2LZM   \n",
      "35875                        Homo sapiens (Human)     1LZ1   \n",
      "35876  Enterobacteria phage T4 (Bacteriophage T4)     2LZM   \n",
      "35877  Enterobacteria phage T4 (Bacteriophage T4)     2LZM   \n",
      "35878  Enterobacteria phage T4 (Bacteriophage T4)     2LZM   \n",
      "\n",
      "                           PBD_CHAIN_MUTATION    pH  T_(C)  Tm_(C)  dTm_(C)  \\\n",
      "57                                        NaN  3.80    NaN    74.8      NaN   \n",
      "97                                        NaN  3.01    NaN    51.8      NaN   \n",
      "98                                2lzm_A:L46A  3.01    NaN    43.2     -8.6   \n",
      "99                               2lzm_A:L118A  3.01    NaN    39.6    -12.2   \n",
      "100                              2lzm_A:L121A  3.01    NaN    42.5     -9.3   \n",
      "...                                       ...   ...    ...     ...      ...   \n",
      "35874                            2lzm_A:W138Y  2.20    NaN    36.3     -6.3   \n",
      "35875                             1lz1_A:I59Y  2.70    NaN    64.9      NaN   \n",
      "35876  2lzm_A:W138Y 2lzm_A:W126Y 2lzm_A:W158Y  2.00    NaN    30.0     -7.0   \n",
      "35877  2lzm_A:W138Y 2lzm_A:W126Y 2lzm_A:W158Y  2.20    NaN    36.0     -6.6   \n",
      "35878  2lzm_A:W138Y 2lzm_A:W126Y 2lzm_A:W158Y  2.50    NaN    40.0     -6.2   \n",
      "\n",
      "       dH_(kcal/mol)  dG_(kcal/mol)  ddG_(kcal/mol)  ddG_H2O_(kcal/mol)  \\\n",
      "57               NaN            NaN             NaN                 NaN   \n",
      "97               NaN            NaN             NaN                 NaN   \n",
      "98               NaN            NaN             NaN                 NaN   \n",
      "99               NaN            NaN             NaN                 NaN   \n",
      "100              NaN            NaN             NaN                 NaN   \n",
      "...              ...            ...             ...                 ...   \n",
      "35874            NaN            NaN           -1.71                 NaN   \n",
      "35875            NaN            NaN             NaN                 NaN   \n",
      "35876            NaN            NaN             NaN                 NaN   \n",
      "35877            NaN            NaN           -1.82                 NaN   \n",
      "35878            NaN            NaN           -1.77                 NaN   \n",
      "\n",
      "       STATE REVERSIBILITY   PUBMED_ID  \\\n",
      "57       NaN           yes   1409571.0   \n",
      "97       NaN           yes   1553543.0   \n",
      "98       NaN           yes   1553543.0   \n",
      "99       NaN           yes   1553543.0   \n",
      "100      NaN           yes   1553543.0   \n",
      "...      ...           ...         ...   \n",
      "35874    NaN           yes    911878.0   \n",
      "35875    NaN           yes  10556244.0   \n",
      "35876    NaN       Unknown   7306671.0   \n",
      "35877    NaN           yes    911878.0   \n",
      "35878    NaN           yes    911878.0   \n",
      "\n",
      "                                               REFERENCE MUTATED_CHAIN  \\\n",
      "57                           PROTEINS 14, 237-248 (1992)           NaN   \n",
      "97                           SCIENCE 255, 178-183 (1992)           NaN   \n",
      "98                           SCIENCE 255, 178-183 (1992)             A   \n",
      "99                           SCIENCE 255, 178-183 (1992)             A   \n",
      "100                          SCIENCE 255, 178-183 (1992)             A   \n",
      "...                                                  ...           ...   \n",
      "35874           BIOCHIM BIOPHYS ACTA 494, 367-383 (1977)             A   \n",
      "35875                     PROTEIN ENG 12, 841-850 (1999)             A   \n",
      "35876  BIOPOLYMERS 20, 1989-1999 (1981); doi:10.1002/...         A,A,A   \n",
      "35877           BIOCHIM BIOPHYS ACTA 494, 367-383 (1977)         A,A,A   \n",
      "35878           BIOCHIM BIOPHYS ACTA 494, 367-383 (1977)         A,A,A   \n",
      "\n",
      "      KINGDOM PBD_MUTANT MEASURE METHOD     POSITION WILD_TYPE_RES  \\\n",
      "57        NaN        NaN     NaN    NaN    wild-type     WILD_TYPE   \n",
      "97        NaN        NaN     NaN    NaN    wild-type     WILD_TYPE   \n",
      "98        NaN        NaN     NaN    NaN           46             L   \n",
      "99        NaN        NaN     NaN    NaN          118             L   \n",
      "100       NaN        NaN     NaN    NaN          121             L   \n",
      "...       ...        ...     ...    ...          ...           ...   \n",
      "35874     NaN        NaN     NaN    NaN          138             W   \n",
      "35875     NaN        NaN     NaN    NaN           77             I   \n",
      "35876     NaN        NaN     NaN    NaN  138,126,158         W,W,W   \n",
      "35877     NaN        NaN     NaN    NaN  138,126,158         W,W,W   \n",
      "35878     NaN        NaN     NaN    NaN  138,126,158         W,W,W   \n",
      "\n",
      "      MUTATED_RES IS_CURATED  CONSERVATION NOTES DATASETS  \n",
      "57      WILD-TYPE        NaN           NaN   NaN      NaN  \n",
      "97      WILD-TYPE        NaN           NaN   NaN      NaN  \n",
      "98              A        NaN           NaN   NaN      NaN  \n",
      "99              A        NaN           NaN   NaN      NaN  \n",
      "100             A        NaN           NaN   NaN      NaN  \n",
      "...           ...        ...           ...   ...      ...  \n",
      "35874           Y        NaN           NaN   NaN      NaN  \n",
      "35875           Y        NaN           NaN   NaN      NaN  \n",
      "35876       Y,Y,Y        NaN           NaN   NaN      NaN  \n",
      "35877       Y,Y,Y        NaN           NaN   NaN      NaN  \n",
      "35878       Y,Y,Y        NaN           NaN   NaN      NaN  \n",
      "\n",
      "[2897 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "path = \"../Raw Data/\" + 'all_data_clean.csv'\n",
    "df = pd.read_csv(path)\n",
    "# print(df.head)\n",
    "print(df.columns)\n",
    "\n",
    "print(df[\"PROTEIN\"].value_counts().head(10))\n",
    "print(df.loc[df['PROTEIN'] == 'Lysozyme'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff72bd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P00644    3033\n",
      "P00720    2767\n",
      "P06654    2297\n",
      "P61626    1146\n",
      "P00648     981\n",
      "P00651     904\n",
      "P0A7Y4     722\n",
      "P63096     698\n",
      "P00044     546\n",
      "P00698     491\n",
      "Name: UNIPROT_ID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"UNIPROT_ID\"].value_counts().head(10)) # 4 possible could be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f5250d",
   "metadata": {},
   "source": [
    "#### P00644 (Thermonuclease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31ecebf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1928\\3113518075.py\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# print(nuclease_df)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# print(df.loc[df['UNIPROT_ID'] == 'P00644'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnuclease_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'UNIPROT_ID'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'P00644'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnuclease_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnuclease_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnuclease_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnuclease_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PROTEIN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Thiol:disulfide interchange protein DsbA'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# finding column with most values\n",
    "# print(nuclease_df)\n",
    "# print(df.loc[df['UNIPROT_ID'] == 'P00644'])\n",
    "nuclease_df = df.loc[df['UNIPROT_ID'] == 'P00644']\n",
    "print(nuclease_df.head(50))\n",
    "nuclease_df = nuclease_df.loc[nuclease_df['PROTEIN'].str.contains('Thiol:disulfide interchange protein DsbA') == False]\n",
    "# print(nuclease_df.columns)\n",
    "nuclease_df = nuclease_df[nuclease_df['ddG_(kcal/mol)'].notna()]\n",
    "nuclease_df = nuclease_df[nuclease_df['MUTATION'].str.contains('wild-type') == False]\n",
    "print(nuclease_df['ddG_(kcal/mol)'].tail(40))\n",
    "\n",
    "# rename ddG to score and mutation to variant\n",
    "nuclease_df = nuclease_df.rename(columns={'MUTATION': 'variant', 'ddG_(kcal/mol)': 'score'})\n",
    "print(nuclease_df['score'])\n",
    "nuclease_df['score'] = nuclease_df['score'].round(6)\n",
    "# print(nuclease_df['variant'].head(30))\n",
    "\n",
    "nuclease_df[\"positions_split\"] = ssf.get_positions_split(nuclease_df)\n",
    "\n",
    "positions_split_subtracted = []\n",
    "for pos_list in nuclease_df[\"positions_split\"]:\n",
    "    pos_list = [x - 1 for x in pos_list]\n",
    "    positions_split_subtracted.append(pos_list)  \n",
    "\n",
    "nuclease_df[\"positions_split\"] = positions_split_subtracted    \n",
    "    \n",
    "new_positions = []\n",
    "pos_string = \"\"\n",
    "for pos_list in nuclease_df[\"positions_split\"]:\n",
    "    pos_string = \",\".join(map(str, pos_list))\n",
    "    # print(pos_string)\n",
    "    new_positions.append(pos_string)\n",
    "    pos_string = \"\"\n",
    "# print(len(new_positions))\n",
    "# print(len(nuclease_df[\"POSITION\"]))\n",
    "\n",
    "nuclease_df[\"POSITION\"] = new_positions # changes positions into new adjusted values (0 index)\n",
    "# replace variant column with reformatted variant name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8297d232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10556    -2.6\n",
      "10557     0.8\n",
      "10558    -1.3\n",
      "10559     0.5\n",
      "10560    -2.5\n",
      "         ... \n",
      "29815     7.2\n",
      "29816     7.3\n",
      "29817     9.3\n",
      "29818    11.3\n",
      "37335     0.7\n",
      "Name: score, Length: 1280, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(nuclease_df['score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "90699696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MET LEU VAL MET THR GLU TYR LEU LEU SER ALA GLY ILE CYS MET ALA ILE VAL SER ILE LEU LEU ILE GLY MET ALA ILE SER ASN VAL SER LYS GLY GLN TYR ALA LYS ARG PHE PHE PHE PHE ALA THR SER CYS LEU VAL LEU THR LEU VAL VAL VAL SER SER LEU SER SER SER ALA ASN ALA SER GLN THR ASP ASN GLY VAL ASN ARG SER GLY SER GLU ASP PRO THR VAL TYR SER ALA THR SER THR LYS LYS LEU HIS LYS GLU PRO ALA THR LEU ILE LYS ALA ILE ASP GLY ASP THR VAL LYS LEU MET TYR LYS GLY GLN PRO MET THR PHE ARG LEU LEU LEU VAL ASP THR PRO GLU THR LYS HIS PRO LYS LYS GLY VAL GLU LYS TYR GLY PRO GLU ALA SER ALA PHE THR LYS LYS MET VAL GLU ASN ALA LYS LYS ILE GLU VAL GLU PHE ASP LYS GLY GLN ARG THR ASP LYS TYR GLY ARG GLY LEU ALA TYR ILE TYR ALA ASP GLY LYS MET VAL ASN GLU ALA LEU VAL ARG GLN GLY LEU ALA LYS VAL ALA TYR VAL TYR LYS PRO ASN ASN THR HIS GLU GLN HIS LEU ARG LYS SER GLU ALA GLN ALA LYS LYS GLU LYS LEU ASN ILE TRP SER GLU ASP ASN ALA ASP SER GLY GLN\n"
     ]
    }
   ],
   "source": [
    "# get protein from uniprot\n",
    "protein_seq_nuclease = ssf.get_protein_seq('P00644')\n",
    "print(protein_seq_nuclease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2f002756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TRP', 'SER', 'GLU']\n",
      "231\n"
     ]
    }
   ],
   "source": [
    "protein_seq_nuclease_split = protein_seq_nuclease.split()\n",
    "print(protein_seq_nuclease_split[221:224])\n",
    "print(len(protein_seq_nuclease_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ede989b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclease_df[\"variant\"] = ssf.get_mutations_names_list(nuclease_df)\n",
    "# print(nuclease_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "893b3ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing STRIDE file\n",
    "path = \"../PDB and STRIDE Files/\" + 'thermonuclease_stride.txt'\n",
    "nuclease_stride_file = open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8266ebe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "nuclease_ss_indexes = ssf.get_all_sec_struc_boolean(nuclease_stride_file) # boolean list of secondary structure assignements from uniprot\n",
    "print(nuclease_ss_indexes.count(True))\n",
    "print(nuclease_ss_indexes.count(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7757717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclease_df = add_sec_str_col(nuclease_df, nuclease_ss_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c24772ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepti\\OneDrive\\UW\\GitHub\\secondary-structure-CNN-learning\\Jupyter Notebooks\\secStrucFormatting.py:219: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  in_domain_df = in_domain_df.append(rows, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "nuclease_df = ssf.get_domain_dataset(nuclease_df, 0, 231, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "49642c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n"
     ]
    }
   ],
   "source": [
    "print(len(nuclease_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9f7edb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258\n",
      "1258\n"
     ]
    }
   ],
   "source": [
    "# print(nuclease_df.head(5))\n",
    "print(len(nuclease_df))\n",
    "nuclease_df = nuclease_df[nuclease_df['score'] != 0.0]\n",
    "print(len(nuclease_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c3d2ec5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len1258\n",
      "280\n",
      "173\n",
      "Train Data Fraction: 0.618\n",
      "false_df len379\n",
      "true_df len879\n",
      "in fraction,df len805\n",
      "Test Data Fraction: 0.62\n",
      "false_df len206\n",
      "true_df len599\n",
      "Size of Test Dataset: 539\n",
      "Size of Total Dataset: 992\n",
      "992\n",
      "Filename: nuclease_MLformat_453_train_539_test_t3.txt\n"
     ]
    }
   ],
   "source": [
    "nuclease_train_df, nuclease_test_df, nuclease_remaining_df = get_train_and_test_df(nuclease_df, 0.62, 453)\n",
    "nuclease_df_format = pd.concat([nuclease_train_df, nuclease_test_df])\n",
    "print(len(nuclease_df_format))\n",
    "ssf.write_data_file(\"nuclease_MLformat_453_train_539_test_t3\", protein_seq_nuclease, nuclease_df_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2336d320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "ss = nuclease_ss_indexes.count(True)\n",
    "not_ss = nuclease_ss_indexes.count(False)\n",
    "print(ss)\n",
    "print(not_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e611a9",
   "metadata": {},
   "source": [
    "#### P00720 (Endolysin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2f16337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2767\n",
      "Lysozyme                                     1637\n",
      "Endolysin                                    1101\n",
      "T4 lysozyme                                    20\n",
      "N,O-diacetylmuramidase                          2\n",
      "Beta-galactosidase                              2\n",
      "Invertase 2                                     1\n",
      "Spanin, inner membrane subunit                  1\n",
      "Cytosol aminopeptidase                          1\n",
      "Thermophilic aminopeptidase 1 alpha chain       1\n",
      "Carboxypeptidase Y                              1\n",
      "Name: PROTEIN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "endolysin_df = df.loc[df['UNIPROT_ID'] == 'P00720']\n",
    "# endolysin_df = protein_G_df[\"PROTEIN\"].value_counts()\n",
    "print(len(endolysin_df))\n",
    "endolysin_df.count()\n",
    "print(endolysin_df[\"PROTEIN\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b6314ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lysozyme                    2897\n",
      "Lysozyme C                   449\n",
      "Lysozyme C, milk isozyme      14\n",
      "Name: PROTEIN, dtype: int64\n",
      "57       wild-type\n",
      "97       wild-type\n",
      "98            L46A\n",
      "99           L118A\n",
      "100          L121A\n",
      "101           L99A\n",
      "102          L133A\n",
      "103          F153A\n",
      "104     L99A F153A\n",
      "105      wild-type\n",
      "106           E25Q\n",
      "107           D36N\n",
      "108           D67N\n",
      "109           D85N\n",
      "110          D120N\n",
      "111          D138N\n",
      "112      wild-type\n",
      "113           E25Q\n",
      "114           D36N\n",
      "115           D67N\n",
      "116           D85N\n",
      "117          D120N\n",
      "118          D138N\n",
      "119      wild-type\n",
      "120           E25Q\n",
      "121           D85N\n",
      "122          D120N\n",
      "123          D138N\n",
      "124      wild-type\n",
      "125           E25Q\n",
      "126           D85N\n",
      "127          D120N\n",
      "128          D138N\n",
      "129      wild-type\n",
      "130      wild-type\n",
      "131           G67A\n",
      "132           G85A\n",
      "133           G89A\n",
      "134          G120A\n",
      "135          G135A\n",
      "136      wild-type\n",
      "137           K16E\n",
      "138          R119E\n",
      "139          K135E\n",
      "140          K147E\n",
      "141          R154E\n",
      "142     K16E R119E\n",
      "143     K16E K135E\n",
      "144     K16E R154E\n",
      "145    R119E K135E\n",
      "Name: MUTATION, dtype: object\n"
     ]
    }
   ],
   "source": [
    "lys_df = df.loc[df['PROTEIN'].str.contains('Lysozyme') == True]\n",
    "print(lys_df[\"PROTEIN\"].value_counts())\n",
    "print(lys_df['MUTATION'].head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5415ec85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endolysin    1110\n",
      "Name: PROTEIN, dtype: int64\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "endo_df = df.loc[df['PROTEIN'].str.contains('Endolysin') == True]\n",
    "print(print(endo_df[\"PROTEIN\"].value_counts()))\n",
    "# print(endo_df['MUTATION'].head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e57039c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing STRIDE file\n",
    "path = \"../PDB and STRIDE Files/\" + 'endolysin_stride.txt'\n",
    "endolysin_stride_file = open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37fe348d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MET ASN ILE PHE GLU MET LEU ARG ILE ASP GLU ARG LEU ARG LEU LYS ILE TYR LYS ASP THR GLU GLY TYR TYR THR ILE GLY ILE GLY HIS LEU LEU THR LYS SER PRO SER LEU ASN ALA ALA LYS SER GLU LEU ASP LYS ALA ILE GLY ARG ASN CYS ASN GLY VAL ILE THR LYS ASP GLU ALA GLU LYS LEU PHE ASN GLN ASP VAL ASP ALA ALA VAL ARG GLY ILE LEU ARG ASN ALA LYS LEU LYS PRO VAL TYR ASP SER LEU ASP ALA VAL ARG ARG CYS ALA LEU ILE ASN MET VAL PHE GLN MET GLY GLU THR GLY VAL ALA GLY PHE THR ASN SER LEU ARG MET LEU GLN GLN LYS ARG TRP ASP GLU ALA ALA VAL ASN LEU ALA LYS SER ILE TRP TYR ASN GLN THR PRO ASN ARG ALA LYS ARG VAL ILE THR THR PHE ARG THR GLY THR TRP ASP ALA TYR LYS ASN LEU\n"
     ]
    }
   ],
   "source": [
    "# getting protein string\n",
    "protein_seq_endolysin = ssf.get_protein_seq('P00720')\n",
    "print(protein_seq_endolysin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05d58574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n"
     ]
    }
   ],
   "source": [
    "protein_seq_endolysin_split = protein_seq_endolysin.split()\n",
    "print(len(protein_seq_endolysin_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0dbcab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "endolysin_ss_indexes = ssf.get_sec_struc_boolean(endolysin_stride_file) # boolean list of secondary structure assignements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdaf7b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "ss = endolysin_ss_indexes.count(True)\n",
    "not_ss = endolysin_ss_indexes.count(False)\n",
    "print(ss)\n",
    "print(not_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d3b31c",
   "metadata": {},
   "source": [
    "#### P06654 (Immunoglobulin G-binding protein G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5fb930a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immunoglobulin G-binding protein G    1995\n",
      "Protein G                              285\n",
      "Single Domain Antibody                  17\n",
      "Name: PROTEIN, dtype: int64\n",
      "1221\n"
     ]
    }
   ],
   "source": [
    "protein_G_df = df.loc[df['UNIPROT_ID'] == 'P06654']\n",
    "print(protein_G_df[\"PROTEIN\"].value_counts())\n",
    "protein_G_df = protein_G_df.loc[protein_G_df['PROTEIN'].str.contains('Single Domain Antibody') == False]\n",
    "protein_G_df = protein_G_df[protein_G_df[\"POSITION\"].str.contains(\"pga_A\") == False]\n",
    "\n",
    "protein_G_df = protein_G_df[protein_G_df[\"ddG_(kcal/mol)\"].notna()]\n",
    "print(len(protein_G_df))\n",
    "\n",
    "protein_G_df = protein_G_df.rename(columns={'MUTATION': 'variant', 'ddG_(kcal/mol)': 'score'})\n",
    "protein_G_df['score'] = protein_G_df['score'].round(6)\n",
    "# print(protein_G_df['variant'].head(30))\n",
    "\n",
    "protein_G_df[\"positions_split\"] = ssf.get_positions_split(protein_G_df)\n",
    "\n",
    "positions_split_subtracted = []\n",
    "for pos_list in protein_G_df[\"positions_split\"]:\n",
    "    pos_list = [x - 1 for x in pos_list]\n",
    "    positions_split_subtracted.append(pos_list)  \n",
    "\n",
    "protein_G_df[\"positions_split\"] = positions_split_subtracted    \n",
    "    \n",
    "new_positions = []\n",
    "pos_string = \"\"\n",
    "for pos_list in protein_G_df[\"positions_split\"]:\n",
    "    pos_string = \",\".join(map(str, pos_list))\n",
    "    # print(pos_string)\n",
    "    new_positions.append(pos_string)\n",
    "    pos_string = \"\"\n",
    "# print(len(new_positions))\n",
    "# print(len(protein_G_df[\"POSITION\"]))\n",
    "\n",
    "protein_G_df[\"POSITION\"] = new_positions\n",
    "# print(protein_G_df[\"variant\"].head(10))\n",
    "# print(protein_G_df[\"POSITION\"].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "18da4b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9330            231ARG, 278GLU, 269ALA\n",
      "9331            231ARG, 278ALA, 269ARG\n",
      "9332            231ARG, 278ALA, 269ALA\n",
      "9333                    278GLU, 269ARG\n",
      "9334                    278GLU, 269ALA\n",
      "9335                    278ALA, 269ARG\n",
      "9336                    278ALA, 269ALA\n",
      "9483    241ILE, 243ILE, 250GLU, 254PHE\n",
      "9484    241ILE, 243ILE, 250GLU, 254TYR\n",
      "9485            241ILE, 243ILE, 254TRP\n",
      "Name: variant, dtype: object\n"
     ]
    }
   ],
   "source": [
    "protein_G_df[\"variant\"] = ssf.get_mutations_names_list(protein_G_df)\n",
    "print(protein_G_df[\"variant\"].head(10))\n",
    "protein_G_df = add_sec_str_col(protein_G_df, protein_G_ss_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d5b75dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing STRIDE file\n",
    "path = \"../PDB and STRIDE Files/\" + 'protein_G_stride.txt'\n",
    "protein_G_stride_file = open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fad21383",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_G_ss_indexes = ssf.get_sec_struc_boolean(protein_G_stride_file) # boolean list of secondary structure assignements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fc82b0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MET GLU LYS GLU LYS LYS VAL LYS TYR PHE LEU ARG LYS SER ALA PHE GLY LEU ALA SER VAL SER ALA ALA PHE LEU VAL GLY SER THR VAL PHE ALA VAL ASP SER PRO ILE GLU ASP THR PRO ILE ILE ARG ASN GLY GLY GLU LEU THR ASN LEU LEU GLY ASN SER GLU THR THR LEU ALA LEU ARG ASN GLU GLU SER ALA THR ALA ASP LEU THR ALA ALA ALA VAL ALA ASP THR VAL ALA ALA ALA ALA ALA GLU ASN ALA GLY ALA ALA ALA TRP GLU ALA ALA ALA ALA ALA ASP ALA LEU ALA LYS ALA LYS ALA ASP ALA LEU LYS GLU PHE ASN LYS TYR GLY VAL SER ASP TYR TYR LYS ASN LEU ILE ASN ASN ALA LYS THR VAL GLU GLY ILE LYS ASP LEU GLN ALA GLN VAL VAL GLU SER ALA LYS LYS ALA ARG ILE SER GLU ALA THR ASP GLY LEU SER ASP PHE LEU LYS SER GLN THR PRO ALA GLU ASP THR VAL LYS SER ILE GLU LEU ALA GLU ALA LYS VAL LEU ALA ASN ARG GLU LEU ASP LYS TYR GLY VAL SER ASP TYR HIS LYS ASN LEU ILE ASN ASN ALA LYS THR VAL GLU GLY VAL LYS GLU LEU ILE ASP GLU ILE LEU ALA ALA LEU PRO LYS THR ASP THR TYR LYS LEU ILE LEU ASN GLY LYS THR LEU LYS GLY GLU THR THR THR GLU ALA VAL ASP ALA ALA THR ALA GLU LYS VAL PHE LYS GLN TYR ALA ASN ASP ASN GLY VAL ASP GLY GLU TRP THR TYR ASP ASP ALA THR LYS THR PHE THR VAL THR GLU LYS PRO GLU VAL ILE ASP ALA SER GLU LEU THR PRO ALA VAL THR THR TYR LYS LEU VAL ILE ASN GLY LYS THR LEU LYS GLY GLU THR THR THR LYS ALA VAL ASP ALA GLU THR ALA GLU LYS ALA PHE LYS GLN TYR ALA ASN ASP ASN GLY VAL ASP GLY VAL TRP THR TYR ASP ASP ALA THR LYS THR PHE THR VAL THR GLU MET VAL THR GLU VAL PRO GLY ASP ALA PRO THR GLU PRO GLU LYS PRO GLU ALA SER ILE PRO LEU VAL PRO LEU THR PRO ALA THR PRO ILE ALA LYS ASP ASP ALA LYS LYS ASP ASP THR LYS LYS GLU ASP ALA LYS LYS PRO GLU ALA LYS LYS ASP ASP ALA LYS LYS ALA GLU THR LEU PRO THR THR GLY GLU GLY SER ASN PRO PHE PHE THR ALA ALA ALA LEU ALA VAL MET ALA GLY ALA GLY ALA LEU ALA VAL ALA SER LYS ARG LYS GLU ASP\n"
     ]
    }
   ],
   "source": [
    "protein_seq_protein_G = ssf.get_protein_seq('P06654')\n",
    "print(protein_seq_protein_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3d935970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['THR', 'TYR', 'LYS', 'LEU', 'ILE', 'LEU', 'ASN']\n"
     ]
    }
   ],
   "source": [
    "protein_seq_protein_G_split = protein_seq_protein_G.split()\n",
    "print(protein_seq_protein_G_split[227:234])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1401726e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1221\n"
     ]
    }
   ],
   "source": [
    "print(len(protein_G_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b4dbdd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein_G_train_df, protein_G_test_df, protein_G_remaining_df = get_train_and_test_df(protein_G_df, 0.53, 878)\n",
    "# protein_G_df_format = pd.concat([protein_G_train_df, protein_G_test_df])\n",
    "# print(len(protein_G_df_format))\n",
    "# # ssf.write_data_file(\"protein_G_MLformat_453_train_639_test_t3\", protein_seq_protein_G, protein_G_df_format)\n",
    "\n",
    "# not enough for test and train set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c61ab9",
   "metadata": {},
   "source": [
    "From Gelman et al."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b446883f",
   "metadata": {},
   "source": [
    "**avGFP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af5c9653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing STRIDE file\n",
    "path = \"../PDB and STRIDE Files/\" + 'avgfp_stride.txt'\n",
    "avgfp_stride_file = open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2c8ce2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgfp_ss_indexes = ssf.get_all_sec_struc_boolean(avgfp_stride_file) # boolean list of secondary structure assignements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b6f676d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "ss = avgfp_ss_indexes.count(True)\n",
    "not_ss = avgfp_ss_indexes.count(False)\n",
    "print(ss)\n",
    "print(not_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01b93e2",
   "metadata": {},
   "source": [
    "Formatting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03905bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54024\n",
      "Index(['variant', 'num_mutations', 'score', 'score_wt_norm'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# importing avGFP data from Gelman et al.\n",
    "avgfp_df1 = pd.read_csv(\"../Raw Data/avgfp.tsv.txt\", sep=\"\\t\")\n",
    "avgfp_df = avgfp_df1.dropna()\n",
    "print(len(avgfp_df))\n",
    "print(avgfp_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b9c347f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54024\n",
      "51714\n"
     ]
    }
   ],
   "source": [
    "# rounding score column to 2 decimal points\n",
    "avgfp_df[\"score\"] = avgfp_df[\"score\"].round(6)\n",
    "print(len(avgfp_df))\n",
    "\n",
    "# remove values with wildcard star thing cause idk what it means\n",
    "avgfp_df = avgfp_df[avgfp_df[\"variant\"].str.contains(\"\\*\") == False]\n",
    "\n",
    "# pab1_df = pab1_df.head(37600)\n",
    "# avgfp_df = avgfp_df.sample(n=160)\n",
    "print(len(avgfp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d177943f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237\n",
      "SER LYS GLY GLU GLU LEU PHE THR GLY VAL VAL PRO ILE LEU VAL GLU LEU ASP GLY ASP VAL ASN GLY HIS LYS PHE SER VAL SER GLY GLU GLY GLU GLY ASP ALA THR TYR GLY LYS LEU THR LEU LYS PHE ILE CYS THR THR GLY LYS LEU PRO VAL PRO TRP PRO THR LEU VAL THR THR LEU SER TYR GLY VAL GLN CYS PHE SER ARG TYR PRO ASP HIS MET LYS GLN HIS ASP PHE PHE LYS SER ALA MET PRO GLU GLY TYR VAL GLN GLU ARG THR ILE PHE PHE LYS ASP ASP GLY ASN TYR LYS THR ARG ALA GLU VAL LYS PHE GLU GLY ASP THR LEU VAL ASN ARG ILE GLU LEU LYS GLY ILE ASP PHE LYS GLU ASP GLY ASN ILE LEU GLY HIS LYS LEU GLU TYR ASN TYR ASN SER HIS ASN VAL TYR ILE MET ALA ASP LYS GLN LYS ASN GLY ILE LYS VAL ASN PHE LYS ILE ARG HIS ASN ILE GLU ASP GLY SER VAL GLN LEU ALA ASP HIS TYR GLN GLN ASN THR PRO ILE GLY ASP GLY PRO VAL LEU LEU PRO ASP ASN HIS TYR LEU SER THR GLN SER ALA LEU SER LYS ASP PRO ASN GLU LYS ARG ASP HIS MET VAL LEU LEU GLU PHE VAL THR ALA ALA GLY ILE THR HIS GLY MET ASP GLU LEU TYR LYS\n"
     ]
    }
   ],
   "source": [
    "# getting dataset size to run\n",
    "\n",
    "string_seq = \"SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK\"\n",
    "print(len(string_seq)) \n",
    "protein_seq_avgfp = ssf.get_expanded_seq(string_seq)\n",
    "print(protein_seq_avgfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "529a3aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237\n",
      "THR\n"
     ]
    }
   ],
   "source": [
    "protein_seq_avgfp_split = protein_seq_avgfp.split()\n",
    "print(len(protein_seq_avgfp_split))\n",
    "print(protein_seq_avgfp_split[60])\n",
    "\n",
    "# 165VAL -> ILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d70812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting variant list if there are multiple mutations\n",
    "avgfp_mut = avgfp_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "avgfp_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(avgfp_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "avgfp_df[\"MUTATED_RES\"] = ssf.get_mutation_type(avgfp_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "avgfp_df[\"POSITION\"] = ssf.get_position(avgfp_mut)\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "avgfp_df[\"variant\"] = ssf.get_mutations_names_list(avgfp_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]\n",
    "\n",
    "# avgfp_df = avgfp_df.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c44ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# need positionssplit\n",
    "avgfp_df[\"positions_split\"] = ssf.get_positions_split(avgfp_df)\n",
    "\n",
    "# add in_sec_str_col\n",
    "avgfp_df = add_sec_str_col(avgfp_df, avgfp_ss_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf7ff9c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'avgfp_test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8676\\4129410156.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mavgfp_train_df_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavgfp_test_df_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavgfp_remaining_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_train_and_test_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavgfp_test_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m465\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mavgfp_df_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mavgfp_train_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavgfp_test_df_2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavgfp_df_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# ssf.write_data_file(\"avgfp_MLformat_465_train_19458_test_t3\", protein_seq_avgfp, avgfp_df_format)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'avgfp_test_df' is not defined"
     ]
    }
   ],
   "source": [
    "avgfp_train_df, avgfp_test_df, avgfp_remaining_df = get_train_and_test_df(avgfp_test_df, 0.88, 465)\n",
    "avgfp_df_format = pd.concat([avgfp_train_df, avgfp_test_df_2])\n",
    "print(len(avgfp_df_format))\n",
    "# ssf.write_data_file(\"avgfp_MLformat_465_train_19458_test_t3\", protein_seq_avgfp, avgfp_df_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb2522f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len51714\n",
      "409\n",
      "56\n",
      "Train Data Fraction: 0.88\n",
      "false_df len20361\n",
      "true_df len31353\n",
      "in fraction,df len51249\n",
      "Test Data Fraction: 0.88\n",
      "false_df len20305\n",
      "true_df len30944\n",
      "Size of Test Dataset: 35158\n",
      "Size of Total Dataset: 35623\n",
      "in fraction,df len35158\n",
      "17600\n",
      "2400\n",
      "Train Data Fraction: 0.88\n",
      "false_df len4219\n",
      "true_df len30939\n",
      "in fraction,df len15158\n",
      "Test Data Fraction: 0.88\n",
      "false_df len1819\n",
      "true_df len13339\n",
      "Size of Test Dataset: 15150\n",
      "Size of Total Dataset: 35150\n",
      "SMALL TEST\n",
      "15150\n",
      "15615\n",
      "Filename: avgfp_MLformat_465_train_15150_test_t3.txt\n"
     ]
    }
   ],
   "source": [
    "avgfp_train_df, avgfp_test_df, avgfp_remaining_df = get_train_and_test_df(avgfp_df, 0.88, 465)\n",
    "avgfp_train_dummy, avgfp_small_test_df, avgfp_remaining_df = get_train_and_test_df(avgfp_test_df, 0.88, 20000)\n",
    "print(\"SMALL TEST\")\n",
    "print(len(avgfp_small_test_df))\n",
    "avgfp_df_format = pd.concat([avgfp_train_df, avgfp_small_test_df])\n",
    "print(len(avgfp_df_format))\n",
    "ssf.write_data_file(\"avgfp_MLformat_465_train_15150_test_t3\", protein_seq_avgfp, avgfp_df_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c8dc698b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len51714\n",
      "297\n",
      "168\n",
      "Train Data Fraction: 0.639\n",
      "false_df len38961\n",
      "true_df len12753\n",
      "in fraction,df len51249\n",
      "Test Data Fraction: 0.64\n",
      "false_df len38793\n",
      "true_df len12456\n",
      "Size of Test Dataset: 19458\n",
      "Size of Total Dataset: 19923\n",
      "19923\n",
      "Filename: avgfp_MLformat_982_train_19458_test_t2.txt\n"
     ]
    }
   ],
   "source": [
    "avgfp_train_df_2, avgfp_test_df_2, avgfp_remaining_df_2 = get_train_and_test_df(avgfp_df, 0.64, 465)\n",
    "avgfp_df_format_2 = pd.concat([avgfp_train_df_2, avgfp_test_df_2])\n",
    "print(len(avgfp_df_format_2))\n",
    "ssf.write_data_file(\"avgfp_MLformat_465_train_19458_test_t2\", protein_seq_avgfp, avgfp_df_format_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1938c550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len51714\n",
      "297\n",
      "168\n",
      "Train Data Fraction: 0.639\n",
      "false_df len38961\n",
      "true_df len12753\n",
      "in fraction,df len51249\n",
      "Test Data Fraction: 0.64\n",
      "false_df len38793\n",
      "true_df len12456\n",
      "Size of Test Dataset: 19458\n",
      "Size of Total Dataset: 19923\n",
      "19923\n",
      "Filename: avgfp_MLformat_982_train_19458_test_t3.txt\n"
     ]
    }
   ],
   "source": [
    "avgfp_train_df_3, avgfp_test_df_3, avgfp_remaining_df_3 = get_train_and_test_df(avgfp_df, 0.64, 465)\n",
    "avgfp_df_format_3 = pd.concat([avgfp_train_df_3, avgfp_test_df_3])\n",
    "print(len(avgfp_df_format_3))\n",
    "ssf.write_data_file(\"avgfp_MLformat_465_train_19458_test_t3\", protein_seq_avgfp, avgfp_df_format_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "77675cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465\n",
      "19458\n",
      "465\n",
      "19458\n",
      "465\n",
      "19458\n"
     ]
    }
   ],
   "source": [
    "print(len(avgfp_train_df))\n",
    "print(len(avgfp_test_df))\n",
    "print(len(avgfp_train_df_2))\n",
    "print(len(avgfp_test_df_2))\n",
    "print(len(avgfp_train_df_3))\n",
    "print(len(avgfp_test_df_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4d480a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len51714\n",
      "297\n",
      "168\n",
      "Train Data Fraction: 0.639\n",
      "false_df len38961\n",
      "true_df len12753\n",
      "in fraction,df len51249\n",
      "Test Data Fraction: 0.64\n",
      "false_df len38793\n",
      "true_df len12456\n",
      "Size of Test Dataset: 19458\n",
      "Size of Total Dataset: 19923\n"
     ]
    }
   ],
   "source": [
    "# avgfp_train_df, avgfp_new_test_df, avgfp_new_remaining_df = get_train_and_test_df(avgfp_test_df, 0.64, 465)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b2979e",
   "metadata": {},
   "source": [
    "# Adding Noise to avgfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af8c1a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51714\n"
     ]
    }
   ],
   "source": [
    "# importing and formatting data (25737 usable vals)\n",
    "avgfp_df1 = pd.read_csv(\"../Raw Data/avgfp.tsv.txt\", sep=\"\\t\")\n",
    "avgfp_df = avgfp_df1.dropna()\n",
    "\n",
    "# rounding score column to 6 decimal points\n",
    "avgfp_df[\"score\"] = avgfp_df[\"score\"].round(6)\n",
    "\n",
    "# remove values with wildcard star next to them\n",
    "avgfp_df = avgfp_df[avgfp_df[\"variant\"].str.contains(\"\\*\") == False]\n",
    "\n",
    "# splitting variant list if there are multiple mutations\n",
    "avgfp_mut = avgfp_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "avgfp_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(avgfp_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "avgfp_df[\"MUTATED_RES\"] = ssf.get_mutation_type(avgfp_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "avgfp_df[\"POSITION\"] = ssf.get_position(avgfp_mut)\n",
    "\n",
    "avgfp_df[\"positions_split\"] = ssf.get_positions_split(avgfp_df)\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "avgfp_df[\"variant\"] = ssf.get_mutations_names_list(avgfp_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]\n",
    "\n",
    "print(len(avgfp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8dcf0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# secondary structure assignments\n",
    "path = \"../PDB and STRIDE Files/\" + 'avgfp_stride.txt'\n",
    "avgfp_stride_file = open(path, 'r')\n",
    "\n",
    "avgfp_ss_indexes = ssf.get_sec_struc_boolean(avgfp_stride_file) # not including turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f475671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need positionssplit\n",
    "avgfp_df[\"positions_split\"] = ssf.get_positions_split(avgfp_df)\n",
    "\n",
    "# avgfp_only_ss_df = get_ss_dataset(avgfp_df, avgfp_ss_indexes, 0)\n",
    "# avgfp_only_not_ss_df = get_not_ss_dataset(avgfp_df, avgfp_ss_indexes, 0)\n",
    "# avgfp_no_mixed_pos_df = pd.concat([avgfp_only_ss_df, avgfp_only_not_ss_df])\n",
    "\n",
    "# # add in_sec_str_col\n",
    "avgfp_no_mixed_pos_df = avgfp_df\n",
    "avgfp_no_mixed_pos_df = add_sec_str_col(avgfp_no_mixed_pos_df, avgfp_ss_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdbc00c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51714\n",
      "51714\n"
     ]
    }
   ],
   "source": [
    "print(len(avgfp_df))\n",
    "print(len(avgfp_no_mixed_pos_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac62b806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling data\n",
    "avgfp_no_mixed_pos_df = avgfp_no_mixed_pos_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e1cf15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein sequence\n",
    "string_seq = \"SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK\"\n",
    "protein_seq_avgfp = ssf.get_expanded_seq(string_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb9d8b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    9\n",
      "True     4\n",
      "Name: in_sec_str, dtype: int64\n",
      "False    7804\n",
      "True     2538\n",
      "Name: in_sec_str, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# getting training set (5k in ss, 5k not in ss)\n",
    "# avgfp_train_ss = avgfp_no_mixed_pos_df[avgfp_no_mixed_pos_df['in_sec_str'] == True].sample(72)\n",
    "# avgfp_train_not_ss = avgfp_no_mixed_pos_df[avgfp_no_mixed_pos_df['in_sec_str'] == False].sample(72)\n",
    "# avgfp_train_df = pd.concat([avgfp_train_ss, avgfp_train_not_ss])\n",
    "avgfp_train_df = avgfp_no_mixed_pos_df.sample(13)\n",
    "\n",
    "# avgfp_test_ss = avgfp_no_mixed_pos_df[avgfp_no_mixed_pos_df['in_sec_str'] == True].sample(15)\n",
    "# avgfp_test_not_ss = avgfp_no_mixed_pos_df[avgfp_no_mixed_pos_df['in_sec_str'] == False].sample(15)\n",
    "# avgfp_test_df = pd.concat([avgfp_test_ss, avgfp_test_not_ss])\n",
    "\n",
    "avgfp_test_df = avgfp_no_mixed_pos_df.sample(10342)\n",
    "\n",
    "# getting test set (2.5k in ss, 2.5k not in ss)\n",
    "print(avgfp_train_df['in_sec_str'].value_counts())\n",
    "print(avgfp_test_df['in_sec_str'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f2e644c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # getting dataset with correct ratios (only using training dataset)\n",
    "# avgfp_train_df, avgfp_test_df_1, avgfp_remaining_df = get_train_and_test_df(avgfp_no_mixed_pos_df, 0.64, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "eed6b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgfp_test_df, avgfp_dummy, avgfp_remaining_df_1 = get_train_and_test_df(avgfp_test_df_1, 0.64, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84f66bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Standard Deviation: 0.9429280004661352\n",
      "Dataset Mean: 3.0688599236111114\n",
      "Dataset Median: 3.560065\n",
      "Kurtosis: 2.39464715467682\n",
      "4375     1.465188\n",
      "2349     3.695193\n",
      "7441     1.780285\n",
      "5749     3.619612\n",
      "6935     3.569778\n",
      "4015     1.309358\n",
      "10840    3.695479\n",
      "10167    3.378846\n",
      "10095    1.603491\n",
      "6864     1.603909\n",
      "Name: score, dtype: float64\n",
      "4375      3.677788\n",
      "2349      2.020927\n",
      "7441      5.547270\n",
      "5749     -1.583931\n",
      "6935     15.979786\n",
      "4015      0.771712\n",
      "10840    -6.062932\n",
      "10167     4.477339\n",
      "10095     6.521446\n",
      "6864     -1.195851\n",
      "Name: score, dtype: float64\n",
      "4375     1.465188\n",
      "2349     3.695193\n",
      "7441     1.780285\n",
      "5749     3.619612\n",
      "6935     3.569778\n",
      "4015     1.309358\n",
      "10840    3.695479\n",
      "10167    3.378846\n",
      "10095    1.603491\n",
      "6864     1.603909\n",
      "Name: score, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_10732\\1354598650.py:36: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(unchanged_scores[0:10])\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_10732\\1354598650.py:38: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(ss_scores[0:10])\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_10732\\1354598650.py:40: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(not_ss_scores[0:10])\n"
     ]
    }
   ],
   "source": [
    "# adding noise to values from uniform distribution and creating files\n",
    "\n",
    "# finding standard deviation of dataset scores\n",
    "std = avgfp_train_df['score'].std()\n",
    "mean = avgfp_train_df['score'].mean()\n",
    "median = avgfp_train_df['score'].median()\n",
    "print(\"Dataset Standard Deviation: \" + str(std))\n",
    "print(\"Dataset Mean: \" + str(mean))\n",
    "print(\"Dataset Median: \" + str(median))\n",
    "print(\"Kurtosis: \" + str(kurtosis(avgfp_train_df['score'], fisher=False)))\n",
    "\n",
    "# finding number of ss and not ss values\n",
    "num_ss_vals = (avgfp_train_df.in_sec_str == True).sum()\n",
    "num_not_ss_vals = (avgfp_train_df.in_sec_str == False).sum()\n",
    "\n",
    "# creating noise (std not the exact same, but similar) // 0 is the mean of the normal distribution\n",
    "noise_ss = np.random.normal(0, std * 6.0, num_ss_vals).tolist()\n",
    "noise_ss_v2 = noise_ss.copy()\n",
    "noise_not_ss = np.random.normal(0, std * 6.0, num_not_ss_vals).tolist()\n",
    "\n",
    "# filling in values for not ss indexes in noise_ss\n",
    "bool_ss_list = avgfp_train_df.in_sec_str.values.tolist()\n",
    "\n",
    "noise_ss_to_add = []\n",
    "noise_not_ss_to_add = []\n",
    "\n",
    "for ss_assign in bool_ss_list:\n",
    "    if ss_assign: # if true (ss index)\n",
    "        noise_ss_to_add.append(noise_ss.pop(0))\n",
    "        noise_not_ss_to_add.append(0)\n",
    "    else: # if false (not ss index)\n",
    "        noise_ss_to_add.append(0)\n",
    "        noise_not_ss_to_add.append(noise_not_ss.pop(0))\n",
    "        \n",
    "unchanged_scores = avgfp_train_df['score']\n",
    "print(unchanged_scores[0:10])\n",
    "ss_scores = avgfp_train_df['score'] + noise_ss_to_add\n",
    "print(ss_scores[0:10])\n",
    "not_ss_scores = avgfp_train_df['score'] + noise_not_ss_to_add\n",
    "print(not_ss_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aea8093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0688599236111105\n",
      "\n",
      "4.4731570331181825\n",
      "Percentage Change: 45.75957014859914\n",
      "3.8219012755040547\n",
      "Percentage Change: 24.538146759297003\n"
     ]
    }
   ],
   "source": [
    "abs_val_list = [abs(x) for x in avgfp_train_df['score']]\n",
    "mean = sum(abs_val_list) / len(abs_val_list)\n",
    "print(mean)\n",
    "print()\n",
    "\n",
    "abs_ss_val_list = [abs(x) for x in ss_scores]\n",
    "mean_ss = sum(abs_ss_val_list) / len(abs_ss_val_list)\n",
    "print(mean_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_ss - mean) / mean) * 100))\n",
    "\n",
    "abs_not_ss_val_list = [abs(x) for x in not_ss_scores]\n",
    "mean_not_ss = sum(abs_not_ss_val_list) / len(abs_not_ss_val_list)\n",
    "print(mean_not_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_not_ss - mean) / mean) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "783074eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.351688913762123\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGhCAYAAABLWk8IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApFUlEQVR4nO3df3SU5Z3//9c0P4YkJtP8gBnmNEC6TX9ogmJwI+lq0uYHywGii0ewuG48UheKYEeSRVJsSV1JIB4TdpstHFwOIBwa/9jG7S7YEro2laVuYwpnIXqsrpGEkjGrppME44SG+/OHX+/vDgnihMBcCc/HOdcfc93vmXnft2PmxTX33OOwLMsSAACAQT4X6QYAAAAuRkABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYJK6D86U9/0hNPPKGMjAzFxcXpi1/8op588klduHDBrrEsS1VVVfJ6vYqLi1NBQYHa29tDHicYDGrt2rVKS0tTQkKCSktLdebMmfHZIwAAMOGFFVC2bt2qHTt2qKGhQa+//rpqa2v19NNP60c/+pFdU1tbq7q6OjU0NKi1tVUej0fFxcXq7++3a3w+n5qamtTY2KijR49qYGBAixYt0vDw8PjtGQAAmLAc4fxY4KJFi+R2u7Vr1y577p577lF8fLz27dsny7Lk9Xrl8/n0+OOPS/p4tcTtdmvr1q1auXKlAoGApk6dqn379mnZsmWSpLNnzyo9PV2HDh3S/PnzL9vHhQsXdPbsWSUmJsrhcIS7zwAAIAIsy1J/f7+8Xq8+97nLrJFYYaipqbFmzpxpvfHGG5ZlWdaJEyesadOmWQcOHLAsy7L+53/+x5Jk/e53vwu5X2lpqfU3f/M3lmVZ1i9/+UtLkvXBBx+E1MyePdv6wQ9+MOrzfvTRR1YgELDHa6+9ZkliMBgMBoMxAUdXV9dlM0e0wvD4448rEAjoq1/9qqKiojQ8PKzNmzfrW9/6liTJ7/dLktxud8j93G63Tp8+bdfExsYqOTl5RM0n979YTU2NfvjDH46Y7+rqUlJSUji7AAAAIqSvr0/p6elKTEy8bG1YAeX555/X/v37deDAAd100006ceKEfD6fvF6vysrK7LqLP3axLOuyH8V8Wk1lZaXWrVtn3/5kB5OSkggoAABMMJ/l9IywAsrf/d3facOGDbrvvvskSdnZ2Tp9+rRqampUVlYmj8cj6eNVkunTp9v36+npsVdVPB6PhoaG1NvbG7KK0tPTo7y8vFGf1+l0yul0htMqAACYwML6Fs+HH3444qSWqKgo+2vGGRkZ8ng8am5utrcPDQ2ppaXFDh85OTmKiYkJqenu7tapU6cuGVAAAMD1JawVlMWLF2vz5s2aMWOGbrrpJh0/flx1dXV66KGHJH28ZOPz+VRdXa3MzExlZmaqurpa8fHxWr58uSTJ5XJpxYoVKi8vV2pqqlJSUlRRUaHs7GwVFRWN/x4CAIAJJ6yA8qMf/Ujf//73tXr1avX09Mjr9WrlypX6wQ9+YNesX79eg4ODWr16tXp7e5Wbm6vDhw+HnBBTX1+v6OhoLV26VIODgyosLNSePXsUFRU1fnsGAAAmrLCug2KKvr4+uVwuBQIBTpIFAGCCCOf9m9/iAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGCetS9wBwLczacDDSLYTtnS0LI90CMKmwggIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIwTVkCZNWuWHA7HiPHII49IkizLUlVVlbxer+Li4lRQUKD29vaQxwgGg1q7dq3S0tKUkJCg0tJSnTlzZvz2CAAATHhhBZTW1lZ1d3fbo7m5WZJ07733SpJqa2tVV1enhoYGtba2yuPxqLi4WP39/fZj+Hw+NTU1qbGxUUePHtXAwIAWLVqk4eHhcdwtAAAwkYUVUKZOnSqPx2OPf//3f9ef/dmfKT8/X5Zladu2bdq4caOWLFmirKws7d27Vx9++KEOHDggSQoEAtq1a5eeeeYZFRUVac6cOdq/f79OnjypI0eOXJUdBAAAE8+Yz0EZGhrS/v379dBDD8nhcKijo0N+v18lJSV2jdPpVH5+vo4dOyZJamtr0/nz50NqvF6vsrKy7JrRBINB9fX1hQwAADB5jTmgvPDCC/rjH/+oBx98UJLk9/slSW63O6TO7Xbb2/x+v2JjY5WcnHzJmtHU1NTI5XLZIz09faxtAwCACWDMAWXXrl1asGCBvF5vyLzD4Qi5bVnWiLmLXa6msrJSgUDAHl1dXWNtGwAATABjCiinT5/WkSNH9O1vf9ue83g8kjRiJaSnp8deVfF4PBoaGlJvb+8la0bjdDqVlJQUMgAAwOQ1poCye/duTZs2TQsXLrTnMjIy5PF47G/2SB+fp9LS0qK8vDxJUk5OjmJiYkJquru7derUKbsGAAAgOtw7XLhwQbt371ZZWZmio///uzscDvl8PlVXVyszM1OZmZmqrq5WfHy8li9fLklyuVxasWKFysvLlZqaqpSUFFVUVCg7O1tFRUXjt1cAAGBCCzugHDlyRJ2dnXrooYdGbFu/fr0GBwe1evVq9fb2Kjc3V4cPH1ZiYqJdU19fr+joaC1dulSDg4MqLCzUnj17FBUVdWV7AgAAJg2HZVlWpJsIV19fn1wulwKBAOejAJPQrA0HI91C2N7ZsvDyRcB1Lpz3b36LBwAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGCTug/OEPf9Bf//VfKzU1VfHx8brlllvU1tZmb7csS1VVVfJ6vYqLi1NBQYHa29tDHiMYDGrt2rVKS0tTQkKCSktLdebMmSvfGwAAMCmEFVB6e3v19a9/XTExMXrxxRf12muv6ZlnntHnP/95u6a2tlZ1dXVqaGhQa2urPB6PiouL1d/fb9f4fD41NTWpsbFRR48e1cDAgBYtWqTh4eFx2zEAADBxOSzLsj5r8YYNG/Sf//mfevnll0fdblmWvF6vfD6fHn/8cUkfr5a43W5t3bpVK1euVCAQ0NSpU7Vv3z4tW7ZMknT27Fmlp6fr0KFDmj9//mX76Ovrk8vlUiAQUFJS0mdtH8AEMWvDwUi3ELZ3tiyMdAuA8cJ5/w5rBeVnP/uZ5s6dq3vvvVfTpk3TnDlz9Oyzz9rbOzo65Pf7VVJSYs85nU7l5+fr2LFjkqS2tjadP38+pMbr9SorK8uuuVgwGFRfX1/IAAAAk1dYAeXtt9/W9u3blZmZqV/84hdatWqVHn30UT333HOSJL/fL0lyu90h93O73fY2v9+v2NhYJScnX7LmYjU1NXK5XPZIT08Pp20AADDBhBVQLly4oFtvvVXV1dWaM2eOVq5cqYcffljbt28PqXM4HCG3LcsaMXexT6uprKxUIBCwR1dXVzhtAwCACSasgDJ9+nTdeOONIXNf+9rX1NnZKUnyeDySNGIlpKenx15V8Xg8GhoaUm9v7yVrLuZ0OpWUlBQyAADA5BVWQPn617+uN954I2Tu97//vWbOnClJysjIkMfjUXNzs719aGhILS0tysvLkyTl5OQoJiYmpKa7u1unTp2yawAAwPUtOpzixx57THl5eaqurtbSpUv129/+Vjt37tTOnTslffzRjs/nU3V1tTIzM5WZmanq6mrFx8dr+fLlkiSXy6UVK1aovLxcqampSklJUUVFhbKzs1VUVDT+ewgAACacsALKbbfdpqamJlVWVurJJ59URkaGtm3bpvvvv9+uWb9+vQYHB7V69Wr19vYqNzdXhw8fVmJiol1TX1+v6OhoLV26VIODgyosLNSePXsUFRU1fnsGAAAmrLCug2IKroMCTG5cBwWYnMJ5/w5rBQUAMLqJGKokghXMxY8FAgAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxwgooVVVVcjgcIcPj8djbLctSVVWVvF6v4uLiVFBQoPb29pDHCAaDWrt2rdLS0pSQkKDS0lKdOXNmfPYGAABMCmGvoNx0003q7u62x8mTJ+1ttbW1qqurU0NDg1pbW+XxeFRcXKz+/n67xufzqampSY2NjTp69KgGBga0aNEiDQ8Pj88eAQCACS867DtER4esmnzCsixt27ZNGzdu1JIlSyRJe/fuldvt1oEDB7Ry5UoFAgHt2rVL+/btU1FRkSRp//79Sk9P15EjRzR//vwr3B0AADAZhL2C8uabb8rr9SojI0P33Xef3n77bUlSR0eH/H6/SkpK7Fqn06n8/HwdO3ZMktTW1qbz58+H1Hi9XmVlZdk1owkGg+rr6wsZAABg8goroOTm5uq5557TL37xCz377LPy+/3Ky8vT+++/L7/fL0lyu90h93G73fY2v9+v2NhYJScnX7JmNDU1NXK5XPZIT08Pp20AADDBhBVQFixYoHvuuUfZ2dkqKirSwYMHJX38Uc4nHA5HyH0syxoxd7HL1VRWVioQCNijq6srnLYBAMAEE/Y5KP9XQkKCsrOz9eabb+ruu++W9PEqyfTp0+2anp4ee1XF4/FoaGhIvb29IasoPT09ysvLu+TzOJ1OOZ3OK2kVuG7N2nAw0i0AQNiu6DoowWBQr7/+uqZPn66MjAx5PB41Nzfb24eGhtTS0mKHj5ycHMXExITUdHd369SpU58aUAAAwPUlrBWUiooKLV68WDNmzFBPT4+eeuop9fX1qaysTA6HQz6fT9XV1crMzFRmZqaqq6sVHx+v5cuXS5JcLpdWrFih8vJypaamKiUlRRUVFfZHRgAAAFKYAeXMmTP61re+pffee09Tp07V7bffrldeeUUzZ86UJK1fv16Dg4NavXq1ent7lZubq8OHDysxMdF+jPr6ekVHR2vp0qUaHBxUYWGh9uzZo6ioqPHdMwAAMGE5LMuyIt1EuPr6+uRyuRQIBJSUlBTpdgCjcQ4KPs07WxZGugVcR8J5/+a3eAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgnCsKKDU1NXI4HPL5fPacZVmqqqqS1+tVXFycCgoK1N7eHnK/YDCotWvXKi0tTQkJCSotLdWZM2eupBUAADCJjDmgtLa2aufOnZo9e3bIfG1trerq6tTQ0KDW1lZ5PB4VFxerv7/frvH5fGpqalJjY6OOHj2qgYEBLVq0SMPDw2PfEwAAMGmMKaAMDAzo/vvv17PPPqvk5GR73rIsbdu2TRs3btSSJUuUlZWlvXv36sMPP9SBAwckSYFAQLt27dIzzzyjoqIizZkzR/v379fJkyd15MiR8dkrAAAwoY0poDzyyCNauHChioqKQuY7Ojrk9/tVUlJizzmdTuXn5+vYsWOSpLa2Np0/fz6kxuv1Kisry665WDAYVF9fX8gAAACTV3S4d2hsbNTvfvc7tba2jtjm9/slSW63O2Te7Xbr9OnTdk1sbGzIyssnNZ/c/2I1NTX64Q9/GG6rAABgggprBaWrq0vf/e53tX//fk2ZMuWSdQ6HI+S2ZVkj5i72aTWVlZUKBAL26OrqCqdtAAAwwYQVUNra2tTT06OcnBxFR0crOjpaLS0t+sd//EdFR0fbKycXr4T09PTY2zwej4aGhtTb23vJmos5nU4lJSWFDAAAMHmFFVAKCwt18uRJnThxwh5z587V/fffrxMnTuiLX/yiPB6Pmpub7fsMDQ2ppaVFeXl5kqScnBzFxMSE1HR3d+vUqVN2DQAAuL6FdQ5KYmKisrKyQuYSEhKUmppqz/t8PlVXVyszM1OZmZmqrq5WfHy8li9fLklyuVxasWKFysvLlZqaqpSUFFVUVCg7O3vESbcAAOD6FPZJspezfv16DQ4OavXq1ert7VVubq4OHz6sxMREu6a+vl7R0dFaunSpBgcHVVhYqD179igqKmq82wEAABOQw7IsK9JNhKuvr08ul0uBQIDzUYDLmLXhYKRbgMHe2bIw0i3gOhLO+ze/xQMAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA44QVULZv367Zs2crKSlJSUlJmjdvnl588UV7u2VZqqqqktfrVVxcnAoKCtTe3h7yGMFgUGvXrlVaWpoSEhJUWlqqM2fOjM/eAACASSGsgPKFL3xBW7Zs0auvvqpXX31V3/zmN3XXXXfZIaS2tlZ1dXVqaGhQa2urPB6PiouL1d/fbz+Gz+dTU1OTGhsbdfToUQ0MDGjRokUaHh4e3z0DAAATlsOyLOtKHiAlJUVPP/20HnroIXm9Xvl8Pj3++OOSPl4tcbvd2rp1q1auXKlAIKCpU6dq3759WrZsmSTp7NmzSk9P16FDhzR//vzP9Jx9fX1yuVwKBAJKSkq6kvaBSW/WhoORbgEGe2fLwki3gOtIOO/fYz4HZXh4WI2NjTp37pzmzZunjo4O+f1+lZSU2DVOp1P5+fk6duyYJKmtrU3nz58PqfF6vcrKyrJrRhMMBtXX1xcyAADA5BV2QDl58qRuuOEGOZ1OrVq1Sk1NTbrxxhvl9/slSW63O6Te7Xbb2/x+v2JjY5WcnHzJmtHU1NTI5XLZIz09Pdy2AQDABBJ2QPnKV76iEydO6JVXXtF3vvMdlZWV6bXXXrO3OxyOkHrLskbMXexyNZWVlQoEAvbo6uoKt20AADCBhB1QYmNj9aUvfUlz585VTU2Nbr75Zv3DP/yDPB6PJI1YCenp6bFXVTwej4aGhtTb23vJmtE4nU77m0OfDAAAMHld8XVQLMtSMBhURkaGPB6Pmpub7W1DQ0NqaWlRXl6eJCknJ0cxMTEhNd3d3Tp16pRdAwAAEB1O8fe+9z0tWLBA6enp6u/vV2Njo371q1/p5z//uRwOh3w+n6qrq5WZmanMzExVV1crPj5ey5cvlyS5XC6tWLFC5eXlSk1NVUpKiioqKpSdna2ioqKrsoMAAGDiCSugvPvuu3rggQfU3d0tl8ul2bNn6+c//7mKi4slSevXr9fg4KBWr16t3t5e5ebm6vDhw0pMTLQfo76+XtHR0Vq6dKkGBwdVWFioPXv2KCoqanz3DAAATFhXfB2USOA6KMBnx3VQMNlw7ZaJ65pcBwUAAOBqIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHHCCig1NTW67bbblJiYqGnTpunuu+/WG2+8EVJjWZaqqqrk9XoVFxengoICtbe3h9QEg0GtXbtWaWlpSkhIUGlpqc6cOXPlewMAACaFsAJKS0uLHnnkEb3yyitqbm7Wn/70J5WUlOjcuXN2TW1trerq6tTQ0KDW1lZ5PB4VFxerv7/frvH5fGpqalJjY6OOHj2qgYEBLVq0SMPDw+O3ZwAAYMJyWJZljfXO//u//6tp06appaVFd955pyzLktfrlc/n0+OPPy7p49USt9utrVu3auXKlQoEApo6dar27dunZcuWSZLOnj2r9PR0HTp0SPPnz7/s8/b19cnlcikQCCgpKWms7QNhm7XhYKRbAK5772xZGOkWMEbhvH9f0TkogUBAkpSSkiJJ6ujokN/vV0lJiV3jdDqVn5+vY8eOSZLa2tp0/vz5kBqv16usrCy75mLBYFB9fX0hAwAATF5jDiiWZWndunX6i7/4C2VlZUmS/H6/JMntdofUut1ue5vf71dsbKySk5MvWXOxmpoauVwue6Snp4+1bQAAMAGMOaCsWbNG//3f/62f/OQnI7Y5HI6Q25ZljZi72KfVVFZWKhAI2KOrq2usbQMAgAlgTAFl7dq1+tnPfqaXXnpJX/jCF+x5j8cjSSNWQnp6euxVFY/Ho6GhIfX29l6y5mJOp1NJSUkhAwAATF5hBRTLsrRmzRr99Kc/1X/8x38oIyMjZHtGRoY8Ho+am5vtuaGhIbW0tCgvL0+SlJOTo5iYmJCa7u5unTp1yq4BAADXt+hwih955BEdOHBA//qv/6rExER7pcTlcikuLk4Oh0M+n0/V1dXKzMxUZmamqqurFR8fr+XLl9u1K1asUHl5uVJTU5WSkqKKigplZ2erqKho/PcQAABMOGEFlO3bt0uSCgoKQuZ3796tBx98UJK0fv16DQ4OavXq1ert7VVubq4OHz6sxMREu76+vl7R0dFaunSpBgcHVVhYqD179igqKurK9gYAAEwKV3QdlEjhOiiIFK6DAkQe10GZuK7ZdVAAAACuBgIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIwTdkD59a9/rcWLF8vr9crhcOiFF14I2W5ZlqqqquT1ehUXF6eCggK1t7eH1ASDQa1du1ZpaWlKSEhQaWmpzpw5c0U7AgAAJo+wA8q5c+d08803q6GhYdTttbW1qqurU0NDg1pbW+XxeFRcXKz+/n67xufzqampSY2NjTp69KgGBga0aNEiDQ8Pj31PAADApBEd7h0WLFigBQsWjLrNsixt27ZNGzdu1JIlSyRJe/fuldvt1oEDB7Ry5UoFAgHt2rVL+/btU1FRkSRp//79Sk9P15EjRzR//vwRjxsMBhUMBu3bfX194bYNAAAmkHE9B6Wjo0N+v18lJSX2nNPpVH5+vo4dOyZJamtr0/nz50NqvF6vsrKy7JqL1dTUyOVy2SM9PX082wYAAIYZ14Di9/slSW63O2Te7Xbb2/x+v2JjY5WcnHzJmotVVlYqEAjYo6urazzbBgAAhgn7I57PwuFwhNy2LGvE3MU+rcbpdMrpdI5bfwAAwGzjuoLi8XgkacRKSE9Pj72q4vF4NDQ0pN7e3kvWAACA69u4BpSMjAx5PB41Nzfbc0NDQ2ppaVFeXp4kKScnRzExMSE13d3dOnXqlF0DAACub2F/xDMwMKC33nrLvt3R0aETJ04oJSVFM2bMkM/nU3V1tTIzM5WZmanq6mrFx8dr+fLlkiSXy6UVK1aovLxcqampSklJUUVFhbKzs+1v9QAAgOtb2AHl1Vdf1Te+8Q379rp16yRJZWVl2rNnj9avX6/BwUGtXr1avb29ys3N1eHDh5WYmGjfp76+XtHR0Vq6dKkGBwdVWFioPXv2KCoqahx2CQAwmc3acDDSLYTtnS0LI93ChOOwLMuKdBPh6uvrk8vlUiAQUFJSUqTbwXVkIv5hBBB5BJSPhfP+zW/xAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIwTHekGcP2ateFgpFsAABiKFRQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcaIj3QAAAJPdrA0HI91C2N7ZsjCiz88KCgAAMA4BBQAAGIePeCaJibh8CADApUR0BeXHP/6xMjIyNGXKFOXk5Ojll1+OZDsAAMAQEQsozz//vHw+nzZu3Kjjx4/rjjvu0IIFC9TZ2RmplgAAgCEclmVZkXji3Nxc3Xrrrdq+fbs997WvfU133323ampqQmqDwaCCwaB9OxAIaMaMGerq6lJSUtK495a16Rfj/pgAAEwkp344f9wfs6+vT+np6frjH/8ol8v16cVWBASDQSsqKsr66U9/GjL/6KOPWnfeeeeI+k2bNlmSGAwGg8FgTILR1dV12awQkZNk33vvPQ0PD8vtdofMu91u+f3+EfWVlZVat26dffvChQv64IMPlJqaKofDcdX7NdknafRqrSZNVByX0XFcRuKYjI7jMhLHZHThHBfLstTf3y+v13vZx43ot3guDheWZY0aOJxOp5xOZ8jc5z//+avZ2oSTlJTE/zCj4LiMjuMyEsdkdByXkTgmo/usx+WyH+38fyJykmxaWpqioqJGrJb09PSMWFUBAADXn4gElNjYWOXk5Ki5uTlkvrm5WXl5eZFoCQAAGCRiH/GsW7dODzzwgObOnat58+Zp586d6uzs1KpVqyLV0oTkdDq1adOmER+BXe84LqPjuIzEMRkdx2UkjsnortZxidjXjKWPL9RWW1ur7u5uZWVlqb6+XnfeeWek2gEAAIaIaEABAAAYDT8WCAAAjENAAQAAxiGgAAAA4xBQAACAcQgoE9jmzZuVl5en+Pj4S15Z1+FwjBg7duy4to1eY5/luHR2dmrx4sVKSEhQWlqaHn30UQ0NDV3bRiNs1qxZI14bGzZsiHRb19yPf/xjZWRkaMqUKcrJydHLL78c6ZYipqqqasRrwuPxRLqta+7Xv/61Fi9eLK/XK4fDoRdeeCFku2VZqqqqktfrVVxcnAoKCtTe3h6ZZq+hyx2XBx98cMTr5/bbbx/z8xFQJrChoSHde++9+s53vvOpdbt371Z3d7c9ysrKrlGHkXG54zI8PKyFCxfq3LlzOnr0qBobG/Uv//IvKi8vv8adRt6TTz4Z8tp44oknIt3SNfX888/L5/Np48aNOn78uO644w4tWLBAnZ2dkW4tYm666aaQ18TJkycj3dI1d+7cOd18881qaGgYdXttba3q6urU0NCg1tZWeTweFRcXq7+//xp3em1d7rhI0l/+5V+GvH4OHTo09ie88t8mRqTt3r3bcrlco26TZDU1NV3TfkxxqeNy6NAh63Of+5z1hz/8wZ77yU9+YjmdTisQCFzDDiNr5syZVn19faTbiKg///M/t1atWhUy99WvftXasGFDhDqKrE2bNlk333xzpNswysV/Qy9cuGB5PB5ry5Yt9txHH31kuVwua8eOHRHoMDJGe28pKyuz7rrrrnF7DlZQrgNr1qxRWlqabrvtNu3YsUMXLlyIdEsR9Zvf/EZZWVkhv6Y5f/58BYNBtbW1RbCza2/r1q1KTU3VLbfcos2bN19XH3MNDQ2pra1NJSUlIfMlJSU6duxYhLqKvDfffFNer1cZGRm677779Pbbb0e6JaN0dHTI7/eHvG6cTqfy8/Ov69fNJ371q19p2rRp+vKXv6yHH35YPT09Y36siP6aMa6+v//7v1dhYaHi4uL0y1/+UuXl5Xrvvfeuu6X8/8vv94/4Ucrk5GTFxsaO+AHLyey73/2ubr31ViUnJ+u3v/2tKisr1dHRoX/+53+OdGvXxHvvvafh4eERrwW3231dvQ7+r9zcXD333HP68pe/rHfffVdPPfWU8vLy1N7ertTU1Ei3Z4RPXhujvW5Onz4diZaMsWDBAt17772aOXOmOjo69P3vf1/f/OY31dbWNqbL4LOCYpjRTlK7eLz66quf+fGeeOIJzZs3T7fccovKy8v15JNP6umnn76Ke3B1jPdxcTgcI+Ysyxp1fiIJ5zg99thjys/P1+zZs/Xtb39bO3bs0K5du/T+++9HeC+urYv/m0+G18FYLViwQPfcc4+ys7NVVFSkgwcPSpL27t0b4c7Mw+tmpGXLlmnhwoXKysrS4sWL9eKLL+r3v/+9/ToKFysohlmzZo3uu+++T62ZNWvWmB//9ttvV19fn959990R/wIw2XgeF4/Ho//6r/8Kmevt7dX58+cn1DEZzZUcp0/Otn/rrbeui38tp6WlKSoqasRqSU9Pz4R/HYyXhIQEZWdn680334x0K8b45FtNfr9f06dPt+d53Yw0ffp0zZw5c8yvHwKKYdLS0pSWlnbVHv/48eOaMmXKJb9+a6rxPC7z5s3T5s2b1d3dbf+BOXz4sJxOp3JycsblOSLlSo7T8ePHJSnkj+5kFhsbq5ycHDU3N+uv/uqv7Pnm5mbdddddEezMHMFgUK+//rruuOOOSLdijIyMDHk8HjU3N2vOnDmSPj6fqaWlRVu3bo1wd2Z5//331dXVNea/KQSUCayzs1MffPCBOjs7NTw8rBMnTkiSvvSlL+mGG27Qv/3bv8nv92vevHmKi4vTSy+9pI0bN+pv//ZvJ/XPhV/uuJSUlOjGG2/UAw88oKeffloffPCBKioq9PDDDyspKSmyzV8jv/nNb/TKK6/oG9/4hlwul1pbW/XYY4+ptLRUM2bMiHR718y6dev0wAMPaO7cuZo3b5527typzs5OrVq1KtKtRURFRYUWL16sGTNmqKenR0899ZT6+vom/aUJLjYwMKC33nrLvt3R0aETJ04oJSVFM2bMkM/nU3V1tTIzM5WZmanq6mrFx8dr+fLlEez66vu045KSkqKqqirdc889mj59ut555x1973vfU1paWsg/AMIybt8HwjVXVlZmSRoxXnrpJcuyLOvFF1+0brnlFuuGG26w4uPjraysLGvbtm3W+fPnI9v4VXa542JZlnX69Glr4cKFVlxcnJWSkmKtWbPG+uijjyLX9DXW1tZm5ebmWi6Xy5oyZYr1la98xdq0aZN17ty5SLd2zf3TP/2TNXPmTCs2Nta69dZbrZaWlki3FDHLli2zpk+fbsXExFher9dasmSJ1d7eHum2rrmXXnpp1L8hZWVllmV9/FXjTZs2WR6Px3I6ndadd95pnTx5MrJNXwOfdlw+/PBDq6SkxJo6daoVExNjzZgxwyorK7M6OzvH/HwOy7KssUUbAACAq4Nv8QAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOP8PdBaLAnrdYUcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(noise_ss_v2)\n",
    "print(np.std(noise_ss_v2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "da339faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2088838055978424\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avgfp_train_df['score'] = ss_scores\n",
    "plt.hist(avgfp_train_df['score'])\n",
    "print(avgfp_train_df['score'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "404b8d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of above cell\n",
    "\n",
    "# getting training set (5k in ss, 5k not in ss)\n",
    "# avgfp_train_ss = avgfp_no_mixed_pos_df[avgfp_no_mixed_pos_df['in_sec_str'] == True].sample(72)\n",
    "# avgfp_train_not_ss = avgfp_no_mixed_pos_df[avgfp_no_mixed_pos_df['in_sec_str'] == False].sample(72)\n",
    "# avgfp_train_df = pd.concat([avgfp_train_ss, avgfp_train_not_ss])\n",
    "avgfp_train_df = avgfp_no_mixed_pos_df.sample(13)\n",
    "\n",
    "# avgfp_test_ss = avgfp_no_mixed_pos_df[avgfp_no_mixed_pos_df['in_sec_str'] == True].sample(15)\n",
    "# avgfp_test_not_ss = avgfp_no_mixed_pos_df[avgfp_no_mixed_pos_df['in_sec_str'] == False].sample(15)\n",
    "# avgfp_test_df = pd.concat([avgfp_test_ss, avgfp_test_not_ss])\n",
    "\n",
    "avgfp_test_df = avgfp_no_mixed_pos_df.sample(10342)\n",
    "\n",
    "# getting test set (2.5k in ss, 2.5k not in ss)\n",
    "# print(avgfp_train_df['in_sec_str'].value_counts())\n",
    "# print(avgfp_test_df['in_sec_str'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4098c337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: avgfp_trainbatch_train_13_test_10342_t3.txt\n"
     ]
    }
   ],
   "source": [
    "# creating files (NO NOISE for test values)\n",
    "\n",
    "# unchanged\n",
    "# avgfp_train_df['score'] = unchanged_scores\n",
    "# avgfp_full_df = pd.concat([avgfp_train_df, avgfp_test_df])\n",
    "ssf.write_data_file(\"avgfp_trainbatch_train_13_test_10342_t3\", protein_seq_avgfp, avgfp_full_df)\n",
    "\n",
    "# # ss\n",
    "# avgfp_trabin_df['score'] = ss_scores\n",
    "# avgfp_full_df = pd.conbcat([avgfp_train_df, avgfp_test_df])\n",
    "# ssf.write_data_file(\"avgfp_MLformat_5000_train_2000_ss_noise_t2_v2\", protein_seq_avgfp, avgfp_full_df)\n",
    "\n",
    "# # not ss\n",
    "# avgfp_train_df['score'] = not_ss_scores\n",
    "# avgfp_full_df = pd.concat([avgfp_train_df, avgfp_test_df])\n",
    "# ssf.write_data_file(\"avgfp_MLformat_5000_train_2000_not_ss_noise_t2_v2\", protein_seq_avgfp, avgfp_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgfp_train_df = avgfp_no_mixed_pos_df.sample(13)\n",
    "avgfp_test_df = avgfp_no_mixed_pos_df.sample(10342)\n",
    "avgfp_full_df = pd.concat([avgfp_train_df, avgfp_test_df])\n",
    "ssf.write_data_file(\"avgfp_trainbatch_train_13_test_10342_t3\", protein_seq_avgfp, avgfp_full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7aeef4",
   "metadata": {},
   "source": [
    "**GB1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7d12a11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing STRIDE file\n",
    "path = \"../PDB and STRIDE Files/\" + 'gb1_stride.txt'\n",
    "gb1_stride_file = open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0439dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb1_ss_indexes = ssf.get_all_sec_struc_boolean(gb1_stride_file) # boolean list of secondary structure assignements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8a6166dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "ss = gb1_ss_indexes.count(True)\n",
    "not_ss = gb1_ss_indexes.count(False)\n",
    "print(ss)\n",
    "print(not_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4aee2008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536084\n",
      "Index(['variant', 'num_mutations', 'inp', 'sel', 'score'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# importing pab1 data from Gelman et al.\n",
    "gb1_df1 = pd.read_csv(\"../Raw Data/gb1.tsv.txt\", sep=\"\\t\")\n",
    "gb1_df = gb1_df1.dropna()\n",
    "print(len(gb1_df))\n",
    "# gb1_df = gb1_df.sample(n=480)\n",
    "print(gb1_df.columns)\n",
    "gb1_df = gb1_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "56682961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536084\n",
      "536084\n"
     ]
    }
   ],
   "source": [
    "# rounding score column to 2 decimal points\n",
    "gb1_df[\"score\"] = gb1_df[\"score\"].round(6)\n",
    "print(len(gb1_df))\n",
    "\n",
    "# remove values with wildcard star thing cause idk what it means\n",
    "gb1_df = gb1_df[gb1_df[\"variant\"].str.contains(\"\\*\") == False]\n",
    "\n",
    "# gb1_df = gb1_df.sample(n=40)\n",
    "# pab1_df = pab1_df.head(37600)\n",
    "print(len(gb1_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "da656d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting protein sequence\n",
    "# protein_seq_gb1 = ssf.get_protein_seq(\"P04386\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9de07a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "MET GLN TYR LYS LEU ILE LEU ASN GLY LYS THR LEU LYS GLY GLU THR THR THR GLU ALA VAL ASP ALA ALA THR ALA GLU LYS VAL PHE LYS GLN TYR ALA ASN ASP ASN GLY VAL ASP GLY GLU TRP THR TYR ASP ASP ALA THR LYS THR PHE THR VAL THR GLU\n"
     ]
    }
   ],
   "source": [
    "# getting dataset size to run\n",
    "\n",
    "string_seq = \"MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDDATKTFTVTE\"\n",
    "print(len(string_seq)) # <- domain length of 75\n",
    "protein_seq_gb1 = ssf.get_expanded_seq(string_seq)\n",
    "print(protein_seq_gb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8e6f74f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting variant list if there are multiple mutations\n",
    "gb1_mut = gb1_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "gb1_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(gb1_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "gb1_df[\"MUTATED_RES\"] = ssf.get_mutation_type(gb1_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "gb1_df[\"POSITION\"] = ssf.get_position(gb1_mut)\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "gb1_df[\"variant\"] = ssf.get_mutations_names_list(gb1_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]\n",
    "\n",
    "# gb1_df = gb1_df.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "98925273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need positionssplit\n",
    "gb1_df[\"positions_split\"] = ssf.get_positions_split(gb1_df)\n",
    "\n",
    "# add in_sec_str_col\n",
    "gb1_df = add_sec_str_col(gb1_df, gb1_ss_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4dd94aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: gb1_MLformat_full_dataset.txt\n"
     ]
    }
   ],
   "source": [
    "# ssf.write_data_file(\"gb1_MLformat_full_dataset\", protein_seq_gb1, gb1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7c4ef844",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len536084\n",
      "77\n",
      "33\n",
      "Train Data Fraction: 0.7\n",
      "false_df len145781\n",
      "true_df len390303\n",
      "in fraction,df len535974\n",
      "Test Data Fraction: 0.7\n",
      "false_df len145748\n",
      "true_df len390226\n",
      "Size of Test Dataset: 485823\n",
      "Size of Total Dataset: 485933\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gb1_test_10000' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21904\\2870214943.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgb1_train_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgb1_test_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgb1_remaining_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_train_and_test_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgb1_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.70\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m110\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# gb1_test_10000 = gb1_test_df.head(10000)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgb1_df_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgb1_train_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgb1_test_10000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgb1_df_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# writing data to txt file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gb1_test_10000' is not defined"
     ]
    }
   ],
   "source": [
    "gb1_train_df, gb1_test_df, gb1_remaining_df = get_train_and_test_df(gb1_df, 0.70, 110)\n",
    "# gb1_test_10000 = gb1_test_df.head(10000)\n",
    "gb1_df_format = pd.concat([gb1_train_df, gb1_test_10000])\n",
    "print(len(gb1_df_format))\n",
    "# writing data to txt file\n",
    "# ssf.write_data_file(\"gb1_MLformat_110_train_382146_test_t1\", protein_seq_gb1, gb1_df_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e6230693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len536084\n",
      "244999\n",
      "105001\n",
      "Train Data Fraction: 0.7\n",
      "false_df len268502\n",
      "true_df len267582\n",
      "in fraction,df len186084\n",
      "Test Data Fraction: 0.7\n",
      "false_df len163501\n",
      "true_df len22583\n",
      "Size of Test Dataset: 32256\n",
      "Size of Total Dataset: 382256\n"
     ]
    }
   ],
   "source": [
    "# make a smaller test size so program doesn't crash\n",
    "gb1_train_dummy, gb1_test_df, gb1_remaining_df = get_train_and_test_df(gb1_df, 0.70, 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6a534f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32256\n"
     ]
    }
   ],
   "source": [
    "print(len(gb1_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f96563fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len536084\n",
      "92\n",
      "18\n",
      "Train Data Fraction: 0.836\n",
      "false_df len145781\n",
      "true_df len390303\n",
      "in fraction,df len535974\n",
      "Test Data Fraction: 0.84\n",
      "false_df len145763\n",
      "true_df len390211\n",
      "Size of Test Dataset: 464531\n",
      "Size of Total Dataset: 464641\n",
      "in fraction,df len464531\n",
      "378000\n",
      "72000\n",
      "Train Data Fraction: 0.84\n",
      "false_df len74325\n",
      "true_df len390206\n",
      "in fraction,df len14531\n",
      "Test Data Fraction: 0.84\n",
      "false_df len2325\n",
      "true_df len12206\n",
      "Size of Test Dataset: 14524\n",
      "Size of Total Dataset: 464524\n",
      "SMALL TEST\n",
      "14524\n",
      "14634\n",
      "Filename: gb1_MLformat_110_train_14524_test_t3.txt\n"
     ]
    }
   ],
   "source": [
    "gb1_train_df, gb1_test_df, gb1_remaining_df = get_train_and_test_df(gb1_df, 0.84, 110)\n",
    "gb1_train_dummy, gb1_small_test_df, gb1_remaining_df = get_train_and_test_df(gb1_test_df, 0.84, 450000)\n",
    "print(\"SMALL TEST\")\n",
    "print(len(gb1_small_test_df))\n",
    "gb1_df_format = pd.concat([gb1_train_df, gb1_small_test_df])\n",
    "print(len(gb1_df_format))\n",
    "ssf.write_data_file(\"gb1_MLformat_110_train_14524_test_t3\", protein_seq_gb1, gb1_df_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da00df42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len25737\n",
      "530\n",
      "452\n",
      "Train Data Fraction: 0.54\n",
      "false_df len17674\n",
      "true_df len8063\n",
      "in fraction,df len24755\n",
      "Test Data Fraction: 0.54\n",
      "false_df len17222\n",
      "true_df len7533\n",
      "Size of Test Dataset: 13945\n",
      "Size of Total Dataset: 14927\n",
      "14927\n",
      "Filename: bgl3_MLformat_982_train_13945_test_t2.txt\n"
     ]
    }
   ],
   "source": [
    "gb1_train_df_2, gb1_test_df_2, gb1_remaining_df_2 = get_train_and_test_df(gb1_df, 0.70, 110)\n",
    "gb1_df_format_2 = pd.concat([gb1_train_df_2, gb1_test_df_2])\n",
    "print(len(gb1_df_format_2))\n",
    "ssf.write_data_file(\"gb1_MLformat_982_train_13945_test_t2\", protein_seq_gb1, gb1_df_format_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "676b4719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len25737\n",
      "530\n",
      "452\n",
      "Train Data Fraction: 0.54\n",
      "false_df len17674\n",
      "true_df len8063\n",
      "in fraction,df len24755\n",
      "Test Data Fraction: 0.54\n",
      "false_df len17222\n",
      "true_df len7533\n",
      "Size of Test Dataset: 13945\n",
      "Size of Total Dataset: 14927\n",
      "14927\n",
      "Filename: bgl3_MLformat_982_train_13945_test_t3.txt\n"
     ]
    }
   ],
   "source": [
    "gb1_train_df_3, gb1_test_df_3, gb1_remaining_df_3 = get_train_and_test_df(gb1_df, 0.70, 110)\n",
    "gb1_df_format_3 = pd.concat([gb1_train_df_3, gb1_test_df_3])\n",
    "print(len(gb1_df_format_3))\n",
    "ssf.write_data_file(\"gb1_MLformat_982_train_13945_test_t3\", protein_seq_gb1, gb1_df_format_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "945d7a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "982\n",
      "13945\n",
      "982\n",
      "13945\n",
      "982\n",
      "13945\n"
     ]
    }
   ],
   "source": [
    "print(len(gb1_train_df))\n",
    "print(len(gb1_test_df))\n",
    "print(len(gb1_train_df_2))\n",
    "print(len(gb1_test_df_2))\n",
    "print(len(gb1_train_df_3))\n",
    "print(len(gb1_test_df_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df004ece",
   "metadata": {},
   "source": [
    "# Adding Noise to GB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6f0cd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536084\n"
     ]
    }
   ],
   "source": [
    "# importing and formatting data (25737 usable vals)\n",
    "gb1_df1 = pd.read_csv(\"../Raw Data/gb1.tsv.txt\", sep=\"\\t\")\n",
    "gb1_df = gb1_df1.dropna()\n",
    "gb1_df = gb1_df.sample(frac=1)\n",
    "\n",
    "# print(gb1_df.head(10))\n",
    "# rounding score column to 6 decimal points\n",
    "gb1_df[\"score\"] = gb1_df[\"score\"].round(6)\n",
    "\n",
    "# remove values with wildcard star next to them\n",
    "gb1_df = gb1_df[gb1_df[\"variant\"].str.contains(\"\\*\") == False]\n",
    "\n",
    "# splitting variant list if there are multiple mutations\n",
    "gb1_mut = gb1_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "gb1_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(gb1_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "gb1_df[\"MUTATED_RES\"] = ssf.get_mutation_type(gb1_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "gb1_df[\"POSITION\"] = ssf.get_position(gb1_mut)\n",
    "\n",
    "gb1_df[\"positions_split\"] = ssf.get_positions_split(gb1_df)\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "gb1_df[\"variant\"] = ssf.get_mutations_names_list(gb1_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]\n",
    "# print(gb1_df.head(10))\n",
    "print(len(gb1_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "edbba0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# secondary structure assignments\n",
    "path = \"../PDB and STRIDE Files/\" + 'gb1_stride.txt'\n",
    "gb1_stride_file = open(path, 'r')\n",
    "\n",
    "gb1_ss_indexes = ssf.get_sec_struc_boolean(gb1_stride_file) # not including turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c019fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need positionssplit\n",
    "gb1_df[\"positions_split\"] = ssf.get_positions_split(gb1_df)\n",
    "\n",
    "# gb1_only_ss_df = get_ss_dataset(gb1_df, gb1_ss_indexes, 0)\n",
    "# gb1_only_not_ss_df = get_not_ss_dataset(gb1_df, gb1_ss_indexes, 0)\n",
    "# gb1_no_mixed_pos_df = pd.concat([gb1_only_ss_df, gb1_only_not_ss_df])\n",
    "gb1_no_mixed_pos_df = gb1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5ca6514b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536084\n",
      "536084\n"
     ]
    }
   ],
   "source": [
    "print(len(gb1_df))\n",
    "print(len(gb1_no_mixed_pos_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bbc09b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    268560\n",
      "True     267524\n",
      "Name: in_sec_str, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "gb1_no_mixed_pos_df = add_sec_str_col(gb1_no_mixed_pos_df, gb1_ss_indexes, 0)\n",
    "print(gb1_no_mixed_pos_df['in_sec_str'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e21e24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536084\n"
     ]
    }
   ],
   "source": [
    "# shuffling data\n",
    "gb1_no_mixed_pos_df = gb1_no_mixed_pos_df.sample(frac=1)\n",
    "print(len(gb1_no_mixed_pos_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9ff12246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein sequence\n",
    "string_seq = \"MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDDATKTFTVTE\"\n",
    "protein_seq_gb1 = ssf.get_expanded_seq(string_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e3557c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     40\n",
      "False    40\n",
      "Name: in_sec_str, dtype: int64\n",
      "True     8\n",
      "False    8\n",
      "Name: in_sec_str, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# getting training set (5k in ss, 5k not in ss)\n",
    "gb1_train_ss = gb1_no_mixed_pos_df[gb1_no_mixed_pos_df['in_sec_str'] == True].sample(40)\n",
    "gb1_train_not_ss = gb1_no_mixed_pos_df[gb1_no_mixed_pos_df['in_sec_str'] == False].sample(40)\n",
    "gb1_train_df = pd.concat([gb1_train_ss, gb1_train_not_ss])\n",
    "\n",
    "gb1_test_ss = gb1_no_mixed_pos_df[gb1_no_mixed_pos_df['in_sec_str'] == True].sample(8)\n",
    "gb1_test_not_ss = gb1_no_mixed_pos_df[gb1_no_mixed_pos_df['in_sec_str'] == False].sample(8)\n",
    "gb1_test_df = pd.concat([gb1_test_ss, gb1_test_not_ss])\n",
    "\n",
    "# getting test set (2.5k in ss, 2.5k not in ss)\n",
    "print(gb1_train_df['in_sec_str'].value_counts())\n",
    "print(gb1_test_df['in_sec_str'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "1a2b5853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # getting dataset with correct ratios (only using training dataset)\n",
    "# gb1_train_df, gb1_test_df_1, gb1_remaining_df = get_train_and_test_df(gb1_no_mixed_pos_df, 0.70, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "9e81a8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gb1_test_df, gb1_dummy_df, gb1_remaining_df_1 = get_train_and_test_df(gb1_test_df_1, 0.70, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0df7555b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Standard Deviation: 2.204906979409146\n",
      "Dataset Mean: -2.0552613375\n",
      "Dataset Median: -1.5347925\n",
      "Kurtosis: 1.9212641745260335\n"
     ]
    }
   ],
   "source": [
    "# adding noise to values from uniform distribution and creating files\n",
    "\n",
    "# finding standard deviation of dataset scores\n",
    "std = gb1_train_df['score'].std()\n",
    "mean = gb1_train_df['score'].mean()\n",
    "median = gb1_train_df['score'].median()\n",
    "print(\"Dataset Standard Deviation: \" + str(std))\n",
    "print(\"Dataset Mean: \" + str(mean))\n",
    "print(\"Dataset Median: \" + str(median))\n",
    "print(\"Kurtosis: \" + str(kurtosis(gb1_train_df['score'], fisher=False)))\n",
    "\n",
    "# finding number of ss and not ss values\n",
    "num_ss_vals = (gb1_train_df.in_sec_str == True).sum()\n",
    "num_not_ss_vals = (gb1_train_df.in_sec_str == False).sum()\n",
    "\n",
    "# creating noise (std not the exact same, but similar) // 0 is the mean of the normal distribution\n",
    "noise_ss = np.random.normal(0, std * 3, num_ss_vals).tolist()\n",
    "noise_ss_v2 = noise_ss.copy()\n",
    "noise_not_ss = np.random.normal(0, std * 3, num_not_ss_vals).tolist()\n",
    "\n",
    "# filling in values for not ss indexes in noise_ss\n",
    "bool_ss_list = gb1_train_df.in_sec_str.values.tolist()\n",
    "\n",
    "noise_ss_to_add = []\n",
    "noise_not_ss_to_add = []\n",
    "\n",
    "for ss_assign in bool_ss_list:\n",
    "    if ss_assign: # if true (ss index)\n",
    "        noise_ss_to_add.append(noise_ss.pop(0))\n",
    "        noise_not_ss_to_add.append(0)\n",
    "    else: # if false (not ss index)\n",
    "        noise_ss_to_add.append(0)\n",
    "        noise_not_ss_to_add.append(noise_not_ss.pop(0))\n",
    "        \n",
    "unchanged_scores = gb1_train_df['score']\n",
    "# print(unchanged_scores[0:10])\n",
    "ss_scores = gb1_train_df['score'] + noise_ss_to_add\n",
    "# print(ss_scores[0:10])\n",
    "not_ss_scores = gb1_train_df['score'] + noise_not_ss_to_add\n",
    "# print(not_ss_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "78f135b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2690442875000008\n",
      "\n",
      "3.557484593696043\n",
      "Percentage Change: 56.78339172549279\n",
      "4.165350043091337\n",
      "Percentage Change: 83.57288423315252\n"
     ]
    }
   ],
   "source": [
    "abs_val_list = [abs(x) for x in gb1_train_df['score']]\n",
    "mean = sum(abs_val_list) / len(abs_val_list)\n",
    "print(mean)\n",
    "print()\n",
    "\n",
    "abs_ss_val_list = [abs(x) for x in ss_scores]\n",
    "mean_ss = sum(abs_ss_val_list) / len(abs_ss_val_list)\n",
    "print(mean_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_ss - mean) / mean) * 100))\n",
    "\n",
    "abs_not_ss_val_list = [abs(x) for x in not_ss_scores]\n",
    "mean_not_ss = sum(abs_not_ss_val_list) / len(abs_not_ss_val_list)\n",
    "print(mean_not_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_not_ss - mean) / mean) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24b96dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: gb1_trainbatch_train_27_test_7_t3.txt\n"
     ]
    }
   ],
   "source": [
    "# creating files (NO NOISE for test values)\n",
    "\n",
    "# unchanged\n",
    "# gb1_train_df['score'] = unchanged_scores\n",
    "gb1_full_df = gb1_no_mixed_pos_df.sample(34)\n",
    "ssf.write_data_file(\"gb1_trainbatch_train_27_test_7_t3\", protein_seq_gb1, gb1_full_df)\n",
    "\n",
    "# # ss\n",
    "# gb1_train_df['score'] = ss_scores\n",
    "# gb1_full_df = pd.concat([gb1_train_df, gb1_test_df])\n",
    "# ssf.write_data_file(\"gb1_MLformat_10000_train_5000_ss_noise_t2_v2\", protein_seq_gb1, gb1_full_df)\n",
    "\n",
    "# # not ss\n",
    "# gb1_train_df['score'] = not_ss_scores\n",
    "# gb1_full_df = pd.concat([gb1_train_df, gb1_test_df])\n",
    "# ssf.write_data_file(\"gb1_MLformat_10000_train_5000_not_ss_noise_t2_v2\", protein_seq_gb1, gb1_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5a1d2d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: gb1_trainbatch_train_27_test_21444_t3.txt\n"
     ]
    }
   ],
   "source": [
    "gb1_full_df = gb1_no_mixed_pos_df.sample(21471)\n",
    "ssf.write_data_file(\"gb1_trainbatch_train_27_test_21444_t3\", protein_seq_gb1, gb1_full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3715ca07",
   "metadata": {},
   "source": [
    "**GAL4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "29913e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing STRIDE file\n",
    "path = \"../PDB and STRIDE Files/\" + 'gal4_stride.txt'\n",
    "gal4_stride_file = open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a935928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gal4_ss_indexes = ssf.get_sec_struc_boolean(gal4_stride_file) # boolean list of secondary structure assignements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e740a750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415\n",
      "466\n"
     ]
    }
   ],
   "source": [
    "ss = gal4_ss_indexes.count(True)\n",
    "not_ss = gal4_ss_indexes.count(False)\n",
    "print(ss)\n",
    "print(not_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaa7c8e",
   "metadata": {},
   "source": [
    "**Alpha-synuclein**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8e8527fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing STRIDE file\n",
    "path = \"../PDB and STRIDE Files/\" + 'alpha-synuclein_stride.txt'\n",
    "alpha_synuclein_stride_file = open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "529330dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_synuclein_ss_indexes = ssf.get_sec_struc_boolean(alpha_synuclein_stride_file) # boolean list of secondary structure assignements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "02c410e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "ss = alpha_synuclein_ss_indexes.count(True)\n",
    "not_ss = alpha_synuclein_ss_indexes.count(False)\n",
    "print(ss)\n",
    "print(not_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0675451f",
   "metadata": {},
   "source": [
    "**Small ubiquitin-related modifier 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4fd23a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing STRIDE file\n",
    "path = \"../PDB and STRIDE Files/\" + 'modifier_1_stride.txt'\n",
    "modifier_1_stride_file = open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "54b27e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "modifier_1_ss_indexes = ssf.get_sec_struc_boolean(modifier_1_stride_file) # boolean list of secondary structure assignements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d6281f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "ss = modifier_1_ss_indexes.count(True)\n",
    "not_ss = modifier_1_ss_indexes.count(False)\n",
    "print(ss)\n",
    "print(not_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1de327",
   "metadata": {},
   "source": [
    "**TAR DNA-binding protein 43**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "189f45e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing STRIDE file\n",
    "path = \"../PDB and STRIDE Files/\" + 'tar_stride.txt'\n",
    "tar_stride_file = open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1ccd28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_ss_indexes = ssf.get_sec_struc_boolean(tar_stride_file) # boolean list of secondary structure assignements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b84c08b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "265\n"
     ]
    }
   ],
   "source": [
    "ss = tar_ss_indexes.count(True)\n",
    "not_ss = tar_ss_indexes.count(False)\n",
    "print(ss)\n",
    "print(not_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6717535",
   "metadata": {},
   "source": [
    "**Human Glucokinase**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8ea616",
   "metadata": {},
   "source": [
    "## Cleaning MaveDB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8149a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# delete rows with \"del\" in it or *\n",
    "# normalize scores? (already done in script)\n",
    "def format_mavedb_variant(df, variant_col_name, offset):\n",
    "    new_var_col = []\n",
    "    for variant in df[variant_col_name]:\n",
    "        wild_type = Bio.PDB.Polypeptide.three_to_one(variant[2:5].upper())\n",
    "        position = int(re.findall(\"[0-9]+\", variant)[0]) + offset\n",
    "        mut_type = Bio.PDB.Polypeptide.three_to_one(variant[-3:].upper())\n",
    "        new_var_col.append(wild_type + str(position) + mut_type)\n",
    "    return new_var_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920e582a",
   "metadata": {},
   "source": [
    "**GAL4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "02a98f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "gal4_df1 = pd.read_csv(\"../Raw Data/gal4.csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "081388b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['accession', 'hgvs_nt', 'hgvs_splice', 'hgvs_pro', 'score'], dtype='object', name=3)\n",
      "1323\n",
      "1196\n"
     ]
    }
   ],
   "source": [
    "# take note of offset\n",
    "\n",
    "# find columns and rename title column\n",
    "gal4_df1 = pd.read_csv(\"../Raw Data/gal4.csv.csv\")\n",
    "gal4_df1.columns = gal4_df1.iloc[3]\n",
    "print(gal4_df1.columns)\n",
    "print(len(gal4_df1))\n",
    "\n",
    "\n",
    "gal4_df = gal4_df1[(gal4_df1[\"hgvs_pro\"].str.contains(\"del\") == False) & (gal4_df1[\"hgvs_pro\"].str.contains(\"hgvs\") == False)\n",
    "                   & (gal4_df1[\"hgvs_pro\"].str.contains(\"Ter\") == False)]\n",
    "gal4_df = gal4_df.sample(frac=1)\n",
    "\n",
    "print(len(gal4_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "cd2c50a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting uniprot to compare offset\n",
    "protein_seq_gal4 = ssf.get_protein_seq(\"P04386\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "cbb85dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO\n"
     ]
    }
   ],
   "source": [
    "# comparing offset\n",
    "protein_seq_gal4_list = protein_seq_gal4.split(\" \")\n",
    "# print(protein_seq_gal4_list)\n",
    "print(protein_seq_gal4_list[41]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "e817fcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepti\\AppData\\Local\\Temp/ipykernel_1360/276527083.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gal4_df[\"variant\"] = format_mavedb_variant(gal4_df, \"hgvs_pro\", 0)\n"
     ]
    }
   ],
   "source": [
    "gal4_df[\"variant\"] = format_mavedb_variant(gal4_df, \"hgvs_pro\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "8002fcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepti\\AppData\\Local\\Temp/ipykernel_1360/789454968.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gal4_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(gal4_mut)\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp/ipykernel_1360/789454968.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gal4_df[\"MUTATED_RES\"] = ssf.get_mutation_type(gal4_mut)\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp/ipykernel_1360/789454968.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gal4_df[\"POSITION\"] = ssf.get_position(gal4_mut)\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp/ipykernel_1360/789454968.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gal4_df[\"variant\"] = ssf.get_mutations_names_list(gal4_df)\n"
     ]
    }
   ],
   "source": [
    "# splitting variant list if there are multiple mutations\n",
    "gal4_mut = gal4_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "gal4_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(gal4_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "gal4_df[\"MUTATED_RES\"] = ssf.get_mutation_type(gal4_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "gal4_df[\"POSITION\"] = ssf.get_position(gal4_mut)\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "gal4_df[\"variant\"] = ssf.get_mutations_names_list(gal4_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "# to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]\n",
    "\n",
    "# pab1_df = pab1_df.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20334ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting training and test datasets\n",
    "\n",
    "# get ss position indexes\n",
    "path = \"../PDB and STRIDE Files/\" + 'gal4_stride.txt'\n",
    "gal4_stride_file = open(path, 'r')\n",
    "\n",
    "gal4_ss_indexes = ssf.get_sec_struc_boolean(gal4_stride_file) # boolean list of secondary structure assignements\n",
    "\n",
    "# need positionssplit\n",
    "gal4_df[\"positions_split\"] = ssf.get_positions_split(gal4_df)\n",
    "\n",
    "# add in_sec_str_col\n",
    "gal4_df = add_sec_str_col(gal4_df, gal4_ss_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a5cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gal4_train_df, gal4_test_df = get_train_and_test_df(gal4_df, 0.47, 40)\n",
    "gal4_df_format = pd.concat([gal4_train_df, gal4_test_df])\n",
    "\n",
    "# writing data to txt file\n",
    "ssf.write_data_file(\"gal4_MLformat_40_train\", protein_seq_gal4, gal4_df_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcb0165",
   "metadata": {},
   "source": [
    "**Small ubiquitin-related modifier 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ed8ca239",
   "metadata": {},
   "outputs": [],
   "source": [
    "modifier_1_df1 = pd.read_csv(\"../Raw Data/modifier_1_mod.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1e90a4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['accession', 'hgvs_nt', 'hgvs_splice', 'hgvs_pro', 'score', 'sd', 'se',\n",
      "       'exp.score', 'exp.sd', 'df', 'pred.score'],\n",
      "      dtype='object')\n",
      "2020\n",
      "1919\n",
      "                   accession  hgvs_nt  hgvs_splice   hgvs_pro     score  \\\n",
      "0  urn:mavedb:00000001-b-1#1      NaN          NaN  p.Glu5Lys  1.311357   \n",
      "\n",
      "         sd        se  exp.score    exp.sd   df  pred.score  \n",
      "0  0.085569  0.042785    1.31651  0.024947  4.0    1.117086  \n"
     ]
    }
   ],
   "source": [
    "# modifier_1_df1.columns = modifier_1_df1.iloc[3]\n",
    "print(modifier_1_df1.columns)\n",
    "print(len(modifier_1_df1))\n",
    "\n",
    "modifier_1_df = modifier_1_df1[(modifier_1_df1[\"hgvs_pro\"].str.contains(\"=\") == False) & (modifier_1_df1[\"hgvs_pro\"].str.contains(\"hgvs\") == False)\n",
    "                   & (modifier_1_df1[\"hgvs_pro\"].str.contains(\"Ter\") == False)]\n",
    "print(len(modifier_1_df))\n",
    "print(modifier_1_df.head(1))\n",
    "\n",
    "# shuffle values\n",
    "modifier_1_df = modifier_1_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6f062765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MET SER ASP GLN GLU ALA LYS PRO SER THR GLU ASP LEU GLY ASP LYS LYS GLU GLY GLU TYR ILE LYS LEU LYS VAL ILE GLY GLN ASP SER SER GLU ILE HIS PHE LYS VAL LYS MET THR THR HIS LEU LYS LYS LEU LYS GLU SER TYR CYS GLN ARG GLN GLY VAL PRO MET ASN SER LEU ARG PHE LEU PHE GLU GLY GLN ARG ILE ALA ASP ASN HIS THR PRO LYS GLU LEU GLY MET GLU GLU GLU ASP VAL ILE GLU VAL TYR GLN GLU GLN THR GLY GLY HIS SER THR VAL\n",
      "403\n"
     ]
    }
   ],
   "source": [
    "# getting uniprot to compare offset\n",
    "protein_seq_modifier_1 = ssf.get_protein_seq(\"P63165\")\n",
    "# offset of 1\n",
    "print(protein_seq_modifier_1)\n",
    "print(len(protein_seq_modifier_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "692a145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_seq_modifier_1_split = protein_seq_modifier_1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c7fd3c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLU GLY GLU TYR ILE LYS LEU LYS VAL ILE GLY GLN ASP SER SER GLU ILE HIS PHE LYS VAL LYS MET THR THR HIS LEU LYS LYS LEU LYS GLU SER TYR CYS GLN ARG GLN GLY VAL PRO MET ASN SER LEU ARG PHE LEU PHE GLU GLY GLN ARG ILE ALA ASP ASN HIS THR PRO LYS GLU LEU GLY MET GLU GLU GLU ASP VAL ILE GLU VAL TYR GLN GLU GLN THR GLY GLY HIS\n"
     ]
    }
   ],
   "source": [
    "protein_seq_modifier_1 = protein_seq_modifier_1_split[17:98]\n",
    "\n",
    "protein_seq_modifier_1_cut = \"\"\n",
    "for residue in protein_seq_modifier_1:\n",
    "\n",
    "    protein_seq_modifier_1_cut += residue + \" \"\n",
    "\n",
    "protein_seq_modifier_1 = protein_seq_modifier_1_cut.rstrip()\n",
    "print(protein_seq_modifier_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "740ef687",
   "metadata": {},
   "outputs": [],
   "source": [
    "modifier_1_df[\"variant\"] = format_mavedb_variant(modifier_1_df, \"hgvs_pro\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9575d7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         accession  hgvs_nt  hgvs_splice    hgvs_pro  \\\n",
      "1649  urn:mavedb:00000001-b-1#1650      NaN          NaN   p.Pro8Asp   \n",
      "1885  urn:mavedb:00000001-b-1#1886      NaN          NaN  p.Lys16Gly   \n",
      "199    urn:mavedb:00000001-b-1#200      NaN          NaN  p.Gln29Cys   \n",
      "360    urn:mavedb:00000001-b-1#361      NaN          NaN  p.Arg70Leu   \n",
      "95      urn:mavedb:00000001-b-1#96      NaN          NaN   p.Ala6Val   \n",
      "1998  urn:mavedb:00000001-b-1#1999      NaN          NaN  p.His98Pro   \n",
      "677    urn:mavedb:00000001-b-1#678      NaN          NaN  p.Lys39Asp   \n",
      "476    urn:mavedb:00000001-b-1#477      NaN          NaN  p.Ser31Gln   \n",
      "445    urn:mavedb:00000001-b-1#446      NaN          NaN  p.Arg63Ile   \n",
      "1428  urn:mavedb:00000001-b-1#1429      NaN          NaN  p.Val90Cys   \n",
      "\n",
      "         score        sd        se  exp.score    exp.sd   df  pred.score  \\\n",
      "1649 -0.538399  0.392906  0.196453  -0.646084  0.290898  4.0   -0.190205   \n",
      "1885  0.800349  0.095263  0.047631   0.802951  0.034200  4.0    0.728795   \n",
      "199   0.513098  0.470306  0.470306        NaN       NaN  NaN    0.513098   \n",
      "360   0.835014  0.103175  0.051587   0.836548  0.040112  4.0    0.799051   \n",
      "95    1.064414  0.077309  0.038655   1.066550  0.022978  4.0    0.976980   \n",
      "1998  0.364560  0.470306  0.470306        NaN       NaN  NaN    0.364560   \n",
      "677  -0.403273  0.239903  0.119952  -0.415407  0.166275  4.0   -0.334632   \n",
      "476   0.395190  0.470306  0.470306        NaN       NaN  NaN    0.395190   \n",
      "445   0.566381  0.120557  0.060279   0.574234  0.049415  4.0    0.416893   \n",
      "1428  0.881913  0.111213  0.055606   0.893542  0.032783  4.0    0.548248   \n",
      "\n",
      "     variant  \n",
      "1649     P7D  \n",
      "1885    K15G  \n",
      "199     Q28C  \n",
      "360     R69L  \n",
      "95       A5V  \n",
      "1998    H97P  \n",
      "677     K38D  \n",
      "476     S30Q  \n",
      "445     R62I  \n",
      "1428    V89C  \n"
     ]
    }
   ],
   "source": [
    "print(modifier_1_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e80a4209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting variant list if there are multiple mutations\n",
    "modifier_1_mut = modifier_1_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "modifier_1_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(modifier_1_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "modifier_1_df[\"MUTATED_RES\"] = ssf.get_mutation_type(modifier_1_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "modifier_1_df[\"POSITION\"] = ssf.get_position(modifier_1_mut)\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "modifier_1_df[\"variant\"] = ssf.get_mutations_names_list(modifier_1_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "# to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]\n",
    "\n",
    "# pab1_df = pab1_df.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7d223264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepti\\OneDrive\\UW\\GitHub\\secondary-structure-CNN-learning\\Jupyter Notebooks\\secStrucFormatting.py:591: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  in_domain_df = in_domain_df.append(rows, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# getting training and test datasets\n",
    "\n",
    "# get ss position indexes\n",
    "path = \"../PDB and STRIDE Files/\" + 'modifier_1_stride_confident.txt'\n",
    "modifier_1_stride_file = open(path, 'r')\n",
    "\n",
    "modifier_1_ss_indexes = ssf.get_all_sec_struc_boolean(modifier_1_stride_file) # boolean list of secondary structure assignements\n",
    "\n",
    "# need positionssplit\n",
    "modifier_1_df[\"positions_split\"] = ssf.get_positions_split(modifier_1_df)\n",
    "\n",
    "# add in_sec_str_col\n",
    "modifier_1_df = ssf.get_domain_dataset_v2(modifier_1_df, 18, 99, [-99])\n",
    "modifier_1_df = add_sec_str_col(modifier_1_df, modifier_1_ss_indexes, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c862a8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(modifier_1_ss_indexes.count(True))\n",
    "print(modifier_1_ss_indexes.count(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "50d00664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len1539\n",
      "166\n",
      "32\n",
      "Train Data Fraction: 0.838\n",
      "false_df len247\n",
      "true_df len1292\n",
      "in fraction,df len1341\n",
      "Test Data Fraction: 0.84\n",
      "false_df len215\n",
      "true_df len1126\n",
      "Size of Test Dataset: 1337\n",
      "Size of Total Dataset: 1535\n",
      "1535\n",
      "Filename: modifier_1_MLformat_198_train_1337_test_turns3.txt\n"
     ]
    }
   ],
   "source": [
    "modifier_1_train_df, modifier_1_test_df, modifier_1_remaining_df = get_train_and_test_df(modifier_1_df, 0.84, 198)\n",
    "# print(\"TEST LEN\")\n",
    "# print(len(modifier_1_test_df))\n",
    "modifier_1_df_format = pd.concat([modifier_1_train_df, modifier_1_test_df])\n",
    "print(len(modifier_1_df_format))\n",
    "# writing data to txt file\n",
    "ssf.write_data_file(\"modifier_1_MLformat_198_train_1337_test_turns3\", protein_seq_modifier_1, modifier_1_df_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6633d640",
   "metadata": {},
   "source": [
    "**TAR DNA-binding protein 43**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "84b5a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_df_pt1 = pd.read_csv(\"../Raw Data/tar1_mod.csv\")\n",
    "tar_df_pt2 = pd.read_csv(\"../Raw Data/tar2_mod.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f3dfe075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704\n",
      "714\n"
     ]
    }
   ],
   "source": [
    "print(len(tar_df_pt1))\n",
    "print(len(tar_df_pt2))\n",
    "# tar_df_pt1 = tar_df_pt1.sample(frac=1)\n",
    "# tar_df_pt2 = tar_df_pt2.sample(frac=1)\n",
    "# print(tar_df_pt1.head(30))\n",
    "# print(tar_df_pt2.head(30))\n",
    "# tar_df1 = pd.concat([tar_df_pt1, tar_df_pt2])\n",
    "# print(len(tar_df1))\n",
    "\n",
    "# print(tar_df1.columns)\n",
    "\n",
    "tar_df_pt1 = tar_df_pt1[(tar_df_pt1[\"hgvs_pro\"].str.contains(\"\\*\") == False) & (tar_df_pt1[\"hgvs_pro\"].str.contains(\"hgvs\") == False)\n",
    "                    & (tar_df_pt1[\"hgvs_pro\"].str.contains(\"Ter\") == False)]\n",
    "\n",
    "tar_df_pt2 = tar_df_pt2[(tar_df_pt2[\"hgvs_pro\"].str.contains(\"\\*\") == False) & (tar_df_pt2[\"hgvs_pro\"].str.contains(\"hgvs\") == False)\n",
    "                    & (tar_df_pt2[\"hgvs_pro\"].str.contains(\"Ter\") == False)]\n",
    "\n",
    "# print(len(tar_df))\n",
    "# # shuffle values\n",
    "# tar_df = tar_df.sample(frac=1)\n",
    "# print(tar_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "151d17a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MET SER GLU TYR ILE ARG VAL THR GLU ASP GLU ASN ASP GLU PRO ILE GLU ILE PRO SER GLU ASP ASP GLY THR VAL LEU LEU SER THR VAL THR ALA GLN PHE PRO GLY ALA CYS GLY LEU ARG TYR ARG ASN PRO VAL SER GLN CYS MET ARG GLY VAL ARG LEU VAL GLU GLY ILE LEU HIS ALA PRO ASP ALA GLY TRP GLY ASN LEU VAL TYR VAL VAL ASN TYR PRO LYS ASP ASN LYS ARG LYS MET ASP GLU THR ASP ALA SER SER ALA VAL LYS VAL LYS ARG ALA VAL GLN LYS THR SER ASP LEU ILE VAL LEU GLY LEU PRO TRP LYS THR THR GLU GLN ASP LEU LYS GLU TYR PHE SER THR PHE GLY GLU VAL LEU MET VAL GLN VAL LYS LYS ASP LEU LYS THR GLY HIS SER LYS GLY PHE GLY PHE VAL ARG PHE THR GLU TYR GLU THR GLN VAL LYS VAL MET SER GLN ARG HIS MET ILE ASP GLY ARG TRP CYS ASP CYS LYS LEU PRO ASN SER LYS GLN SER GLN ASP GLU PRO LEU ARG SER ARG LYS VAL PHE VAL GLY ARG CYS THR GLU ASP MET THR GLU ASP GLU LEU ARG GLU PHE PHE SER GLN TYR GLY ASP VAL MET ASP VAL PHE ILE PRO LYS PRO PHE ARG ALA PHE ALA PHE VAL THR PHE ALA ASP ASP GLN ILE ALA GLN SER LEU CYS GLY GLU ASP LEU ILE ILE LYS GLY ILE SER VAL HIS ILE SER ASN ALA GLU PRO LYS HIS ASN SER ASN ARG GLN LEU GLU ARG SER GLY ARG PHE GLY GLY ASN PRO GLY GLY PHE GLY ASN GLN GLY GLY PHE GLY ASN SER ARG GLY GLY GLY ALA GLY LEU GLY ASN ASN GLN GLY SER ASN MET GLY GLY GLY MET ASN PHE GLY ALA PHE SER ILE ASN PRO ALA MET MET ALA ALA ALA GLN ALA ALA LEU GLN SER SER TRP GLY MET MET GLY MET LEU ALA SER GLN GLN ASN GLN SER GLY PRO SER GLY ASN ASN GLN ASN GLN GLY ASN MET GLN ARG GLU PRO ASN GLN ALA PHE GLY SER GLY ASN ASN SER TYR SER GLY SER ASN SER GLY ALA ALA ILE GLY TRP GLY SER ALA SER ASN ALA GLY SER GLY SER GLY PHE ASN GLY GLY PHE GLY SER SER MET ASP SER LYS SER SER GLY TRP GLY MET\n"
     ]
    }
   ],
   "source": [
    "# getting uniprot to compare offset\n",
    "protein_seq_tar = ssf.get_protein_seq(\"Q13148\")\n",
    "print(protein_seq_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6e259c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SER\n"
     ]
    }
   ],
   "source": [
    "protein_seq_tar_split = protein_seq_tar.split()\n",
    "print(protein_seq_tar_split[291]) # for the first one starts at 289 (add offset of )\n",
    "# row 10, col 11, 31 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8cb3861e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SER\n"
     ]
    }
   ],
   "source": [
    "print(protein_seq_tar_split[346]) \n",
    "# row 12, 6, 31 <- 16 starts at 346: 1 starts at 331?\n",
    "# have to offset seperately and then add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6daf0cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_df_pt1[\"variant\"] = format_mavedb_variant(tar_df_pt1, \"hgvs_pro\", 288)\n",
    "tar_df_pt2[\"variant\"] = format_mavedb_variant(tar_df_pt2, \"hgvs_pro\", 330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "82f582f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1342\n"
     ]
    }
   ],
   "source": [
    "tar_df = pd.concat([tar_df_pt1, tar_df_pt2])\n",
    "tar_df = tar_df.sample(frac=1)\n",
    "print(len(tar_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9bc8c8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting variant list if there are multiple mutations\n",
    "tar_mut = tar_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "tar_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(tar_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "tar_df[\"MUTATED_RES\"] = ssf.get_mutation_type(tar_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "tar_df[\"POSITION\"] = ssf.get_position(tar_mut)\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "tar_df[\"variant\"] = ssf.get_mutations_names_list(tar_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "# to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]\n",
    "\n",
    "# pab1_df = pab1_df.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "aae89db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting training and test datasets\n",
    "\n",
    "# get ss position indexes\n",
    "path = \"../PDB and STRIDE Files/\" + 'tar_stride.txt'\n",
    "tar_stride_file = open(path, 'r')\n",
    "\n",
    "tar_ss_indexes = ssf.get_sec_struc_boolean(tar_stride_file) # boolean list of secondary structure assignements\n",
    "\n",
    "# need positionssplit\n",
    "tar_df[\"positions_split\"] = ssf.get_positions_split(tar_df)\n",
    "\n",
    "# add in_sec_str_col\n",
    "tar_df = add_sec_str_col(tar_df, tar_ss_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8557752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tar_train_df, tar_test_df, tar_remaining_df = get_train_and_test_df(tar_df, 0.36, 812)\n",
    "# print(len(tar_test_df))\n",
    "# tar_df_format = pd.concat([tar_train_df, tar_test_df])\n",
    "\n",
    "# # writing data to txt file\n",
    "# # ssf.write_data_file(\"tar_MLformat_812_train_10k_test_1\", protein_seq_tar, tar_df_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b040f6e3",
   "metadata": {},
   "source": [
    "# Human Glucokinase? (Adding Noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "0097d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "glucokinase_df1 = pd.read_csv(\"../Raw Data/glucokinase_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "53c43b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['# Accession: urn:mavedb:00000096-a-1', 'Unnamed: 1', 'Unnamed: 2',\n",
      "       'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(glucokinase_df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2cf06f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['accession', 'hgvs_nt', 'hgvs_splice', 'hgvs_pro', 'score', 'sd', 'df',\n",
      "       'se'],\n",
      "      dtype='object', name=3)\n",
      "9366\n",
      "8570\n"
     ]
    }
   ],
   "source": [
    "# take note of offset\n",
    "\n",
    "glucokinase_df1.columns = glucokinase_df1.iloc[3]\n",
    "print(glucokinase_df1.columns)\n",
    "print(len(glucokinase_df1))\n",
    "\n",
    "\n",
    "glucokinase_df = glucokinase_df1[(glucokinase_df1[\"hgvs_pro\"].str.contains(\"del\") == False) & (glucokinase_df1[\"hgvs_pro\"].str.contains(\"hgvs\") == False)\n",
    "                   & (glucokinase_df1[\"hgvs_pro\"].str.contains(\"Ter\") == False)]\n",
    "\n",
    "glucokinase_df = glucokinase_df1[(glucokinase_df1[\"hgvs_pro\"].str.contains(\"=\") == False) & (glucokinase_df1[\"hgvs_pro\"].str.contains(\"hgvs\") == False)\n",
    "                   & (glucokinase_df1[\"hgvs_pro\"].str.contains(\"Ter\") == False)]\n",
    "\n",
    "glucokinase_df = glucokinase_df.sample(frac=1)\n",
    "\n",
    "print(len(glucokinase_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "15d566af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MET LEU ASP ASP ARG ALA ARG MET GLU ALA ALA LYS LYS GLU LYS VAL GLU GLN ILE LEU ALA GLU PHE GLN LEU GLN GLU GLU ASP LEU LYS LYS VAL MET ARG ARG MET GLN LYS GLU MET ASP ARG GLY LEU ARG LEU GLU THR HIS GLU GLU ALA SER VAL LYS MET LEU PRO THR TYR VAL ARG SER THR PRO GLU GLY SER GLU VAL GLY ASP PHE LEU SER LEU ASP LEU GLY GLY THR ASN PHE ARG VAL MET LEU VAL LYS VAL GLY GLU GLY GLU GLU GLY GLN TRP SER VAL LYS THR LYS HIS GLN MET TYR SER ILE PRO GLU ASP ALA MET THR GLY THR ALA GLU MET LEU PHE ASP TYR ILE SER GLU CYS ILE SER ASP PHE LEU ASP LYS HIS GLN MET LYS HIS LYS LYS LEU PRO LEU GLY PHE THR PHE SER PHE PRO VAL ARG HIS GLU ASP ILE ASP LYS GLY ILE LEU LEU ASN TRP THR LYS GLY PHE LYS ALA SER GLY ALA GLU GLY ASN ASN VAL VAL GLY LEU LEU ARG ASP ALA ILE LYS ARG ARG GLY ASP PHE GLU MET ASP VAL VAL ALA MET VAL ASN ASP THR VAL ALA THR MET ILE SER CYS TYR TYR GLU ASP HIS GLN CYS GLU VAL GLY MET ILE VAL GLY THR GLY CYS ASN ALA CYS TYR MET GLU GLU MET GLN ASN VAL GLU LEU VAL GLU GLY ASP GLU GLY ARG MET CYS VAL ASN THR GLU TRP GLY ALA PHE GLY ASP SER GLY GLU LEU ASP GLU PHE LEU LEU GLU TYR ASP ARG LEU VAL ASP GLU SER SER ALA ASN PRO GLY GLN GLN LEU TYR GLU LYS LEU ILE GLY GLY LYS TYR MET GLY GLU LEU VAL ARG LEU VAL LEU LEU ARG LEU VAL ASP GLU ASN LEU LEU PHE HIS GLY GLU ALA SER GLU GLN LEU ARG THR ARG GLY ALA PHE GLU THR ARG PHE VAL SER GLN VAL GLU SER ASP THR GLY ASP ARG LYS GLN ILE TYR ASN ILE LEU SER THR LEU GLY LEU ARG PRO SER THR THR ASP CYS ASP ILE VAL ARG ARG ALA CYS GLU SER VAL SER THR ARG ALA ALA HIS MET CYS SER ALA GLY LEU ALA GLY VAL ILE ASN ARG MET ARG GLU SER ARG SER GLU ASP VAL MET ARG ILE THR VAL GLY VAL ASP GLY SER VAL TYR LYS LEU HIS PRO SER PHE LYS GLU ARG PHE HIS ALA SER VAL ARG ARG LEU THR PRO SER CYS GLU ILE THR PHE ILE GLU SER GLU GLU GLY SER GLY ARG GLY ALA ALA LEU VAL SER ALA VAL ALA CYS LYS LYS ALA CYS MET LEU GLY GLN\n",
      "1859\n"
     ]
    }
   ],
   "source": [
    "# getting uniprot to compare offset\n",
    "protein_seq_glucokinase = ssf.get_protein_seq(\"P35557\")\n",
    "# offset of 1\n",
    "print(protein_seq_glucokinase)\n",
    "print(len(protein_seq_glucokinase))\n",
    "# protein_seq_glucokinase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bdc8249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein_seq_glucokinase_split = protein_seq_glucokinase.split()\n",
    "# print(len(protein_seq_glucokinase_split))\n",
    "# protein_seq_glucokinase = protein_seq_glucokinase[:-4]\n",
    "# print(protein_seq_glucokinase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "91dcd567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8570\n"
     ]
    }
   ],
   "source": [
    "glucokinase_df[\"variant\"] = format_mavedb_variant(glucokinase_df, \"hgvs_pro\", -1)\n",
    "print(len(glucokinase_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "18b80d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting variant list if there are multiple mutations\n",
    "glucokinase_mut = glucokinase_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "glucokinase_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(glucokinase_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "glucokinase_df[\"MUTATED_RES\"] = ssf.get_mutation_type(glucokinase_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "glucokinase_df[\"POSITION\"] = ssf.get_position(glucokinase_mut)\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "glucokinase_df[\"variant\"] = ssf.get_mutations_names_list(glucokinase_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c5188f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "320\n",
      "8535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepti\\OneDrive\\UW\\GitHub\\secondary-structure-CNN-learning\\Jupyter Notebooks\\secStrucFormatting.py:591: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  in_domain_df = in_domain_df.append(rows, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# getting training and test datasets\n",
    "\n",
    "# get ss position indexes\n",
    "path = \"../PDB and STRIDE Files/\" + 'glucokinase_stride_confident.txt'\n",
    "glucokinase_stride_file = open(path, 'r')\n",
    "\n",
    "glucokinase_ss_indexes = ssf.get_sec_struc_boolean(glucokinase_stride_file) # boolean list of secondary structure assignements\n",
    "print(glucokinase_ss_indexes.count(False))\n",
    "print(glucokinase_ss_indexes.count(True))\n",
    "\n",
    "# need positionssplit\n",
    "glucokinase_df[\"positions_split\"] = ssf.get_positions_split(glucokinase_df)\n",
    "glucokinase_df = ssf.get_domain_dataset_v2(glucokinase_df, 0, 463, [])\n",
    "print(len(glucokinase_df))\n",
    "\n",
    "# add in_sec_str_col\n",
    "glucokinase_df = add_sec_str_col(glucokinase_df, glucokinase_ss_indexes, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "98d9bd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3                        accession hgvs_nt hgvs_splice     hgvs_pro  \\\n",
      "0     urn:mavedb:00000096-a-1#9098     NaN         NaN  p.Ala232Lys   \n",
      "1     urn:mavedb:00000096-a-1#6698     NaN         NaN  p.Cys382Ala   \n",
      "2     urn:mavedb:00000096-a-1#7241     NaN         NaN   p.Gln24Ala   \n",
      "3      urn:mavedb:00000096-a-1#853     NaN         NaN   p.Thr65Glu   \n",
      "4     urn:mavedb:00000096-a-1#5020     NaN         NaN  p.Gly343Arg   \n",
      "...                            ...     ...         ...          ...   \n",
      "8530  urn:mavedb:00000096-a-1#1912     NaN         NaN  p.Ser426Met   \n",
      "8531  urn:mavedb:00000096-a-1#3472     NaN         NaN  p.Lys459Tyr   \n",
      "8532  urn:mavedb:00000096-a-1#6974     NaN         NaN  p.Asp409Met   \n",
      "8533  urn:mavedb:00000096-a-1#7522     NaN         NaN  p.Asp247Trp   \n",
      "8534   urn:mavedb:00000096-a-1#939     NaN         NaN   p.Thr49Gly   \n",
      "\n",
      "3            score           sd df           se variant WILD_TYPE_RES  \\\n",
      "0     -0.272247725  0.499682549  2  0.353328919  231LYS             A   \n",
      "1      1.128744689  0.257378164  4  0.128689082  381ALA             C   \n",
      "2       0.90998005  0.555044397  4  0.277522198   23ALA             Q   \n",
      "3      0.332541403  0.424709432  2  0.300314919   64GLU             T   \n",
      "4      0.207961053  0.678824603  6  0.277128984  342ARG             G   \n",
      "...            ...          ... ..          ...     ...           ...   \n",
      "8530   1.095851794  0.174930429  2  0.123694493  425MET             S   \n",
      "8531   1.818580421   0.10236177  2  0.072380702  458TYR             K   \n",
      "8532   0.020247534  0.130750836  2  0.092454803  408MET             D   \n",
      "8533    0.62326504  0.056969675  2  0.040283643  246TRP             D   \n",
      "8534    1.58145045   0.73261296  4   0.36630648   48GLY             T   \n",
      "\n",
      "3    MUTATED_RES POSITION positions_split  in_sec_str  has_sec_str  \n",
      "0              K      231           [231]        True         True  \n",
      "1              A      381           [381]        True         True  \n",
      "2              A       23            [23]       False        False  \n",
      "3              E       64            [64]       False        False  \n",
      "4              R      342           [342]       False        False  \n",
      "...          ...      ...             ...         ...          ...  \n",
      "8530           M      425           [425]        True         True  \n",
      "8531           Y      458           [458]        True         True  \n",
      "8532           M      408           [408]        True         True  \n",
      "8533           W      246           [246]       False        False  \n",
      "8534           G       48            [48]       False        False  \n",
      "\n",
      "[8535 rows x 15 columns]\n",
      "5865\n",
      "2670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_17412\\1097654771.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sec_str_df = sec_str_df.append(rows, ignore_index=True)\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_17412\\4042603016.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  not_sec_str_df = not_sec_str_df.append(rows, ignore_index=True)\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_17412\\501139114.py:8: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  glucokinase_no_mixed_pos_df = pd.concat([glucokinase_only_ss_df, glucokinase_only_not_ss_df])\n"
     ]
    }
   ],
   "source": [
    "# # need positionssplit\n",
    "# glucokinase_df[\"positions_split\"] = ssf.get_positions_split(glucokinase_df)\n",
    "\n",
    "glucokinase_only_ss_df = get_ss_dataset(glucokinase_df, glucokinase_ss_indexes, 0)\n",
    "print(len(glucokinase_only_ss_df))\n",
    "glucokinase_only_not_ss_df = get_not_ss_dataset(glucokinase_df, glucokinase_ss_indexes, 0)\n",
    "print(len(glucokinase_only_not_ss_df))\n",
    "glucokinase_no_mixed_pos_df = pd.concat([glucokinase_only_ss_df, glucokinase_only_not_ss_df])\n",
    "\n",
    "# add in_sec_str_col\n",
    "glucokinase_no_mixed_pos_df = add_sec_str_col(glucokinase_no_mixed_pos_df, glucokinase_ss_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3f142c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8535\n",
      "8535\n"
     ]
    }
   ],
   "source": [
    "# shuffling data\n",
    "glucokinase_no_mixed_pos_df = glucokinase_no_mixed_pos_df.sample(frac=1)\n",
    "print(len(glucokinase_no_mixed_pos_df))\n",
    "glucokinase_no_mixed_pos_df = glucokinase_no_mixed_pos_df.dropna(subset=[\"score\"])\n",
    "print(len(glucokinase_no_mixed_pos_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fd0610ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     2000\n",
      "False    2000\n",
      "Name: in_sec_str, dtype: int64\n",
      "True     500\n",
      "False    500\n",
      "Name: in_sec_str, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# getting training set (5k in ss, 5k not in ss)\n",
    "glucokinase_train_ss = glucokinase_no_mixed_pos_df[glucokinase_no_mixed_pos_df['in_sec_str'] == True].sample(2000)\n",
    "glucokinase_train_not_ss = glucokinase_no_mixed_pos_df[glucokinase_no_mixed_pos_df['in_sec_str'] == False].sample(2000)\n",
    "glucokinase_train_df = pd.concat([glucokinase_train_ss, glucokinase_train_not_ss])\n",
    "\n",
    "glucokinase_test_ss = glucokinase_no_mixed_pos_df[glucokinase_no_mixed_pos_df['in_sec_str'] == True].sample(500)\n",
    "glucokinase_test_not_ss = glucokinase_no_mixed_pos_df[glucokinase_no_mixed_pos_df['in_sec_str'] == False].sample(500)\n",
    "glucokinase_test_df = pd.concat([glucokinase_test_ss, glucokinase_test_not_ss])\n",
    "\n",
    "# getting test set (2.5k in ss, 2.5k not in ss)\n",
    "print(glucokinase_train_df['in_sec_str'].value_counts())\n",
    "print(glucokinase_test_df['in_sec_str'].value_counts())\n",
    "\n",
    "glucokinase_train_df[\"score\"] = glucokinase_train_ss[\"score\"].astype(float)\n",
    "glucokinase_test_df[\"score\"] = glucokinase_test_ss[\"score\"].astype(float)\n",
    "\n",
    "glucokinase_train_df = glucokinase_train_df.dropna(subset = [\"score\", \"variant\"])\n",
    "glucokinase_test_df = glucokinase_test_df.dropna(subset = [\"score\", \"variant\"])\n",
    "\n",
    "\n",
    "# # cast to float\n",
    "# new_float_scores_train = []\n",
    "# for x in glucokinase_train_ss[\"score\"]:\n",
    "#     x_float = float(x)\n",
    "#     new_float_scores_train.append(x_float)\n",
    "    \n",
    "# glucokinase_train_ss[\"score\"] = new_float_scores_train\n",
    "    \n",
    "# new_float_scores_test = []\n",
    "# for x in glucokinase_test_not_ss[\"score\"]:\n",
    "#     x_float = float(x)\n",
    "#     new_float_scores_test.append(x_float)\n",
    "    \n",
    "# glucokinase_test_not_ss[\"score\"] = new_float_scores_test\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7969da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(glucokinase_train_ss.columns)\n",
    "# print(type(glucokinase_train_ss[\"score\"].iloc[0]))\n",
    "# print(glucokinase_train_df[\"score\"])\n",
    "\n",
    "# for val in glucokinase_train_df[\"score\"]:\n",
    "#     if type(val) == str:\n",
    "#         print(val)\n",
    "#         print(\"problem\")\n",
    "#     else:\n",
    "#         print(\"not problem\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "36774404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Standard Deviation: 1.3483178563016196\n",
      "Dataset Mean: 0.6644973974530596\n",
      "Dataset Median: 0.561735664\n",
      "Kurtosis: 7.398595944119408\n",
      "1248   -0.238918\n",
      "2910    0.066074\n",
      "3312    2.515454\n",
      "2372    0.802195\n",
      "5307    0.752648\n",
      "3662    0.080216\n",
      "1331    1.301941\n",
      "4112    0.642198\n",
      "5569   -0.282153\n",
      "4185    0.142465\n",
      "Name: score, dtype: float64\n",
      "1248    10.876222\n",
      "2910     1.189809\n",
      "3312     0.514827\n",
      "2372     1.801962\n",
      "5307     1.888411\n",
      "3662    -1.106385\n",
      "1331    -3.478624\n",
      "4112     9.224042\n",
      "5569    -0.000408\n",
      "4185    -2.000411\n",
      "Name: score, dtype: float64\n",
      "1248   -0.238918\n",
      "2910    0.066074\n",
      "3312    2.515454\n",
      "2372    0.802195\n",
      "5307    0.752648\n",
      "3662    0.080216\n",
      "1331    1.301941\n",
      "4112    0.642198\n",
      "5569   -0.282153\n",
      "4185    0.142465\n",
      "Name: score, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_17412\\1853856707.py:38: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(unchanged_scores[0:10])\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_17412\\1853856707.py:40: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(ss_scores[0:10])\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_17412\\1853856707.py:42: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(not_ss_scores[0:10])\n"
     ]
    }
   ],
   "source": [
    "# adding noise to values from uniform distribution and creating files\n",
    "\n",
    "# finding standard deviation of dataset scores\n",
    "# list_train = list(glucokinase_train_df['score'])\n",
    "# print(list)\n",
    "std = glucokinase_train_df['score'].std()\n",
    "mean = glucokinase_train_df['score'].mean()\n",
    "median = glucokinase_train_df['score'].median()\n",
    "print(\"Dataset Standard Deviation: \" + str(std))\n",
    "print(\"Dataset Mean: \" + str(mean))\n",
    "print(\"Dataset Median: \" + str(median))\n",
    "print(\"Kurtosis: \" + str(kurtosis(glucokinase_train_df['score'], fisher=False)))\n",
    "\n",
    "# finding number of ss and not ss values\n",
    "num_ss_vals = (glucokinase_train_df.in_sec_str == True).sum()\n",
    "num_not_ss_vals = (glucokinase_train_df.in_sec_str == False).sum()\n",
    "\n",
    "# creating noise (std not the exact same, but similar) // 0 is the mean of the normal distribution\n",
    "noise_ss = np.random.normal(0, std * 3, num_ss_vals).tolist()\n",
    "noise_ss_v2 = noise_ss.copy()\n",
    "noise_not_ss = np.random.normal(0, std * 3, num_not_ss_vals).tolist()\n",
    "\n",
    "# filling in values for not ss indexes in noise_ss\n",
    "bool_ss_list = glucokinase_train_df.in_sec_str.values.tolist()\n",
    "\n",
    "noise_ss_to_add = []\n",
    "noise_not_ss_to_add = []\n",
    "\n",
    "for ss_assign in bool_ss_list:\n",
    "    if ss_assign: # if true (ss index)\n",
    "        noise_ss_to_add.append(noise_ss.pop(0))\n",
    "        noise_not_ss_to_add.append(0)\n",
    "    else: # if false (not ss index)\n",
    "        noise_ss_to_add.append(0)\n",
    "        noise_not_ss_to_add.append(noise_not_ss.pop(0))\n",
    "        \n",
    "unchanged_scores = glucokinase_train_df['score']\n",
    "print(unchanged_scores[0:10])\n",
    "ss_scores = glucokinase_train_df['score'] + noise_ss_to_add\n",
    "print(ss_scores[0:10])\n",
    "not_ss_scores = glucokinase_train_df['score'] + noise_not_ss_to_add\n",
    "print(not_ss_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "38e1a425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0400298755442101\n",
      "\n",
      "2.989093577462081\n",
      "Percentage Change: 187.40458786320883\n",
      "1.5371111664991761\n",
      "Percentage Change: 47.7949049968263\n"
     ]
    }
   ],
   "source": [
    "abs_val_list = [abs(x) for x in glucokinase_train_df['score']]\n",
    "mean = sum(abs_val_list) / len(abs_val_list)\n",
    "print(mean)\n",
    "print()\n",
    "\n",
    "abs_ss_val_list = [abs(x) for x in ss_scores]\n",
    "mean_ss = sum(abs_ss_val_list) / len(abs_ss_val_list)\n",
    "print(mean_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_ss - mean) / mean) * 100))\n",
    "\n",
    "abs_not_ss_val_list = [abs(x) for x in not_ss_scores]\n",
    "mean_not_ss = sum(abs_not_ss_val_list) / len(abs_not_ss_val_list)\n",
    "print(mean_not_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_not_ss - mean) / mean) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "3362a5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: glucokinase_MLformat_2000_train_500_no_noise_t2_v2.txt\n",
      "Filename: glucokinase_MLformat_2000_train_500_ss_noise_t2_v2.txt\n",
      "Filename: glucokinase_MLformat_2000_train_500_not_ss_noise_t2_v2.txt\n"
     ]
    }
   ],
   "source": [
    "# creating files (NO NOISE for test values)\n",
    "\n",
    "# unchanged\n",
    "glucokinase_train_df['score'] = unchanged_scores\n",
    "glucokinase_full_df = pd.concat([glucokinase_train_df, glucokinase_test_df])\n",
    "ssf.write_data_file(\"glucokinase_MLformat_2000_train_500_no_noise_t2_v2\", protein_seq_glucokinase, glucokinase_full_df)\n",
    "\n",
    "# ss\n",
    "glucokinase_train_df['score'] = ss_scores\n",
    "glucokinase_full_df = pd.concat([glucokinase_train_df, glucokinase_test_df])\n",
    "ssf.write_data_file(\"glucokinase_MLformat_2000_train_500_ss_noise_t2_v2\", protein_seq_glucokinase, glucokinase_full_df)\n",
    "\n",
    "# not ss\n",
    "glucokinase_train_df['score'] = not_ss_scores\n",
    "glucokinase_full_df = pd.concat([glucokinase_train_df, glucokinase_test_df])\n",
    "ssf.write_data_file(\"glucokinase_MLformat_2000_train_500_not_ss_noise_t2_v2\", protein_seq_glucokinase, glucokinase_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cd1b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f238b9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len8570\n",
      "629\n",
      "283\n",
      "Train Data Fraction: 0.69\n",
      "false_df len2686\n",
      "true_df len5884\n",
      "in fraction,df len7658\n",
      "Test Data Fraction: 0.69\n",
      "false_df len2403\n",
      "true_df len5255\n",
      "Size of Test Dataset: 7612\n",
      "Size of Total Dataset: 8524\n",
      "8524\n",
      "Filename: glucokinase_MLformat_912_train_7612_test_3.txt\n"
     ]
    }
   ],
   "source": [
    "glucokinase_train_df, glucokinase_test_df, glucokinase_remaining_df = get_train_and_test_df(glucokinase_df, 0.69, 912)\n",
    "glucokinase_df_format = pd.concat([glucokinase_train_df, glucokinase_test_df])\n",
    "print(len(glucokinase_df_format))\n",
    "# writing data to txt file\n",
    "ssf.write_data_file(\"glucokinase_MLformat_912_train_7612_test_3\", protein_seq_glucokinase, glucokinase_df_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76987982",
   "metadata": {},
   "source": [
    "## Getting Dataset Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ad4ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds boolean column to dataframe to indicate whether value is in secondary structure\n",
    "# needs positions split column\n",
    "def add_sec_str_col(df, bool_ss_list, domain_start_index):\n",
    "    has_sec_str = []\n",
    "    for val in df[\"positions_split\"]:\n",
    "        # list of boolean values that are true if all mutation positions in line are sec. strc.\n",
    "        all_pos_sec_struc = []\n",
    "\n",
    "        for position in val:\n",
    "            # print(position)\n",
    "            if (bool_ss_list[position - domain_start_index] == False):  # line up ss_indexes w/ position\n",
    "                all_pos_sec_struc.append(False)\n",
    "            else:\n",
    "                all_pos_sec_struc.append(True)\n",
    "\n",
    "        # all pos sec struc should match val list\n",
    "        # if there's a value in all_pos_sec_struc that's false, append false\n",
    "        # otherwise, append true\n",
    "        if (all_pos_sec_struc.count(False) == 0):\n",
    "            has_only_sec_str = True\n",
    "        else:\n",
    "            has_only_sec_str = False\n",
    "\n",
    "        has_sec_str.append(has_only_sec_str)\n",
    "        all_pos_sec_struc.clear()\n",
    "\n",
    "    # print(len(has_sec_str)) # should match dataframe length\n",
    "    df['in_sec_str'] = has_sec_str\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bacad755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fractioned_dataset(df_orig, fraction_ss, size):\n",
    "    df = df_orig.copy()\n",
    "    print(\"in fraction,df len\" + str(len(df)))\n",
    "    print(\"num ss orig\" + str(len(df[df[\"in_sec_str\"] == True])))\n",
    "    print(\"num not ss orig\" + str(len(df[df[\"in_sec_str\"] == False])))\n",
    "    if (size is not None): # need training dataset size\n",
    "        num_in_ss = int(size*fraction_ss) \n",
    "        print(\"num_in_ss\" + str(num_in_ss))\n",
    "        num_not_ss = size - num_in_ss\n",
    "        print(\"num_not_ss\" + str(num_not_ss))\n",
    "        real_fraction = round(float(num_in_ss)/(num_in_ss+num_not_ss), 3)\n",
    "        print(\"Train Data Fraction: \" + str(real_fraction))\n",
    "    else: # need test dataset and size of dataset doesn't matter\n",
    "        num_in_ss, num_not_ss = get_num_ss(df, fraction_ss)\n",
    "        real_fraction = round(float(num_in_ss)/(num_in_ss+num_not_ss), 3)\n",
    "        print(\"Test Data Fraction: \" + str(real_fraction))\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    ss_df = df[df[\"in_sec_str\"] == True].sample(num_in_ss)\n",
    "    print(\"len of ss_df = \" + str(len(ss_df)))\n",
    "    df = df.drop(ss_df.index)\n",
    "    not_ss_df = df[df[\"in_sec_str\"] == False].sample(num_not_ss)\n",
    "    print(\"len of notss_df = \" + str(len(not_ss_df)))\n",
    "    df = df.drop(not_ss_df.index)\n",
    "    \n",
    "    fractioned_df = pd.concat([ss_df, not_ss_df])\n",
    "    \n",
    "#     remaining_df = pd.concat([fractioned_df, df])\n",
    "#     remaining_df_copy = remaining_df.copy()\n",
    "#     print(\"len of remaining_df not removing dups\" + str(len(remaining_df)))\n",
    "#     # remaining_df = remaining_df[~remaining_df.index.duplicated(keep=False)]\n",
    "#     # remaining_df.drop_duplicates(keep=False, inplace=True) doesn't work\n",
    "#     remaining_df = remaining_df.iloc[remaining_df_copy.astype(str).drop_duplicates(keep=False, subset=['POSITION', 'score', 'variant']).index]\n",
    "#     print(\"ss of remaining dups\" + str(len(remaining_df[remaining_df[\"in_sec_str\"] == True])))\n",
    "#     print(\"not ss of remaining dups\" + str(len(remaining_df[remaining_df[\"in_sec_str\"] == False])))\n",
    "#     print(\"removing dups\" + str(len(remaining_df)))\n",
    "    print(\"ss of remaining dups\" + str(len(df[df[\"in_sec_str\"] == True])))\n",
    "    print(\"not ss of remaining dups\" + str(len(df[df[\"in_sec_str\"] == False])))\n",
    "    \n",
    "    return fractioned_df.sample(frac=1), df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03b9e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_ss(df, fraction_ss): # use when size is dependent on remaining values\n",
    "    # print(\"enters this method\")\n",
    "    num_ss_vals = (df[\"in_sec_str\"] == True).sum() # number of trues to work from \n",
    "    print(\"here is where im printing the nums\")\n",
    "    print(num_ss_vals)\n",
    "    num_not_ss_vals = (df[\"in_sec_str\"] == False).sum() # number of falses to work from \n",
    "    print(num_not_ss_vals)\n",
    "    if (num_not_ss_vals < num_ss_vals): # if not in ss is limiting factor\n",
    "        ideal_split_ss = int((num_not_ss_vals/(1-fraction_ss))*fraction_ss)\n",
    "        ideal_split_not_ss = int(num_not_ss_vals)\n",
    "        # instead do min value, max value and fraction it is\n",
    "    else:\n",
    "        ideal_split_ss = int(num_ss_vals)\n",
    "        ideal_split_not_ss = int((num_ss_vals/fraction_ss)*(1-fraction_ss))\n",
    "    total = ideal_split_ss + ideal_split_not_ss\n",
    "    # print(\"ideal_ss: \" + str(ideal_split_ss))\n",
    "    # print(\"ideal_not_ss: \" + str(ideal_split_not_ss))\n",
    "    while (ideal_split_ss >= num_ss_vals or ideal_split_not_ss >= num_not_ss_vals):\n",
    "        # until thei)y both fit the total number of values\n",
    "        if (ideal_split_ss < ideal_split_not_ss):\n",
    "            ideal_split_ss = ideal_split_ss - 1\n",
    "            ideal_split_not_ss = (ideal_split_ss/fraction_ss)*(1-fraction_ss)\n",
    "        else:\n",
    "            ideal_split_not_ss = ideal_split_not_ss - 1\n",
    "            ideal_split_ss = (ideal_split_not_ss/(1-fraction_ss))*(fraction_ss)\n",
    "        ideal_split_ss = int(ideal_split_ss)\n",
    "        ideal_split_not_ss = int(ideal_split_not_ss)\n",
    "        # total = ideal_split_ss + ideal_split_not_ss\n",
    "        # print(\"total: \" + str(total))\n",
    "        # print(total % batch_size != 0)\n",
    "        # print(ideal_split_ss >= num_ss_vals)\n",
    "        # print(ideal_split_not_ss >= num_not_ss_vals)\n",
    "        #print((ideal_split_ss >= num_ss_vals or ideal_split_not_ss >= num_not_ss_vals))\n",
    "    return int(ideal_split_ss), int(ideal_split_not_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9db33590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets both train and test datasets based on size\n",
    "# fraction_ss is a percent (e.g. 0.56)\n",
    "\n",
    "# need \"is_sec_struc_col\"\n",
    "# reutrns remaining df\n",
    "def get_train_and_test_df(df, fraction_ss, train_size):\n",
    "    train_df, remaining_df = get_fractioned_dataset(df, fraction_ss, train_size)\n",
    "    print(\"first round is fine\")\n",
    "    print(\"len train and remaining\")\n",
    "    print(len(train_df))\n",
    "    print(len(remaining_df))\n",
    "    test_df, remaining_df_2 = get_fractioned_dataset(remaining_df, fraction_ss, None)\n",
    "    print(\"second round is fine\")\n",
    "    print(\"Size of Test Dataset: \" + str(len(test_df)))\n",
    "    print(\"Size of Total Dataset: \" + str(len(test_df)+ len(train_df)))\n",
    "    return train_df, test_df, remaining_df_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48a4e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_trainset(train_df, remaining_df, fraction_ss, size):\n",
    "    if (size > len(remaining_df)):\n",
    "        print(\"Not enough training values, combining old values\")\n",
    "        df = pd.concat([train_df, remaining_df])\n",
    "        # print(\"enters wrong block\")     \n",
    "    else:\n",
    "        # print(\"enters right block\")\n",
    "        df = remaining_df\n",
    "        print(\"remaing df len\" + str(len(df)))\n",
    "    new_train_df, new_remaining_df = get_fractioned_dataset(df, fraction_ss, size)\n",
    "    return new_train_df, new_remaining_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ebb159",
   "metadata": {},
   "source": [
    "## Cleaning Gelman et al. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b802034",
   "metadata": {},
   "source": [
    "## Ube4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "aa423a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98297\n",
      "Index(['variant', 'num_mutations', 'score'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# importing Ube4b data from Gelman et al.\n",
    "ube4b_df1 = pd.read_csv(\"../Raw Data/ube4b.tsv.txt\", sep=\"\\t\")\n",
    "ube4b_df = ube4b_df1.dropna()\n",
    "print(len(ube4b_df))\n",
    "print(ube4b_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4a7a3198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91031\n",
      "91031\n"
     ]
    }
   ],
   "source": [
    "# rounding score column to 6 decimal points\n",
    "ube4b_df[\"score\"] = ube4b_df[\"score\"].round(6)\n",
    "\n",
    "# remove values with wildcard star next to them\n",
    "ube4b_df = ube4b_df[ube4b_df[\"variant\"].str.contains(\"\\*\") == False]\n",
    "print(len(ube4b_df))\n",
    "ube4b_df = ube4b_df.sample(frac=1)\n",
    "# change this value depending on amount of data needed for dataset\n",
    "# ube4b_df = ube4b_df.sample(n=80)\n",
    "print(len(ube4b_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7d2fc1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n"
     ]
    }
   ],
   "source": [
    "# # get protein sequence from Uniprot and split\n",
    "# # protein_seq_ube4b = ssf.get_protein_seq(\"Q9ES00\")\n",
    "# protein_seq_ube4b_split = protein_seq_ube4b.split()\n",
    "# print(len(protein_seq_ube4b_split)) # protein length of 1173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8a214d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "ILE GLU LYS PHE LYS LEU LEU ALA GLU LYS VAL GLU GLU ILE VAL ALA LYS ASN ALA ARG ALA GLU ILE ASP TYR SER ASP ALA PRO ASP GLU PHE ARG ASP PRO LEU MET ASP THR LEU MET THR ASP PRO VAL ARG LEU PRO SER GLY THR VAL MET ASP ARG SER ILE ILE LEU ARG HIS LEU LEU ASN SER PRO THR ASP PRO PHE ASN ARG GLN MET LEU THR GLU SER MET LEU GLU PRO VAL PRO GLU LEU LYS GLU GLN ILE GLN ALA TRP MET ARG GLU LYS GLN SER SER ASP HIS\n"
     ]
    }
   ],
   "source": [
    "# ube4b protein domain sequence from Gelman et. al\n",
    "string_seq = \"IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLNSPTDPFNRQMLTESMLEPVPELKEQIQAWMREKQSSDH\"\n",
    "print(len(string_seq)) # <- domain length of 102\n",
    "protein_seq_ube4b = ssf.get_expanded_seq(string_seq)\n",
    "print(protein_seq_ube4b)\n",
    "# protein_seq_ube4b = protein_seq_ube4b.split()\n",
    "\n",
    "# NOTE - index in list corresponds exactly to location in domain (huh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ff4c2265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of domain inside protein\n",
    "# ssf.get_index_range(protein_seq_ube4b_split, ube4b_domain_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "397f7057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting variant list if there are multiple mutations\n",
    "ube4b_mut = ube4b_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "ube4b_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(ube4b_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "ube4b_df[\"MUTATED_RES\"] = ssf.get_mutation_type(ube4b_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "ube4b_df[\"POSITION\"] = ssf.get_position(ube4b_mut)\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "ube4b_df[\"variant\"] = ssf.get_mutations_names_list(ube4b_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "# to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]\n",
    "\n",
    "#  ube4b_df = ube4b_df.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "26a9ede4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# get ss position indexes\n",
    "path = \"../PDB and STRIDE Files/\" + 'ube4b_stride.txt'\n",
    "ube4b_stride_file = open(path, 'r')\n",
    "\n",
    "ube4b_ss_indexes = ssf.get_all_sec_struc_boolean(ube4b_stride_file)\n",
    "print(ube4b_ss_indexes.count(True))\n",
    "print(ube4b_ss_indexes.count(False))\n",
    "\n",
    "# need positionssplit\n",
    "ube4b_df[\"positions_split\"] = ssf.get_positions_split(ube4b_df)\n",
    "\n",
    "# add in_sec_str_col\n",
    "ube4b_df = add_sec_str_col(ube4b_df, ube4b_ss_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52f1fe1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91031\n"
     ]
    }
   ],
   "source": [
    "print(len(ube4b_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "887363e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ube4b_remaining' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20876/3702259411.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mube4b_train_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mube4b_test_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mube4b_remaining_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_train_and_test_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mube4b_remaining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.52\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ube4b_remaining' is not defined"
     ]
    }
   ],
   "source": [
    "ube4b_train_df, ube4b_test_df, ube4b_remaining_df = get_train_and_test_df(ube4b_remaining, 0.52, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21ee6306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len91031\n",
      "104\n",
      "96\n",
      "Train Data Fraction: 0.52\n",
      "false_df len76653\n",
      "true_df len14378\n",
      "in fraction,df len90831\n",
      "Test Data Fraction: 0.52\n",
      "false_df len76557\n",
      "true_df len14274\n",
      "Size of Test Dataset: 27447\n",
      "Size of Total Dataset: 27647\n"
     ]
    }
   ],
   "source": [
    "ube4b_train_df, ube4b_test_df, ube4b_remaining_df = get_train_and_test_df(ube4b_df, 0.52, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f6c9bd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len91031\n",
      "182\n",
      "18\n",
      "Train Data Fraction: 0.91\n",
      "false_df len23348\n",
      "true_df len67683\n",
      "in fraction,df len90831\n",
      "Test Data Fraction: 0.91\n",
      "false_df len23330\n",
      "true_df len67501\n",
      "Size of Test Dataset: 74166\n",
      "Size of Total Dataset: 74366\n",
      "in fraction,df len74166\n",
      "51870\n",
      "5130\n",
      "Train Data Fraction: 0.91\n",
      "false_df len6675\n",
      "true_df len67491\n",
      "in fraction,df len17166\n",
      "Test Data Fraction: 0.91\n",
      "false_df len1545\n",
      "true_df len15621\n",
      "Size of Test Dataset: 17155\n",
      "Size of Total Dataset: 74155\n",
      "SMALL TEST\n",
      "17155\n",
      "17355\n",
      "Filename: ube4b_MLformat_200_train_17155_test_t3.txt\n"
     ]
    }
   ],
   "source": [
    "ube4b_train_df, ube4b_test_df, ube4b_remaining_df = get_train_and_test_df(ube4b_df, 0.91, 200)\n",
    "ube4b_train_dummy, ube4b_small_test_df, ube4b_remaining_df = get_train_and_test_df(ube4b_test_df, 0.91, 57000)\n",
    "print(\"SMALL TEST\")\n",
    "print(len(ube4b_small_test_df))\n",
    "ube4b_df_format = pd.concat([ube4b_train_df, ube4b_small_test_df])\n",
    "print(len(ube4b_df_format))\n",
    "ssf.write_data_file(\"ube4b_MLformat_200_train_17155_test_t3\", protein_seq_ube4b, ube4b_df_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d3e5b5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len27447\n",
      "7280\n",
      "6720\n",
      "Train Data Fraction: 0.52\n",
      "false_df len13175\n",
      "true_df len14272\n",
      "in fraction,df len13447\n",
      "Test Data Fraction: 0.52\n",
      "false_df len6455\n",
      "true_df len6992\n",
      "Size of Test Dataset: 13445\n",
      "Size of Total Dataset: 27445\n",
      "13645\n",
      "Filename: ube4b_MLformat_200_train_13445_test_t3.txt\n"
     ]
    }
   ],
   "source": [
    "# making test set smaller\n",
    "ube4b_dummy_df, ube4b_small_test_df, ube4b_remaining_df = get_train_and_test_df(ube4b_test_df, 0.52, 14000)\n",
    "ube4b_df_format = pd.concat([ube4b_train_df, ube4b_small_test_df])\n",
    "print(len(ube4b_df_format))\n",
    "ssf.write_data_file(\"ube4b_MLformat_200_train_13445_test_t3\", protein_seq_ube4b, ube4b_df_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3fb5e98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len27447\n",
      "7280\n",
      "6720\n",
      "Train Data Fraction: 0.52\n",
      "false_df len13175\n",
      "true_df len14272\n",
      "in fraction,df len13447\n",
      "Test Data Fraction: 0.52\n",
      "false_df len6455\n",
      "true_df len6992\n",
      "Size of Test Dataset: 13445\n",
      "Size of Total Dataset: 27445\n",
      "13645\n",
      "Filename: ube4b_MLformat_200_train_13445_test_t2.txt\n"
     ]
    }
   ],
   "source": [
    "# making test set smaller\n",
    "ube4b_dummy_df_2, ube4b_small_test_df_2, ube4b_remaining_df_2 = get_train_and_test_df(ube4b_test_df, 0.52, 14000)\n",
    "ube4b_df_format_2 = pd.concat([ube4b_train_df_2, ube4b_small_test_df_2])\n",
    "print(len(ube4b_df_format_2))\n",
    "ssf.write_data_file(\"ube4b_MLformat_200_train_13445_test_t2\", protein_seq_ube4b, ube4b_df_format_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "77ded24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len27447\n",
      "7280\n",
      "6720\n",
      "Train Data Fraction: 0.52\n",
      "false_df len13175\n",
      "true_df len14272\n",
      "in fraction,df len13447\n",
      "Test Data Fraction: 0.52\n",
      "false_df len6455\n",
      "true_df len6992\n",
      "Size of Test Dataset: 13445\n",
      "Size of Total Dataset: 27445\n",
      "13645\n",
      "Filename: ube4b_MLformat_200_train_13445_test_t3.txt\n"
     ]
    }
   ],
   "source": [
    "# making test set smaller\n",
    "ube4b_dummy_df_3, ube4b_small_test_df_3, ube4b_remaining_df_3 = get_train_and_test_df(ube4b_test_df, 0.52, 14000)\n",
    "ube4b_df_format_3 = pd.concat([ube4b_train_df_3, ube4b_small_test_df_3])\n",
    "print(len(ube4b_df_format_3))\n",
    "ssf.write_data_file(\"ube4b_MLformat_200_train_13445_test_t3\", protein_seq_ube4b, ube4b_df_format_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0d8b1da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "27447\n",
      "200\n",
      "27447\n",
      "200\n",
      "27447\n"
     ]
    }
   ],
   "source": [
    "print(len(ube4b_train_df))\n",
    "print(len(ube4b_test_df))\n",
    "print(len(ube4b_train_df_2))\n",
    "print(len(ube4b_test_df_2))\n",
    "print(len(ube4b_train_df_3))\n",
    "print(len(ube4b_test_df_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7784fd",
   "metadata": {},
   "source": [
    "# Adding Noise to Ube4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bbce60f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91031\n"
     ]
    }
   ],
   "source": [
    "# importing and formatting data (25737 usable vals)\n",
    "ube4b_df1 = pd.read_csv(\"../Raw Data/ube4b.tsv.txt\", sep=\"\\t\")\n",
    "ube4b_df = ube4b_df1.dropna()\n",
    "\n",
    "# rounding score column to 6 decimal points\n",
    "ube4b_df[\"score\"] = ube4b_df[\"score\"].round(6)\n",
    "\n",
    "# remove values with wildcard star next to them\n",
    "ube4b_df = ube4b_df[ube4b_df[\"variant\"].str.contains(\"\\*\") == False]\n",
    "\n",
    "# splitting variant list if there are multiple mutations\n",
    "ube4b_mut = ube4b_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "ube4b_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(ube4b_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "ube4b_df[\"MUTATED_RES\"] = ssf.get_mutation_type(ube4b_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "ube4b_df[\"POSITION\"] = ssf.get_position(ube4b_mut)\n",
    "\n",
    "ube4b_df[\"positions_split\"] = ssf.get_positions_split(ube4b_df)\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "ube4b_df[\"variant\"] = ssf.get_mutations_names_list(ube4b_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]\n",
    "\n",
    "print(len(ube4b_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "97f8d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# secondary structure assignments\n",
    "path = \"../PDB and STRIDE Files/\" + 'ube4b_stride.txt'\n",
    "ube4b_stride_file = open(path, 'r')\n",
    "\n",
    "ube4b_ss_indexes = ssf.get_sec_struc_boolean(ube4b_stride_file) # not including turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b25c7d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need positionssplit\n",
    "ube4b_df[\"positions_split\"] = ssf.get_positions_split(ube4b_df)\n",
    "\n",
    "# ube4b_only_ss_df = get_ss_dataset(ube4b_df, ube4b_ss_indexes, 0)\n",
    "# ube4b_only_not_ss_df = get_not_ss_dataset(ube4b_df, ube4b_ss_indexes, 0)\n",
    "# ube4b_no_mixed_pos_df = pd.concat([ube4b_only_ss_df, ube4b_only_not_ss_df])\n",
    "\n",
    "# add in_sec_str_col\n",
    "# ube4b_no_mixed_pos_df = add_sec_str_col(ube4b_no_mixed_pos_df, ube4b_ss_indexes, 0)\n",
    "ube4b_no_mixed_pos_df = ube4b_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a3efb707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91031\n",
      "91031\n"
     ]
    }
   ],
   "source": [
    "print(len(ube4b_df))\n",
    "print(len(ube4b_no_mixed_pos_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bb7263fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling data\n",
    "ube4b_no_mixed_pos_df = ube4b_no_mixed_pos_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8b6f2ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein sequence\n",
    "string_seq = \"IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLNSPTDPFNRQMLTESMLEPVPELKEQIQAWMREKQSSDH\"\n",
    "protein_seq_ube4b = ssf.get_expanded_seq(string_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "71d05207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     365\n",
      "False    365\n",
      "Name: in_sec_str, dtype: int64\n",
      "True     73\n",
      "False    73\n",
      "Name: in_sec_str, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# getting training set (5k in ss, 5k not in ss)\n",
    "# ube4b_train_ss = ube4b_no_mixed_pos_df[ube4b_no_mixed_pos_df['in_sec_str'] == True].sample(365)\n",
    "# ube4b_train_not_ss = ube4b_no_mixed_pos_df[ube4b_no_mixed_pos_df['in_sec_str'] == False].sample(365)\n",
    "# ube4b_train_df = pd.concat([ube4b_train_ss, ube4b_train_not_ss])\n",
    "\n",
    "# ube4b_test_ss = ube4b_no_mixed_pos_df[ube4b_no_mixed_pos_df['in_sec_str'] == True].sample(73)\n",
    "# ube4b_test_not_ss = ube4b_no_mixed_pos_df[ube4b_no_mixed_pos_df['in_sec_str'] == False].sample(73)\n",
    "# ube4b_test_df = pd.concat([ube4b_test_ss, ube4b_test_not_ss])\n",
    "\n",
    "# getting test set (2.5k in ss, 2.5k not in ss)\n",
    "print(ube4b_train_df['in_sec_str'].value_counts())\n",
    "print(ube4b_test_df['in_sec_str'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "941d6a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # getting dataset with correct ratios (only using training dataset)\n",
    "# ube4b_train_df, ube4b_test_df_1, ube4b_remaining_df = get_train_and_test_df(ube4b_no_mixed_pos_df, 0.52, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "19401a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ube4b_test_df, ube4b_dummy, ube4b_remaining_df_1 = get_train_and_test_df(ube4b_test_df_1, 0.52, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "747337a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Standard Deviation: 1.9813523347311117\n",
      "Dataset Mean: -1.1617138780821916\n",
      "Dataset Median: -1.0104435\n",
      "Kurtosis: 3.513099299890523\n",
      "2581     0.395233\n",
      "3511     0.050008\n",
      "4740    -0.320974\n",
      "11658   -2.780406\n",
      "9802    -1.887321\n",
      "4320    -0.206331\n",
      "12005   -3.450257\n",
      "12580   -3.450257\n",
      "13478   -4.298254\n",
      "1699     0.891571\n",
      "Name: score, dtype: float64\n",
      "2581     13.251656\n",
      "3511      4.502488\n",
      "4740     12.172355\n",
      "11658     5.389155\n",
      "9802     -5.749450\n",
      "4320     -9.669734\n",
      "12005    -3.924908\n",
      "12580    -9.066239\n",
      "13478    -9.298264\n",
      "1699      4.777121\n",
      "Name: score, dtype: float64\n",
      "2581     0.395233\n",
      "3511     0.050008\n",
      "4740    -0.320974\n",
      "11658   -2.780406\n",
      "9802    -1.887321\n",
      "4320    -0.206331\n",
      "12005   -3.450257\n",
      "12580   -3.450257\n",
      "13478   -4.298254\n",
      "1699     0.891571\n",
      "Name: score, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_10732\\737844189.py:36: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(unchanged_scores[0:10])\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_10732\\737844189.py:38: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(ss_scores[0:10])\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_10732\\737844189.py:40: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(not_ss_scores[0:10])\n"
     ]
    }
   ],
   "source": [
    "# adding noise to values from uniform distribution and creating files\n",
    "\n",
    "# finding standard deviation of dataset scores\n",
    "std = ube4b_train_df['score'].std()\n",
    "mean = ube4b_train_df['score'].mean()\n",
    "median = ube4b_train_df['score'].median()\n",
    "print(\"Dataset Standard Deviation: \" + str(std))\n",
    "print(\"Dataset Mean: \" + str(mean))\n",
    "print(\"Dataset Median: \" + str(median))\n",
    "print(\"Kurtosis: \" + str(kurtosis(ube4b_train_df['score'], fisher=False)))\n",
    "\n",
    "# finding number of ss and not ss values\n",
    "num_ss_vals = (ube4b_train_df.in_sec_str == True).sum()\n",
    "num_not_ss_vals = (ube4b_train_df.in_sec_str == False).sum()\n",
    "\n",
    "# creating noise (std not the exact same, but similar) // 0 is the mean of the normal distribution\n",
    "noise_ss = np.random.normal(0, std * 3, num_ss_vals).tolist()\n",
    "noise_ss_v2 = noise_ss.copy()\n",
    "noise_not_ss = np.random.normal(0, std * 3, num_not_ss_vals).tolist()\n",
    "\n",
    "# filling in values for not ss indexes in noise_ss\n",
    "bool_ss_list = ube4b_train_df.in_sec_str.values.tolist()\n",
    "\n",
    "noise_ss_to_add = []\n",
    "noise_not_ss_to_add = []\n",
    "\n",
    "for ss_assign in bool_ss_list:\n",
    "    if ss_assign: # if true (ss index)\n",
    "        noise_ss_to_add.append(noise_ss.pop(0))\n",
    "        noise_not_ss_to_add.append(0)\n",
    "    else: # if false (not ss index)\n",
    "        noise_ss_to_add.append(0)\n",
    "        noise_not_ss_to_add.append(noise_not_ss.pop(0))\n",
    "        \n",
    "unchanged_scores = ube4b_train_df['score']\n",
    "print(unchanged_scores[0:10])\n",
    "ss_scores = ube4b_train_df['score'] + noise_ss_to_add\n",
    "print(ss_scores[0:10])\n",
    "not_ss_scores = ube4b_train_df['score'] + noise_not_ss_to_add\n",
    "print(not_ss_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "df002909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7788946589041088\n",
      "\n",
      "3.4980660028642583\n",
      "Percentage Change: 96.6426727605809\n",
      "3.4610782609863415\n",
      "Percentage Change: 94.56341856231919\n"
     ]
    }
   ],
   "source": [
    "abs_val_list = [abs(x) for x in ube4b_train_df['score']]\n",
    "mean = sum(abs_val_list) / len(abs_val_list)\n",
    "print(mean)\n",
    "print()\n",
    "\n",
    "abs_ss_val_list = [abs(x) for x in ss_scores]\n",
    "mean_ss = sum(abs_ss_val_list) / len(abs_ss_val_list)\n",
    "print(mean_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_ss - mean) / mean) * 100))\n",
    "\n",
    "abs_not_ss_val_list = [abs(x) for x in not_ss_scores]\n",
    "mean_not_ss = sum(abs_not_ss_val_list) / len(abs_not_ss_val_list)\n",
    "print(mean_not_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_not_ss - mean) / mean) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbcfa4c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: ube4b_trainbatch_train_23_test_6_t3.txt\n"
     ]
    }
   ],
   "source": [
    "# creating files (NO NOISE for test values)\n",
    "\n",
    "# unchanged\n",
    "# ube4b_train_df['score'] = unchanged_scores\n",
    "# ube4b_full_df = pd.concat([ube4b_train_df, ube4b_test_df])\n",
    "ube4b_full_df = ube4b_no_mixed_pos_df.sample(29)\n",
    "ssf.write_data_file(\"ube4b_trainbatch_train_23_test_6_t3\", protein_seq_ube4b, ube4b_full_df)\n",
    "\n",
    "# # ss\n",
    "# ube4b_train_df['score'] = ss_scores\n",
    "# ube4b_full_df = pd.concat([ube4b_train_df, ube4b_test_df])\n",
    "# ssf.write_data_file(\"ube4b_MLformat_10000_train_5000_ss_noise_t2_v2\", protein_seq_ube4b, ube4b_full_df)\n",
    "\n",
    "# # not ss\n",
    "# ube4b_train_df['score'] = not_ss_scores\n",
    "# ube4b_full_df = pd.concat([ube4b_train_df, ube4b_test_df])\n",
    "# ssf.write_data_file(\"ube4b_MLformat_10000_train_5000_not_ss_noise_t2_v2\", protein_seq_ube4b, ube4b_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "83374abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: ube4b_trainbatch_train_23_test_3642_t3.txt\n"
     ]
    }
   ],
   "source": [
    "ube4b_full_df = ube4b_no_mixed_pos_df.sample(3665)\n",
    "ssf.write_data_file(\"ube4b_trainbatch_train_23_test_3642_t3\", protein_seq_ube4b, ube4b_full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4df64ab",
   "metadata": {},
   "source": [
    "#### Pab1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7ff40dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40852\n",
      "Index(['variant', 'num_mutations', 'score'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# importing pab1 data from Gelman et al.\n",
    "pab1_df1 = pd.read_csv(\"../Raw Data/pab1.tsv.txt\", sep=\"\\t\")\n",
    "pab1_df = pab1_df1.dropna()\n",
    "print(len(pab1_df))\n",
    "print(pab1_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "27937955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40852\n",
      "37710\n",
      "37710\n"
     ]
    }
   ],
   "source": [
    "# rounding score column to 6 decimal points\n",
    "pab1_df[\"score\"] = pab1_df[\"score\"].round(6)\n",
    "print(len(pab1_df))\n",
    "\n",
    "# remove values with wildcard star next to them\n",
    "pab1_df = pab1_df[pab1_df[\"variant\"].str.contains(\"\\*\") == False]\n",
    "print(len(pab1_df))\n",
    "# change this value depending on amount of data needed for dataset\n",
    "# pab1_df = pab1_df.sample(n=10000)\n",
    "print(len(pab1_df))\n",
    "pab1_df = pab1_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cf82cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting variant list if there are multiple mutations\n",
    "pab1_mut = pab1_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "pab1_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(pab1_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "pab1_df[\"MUTATED_RES\"] = ssf.get_mutation_type(pab1_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "pab1_df[\"POSITION\"] = ssf.get_position(pab1_mut)\n",
    "pab1_df[\"positions_split\"] = ssf.get_positions_split(pab1_df)\n",
    "\n",
    "positions_split_subtracted = []\n",
    "for pos_list in pab1_df[\"positions_split\"]:\n",
    "    pos_list = [x - 126 for x in pos_list]\n",
    "    positions_split_subtracted.append(pos_list)  \n",
    "\n",
    "pab1_df[\"positions_split\"] = positions_split_subtracted    \n",
    "    \n",
    "new_positions = []\n",
    "pos_string = \"\"\n",
    "for pos_list in pab1_df[\"positions_split\"]:\n",
    "    pos_string = \",\".join(map(str, pos_list))\n",
    "    # print(pos_string)\n",
    "    new_positions.append(pos_string)\n",
    "    pos_string = \"\"\n",
    "# print(len(new_positions))\n",
    "# print(len(pab1_df[\"POSITION\"]))\n",
    "\n",
    "pab1_df[\"POSITION\"] = new_positions # changes positions into new adjusted values (0 index)\n",
    "# replace variant column with reformatted variant name\n",
    "pab1_df[\"variant\"] = ssf.get_mutations_names_list(pab1_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]\n",
    "\n",
    "# pab1_df = pab1_df.drop(columns=to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cbbe441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37710\n"
     ]
    }
   ],
   "source": [
    "print(len(pab1_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cd9228bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../PDB and STRIDE Files/\" + 'pab1_stride.txt'\n",
    "pab1_stride_file = open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f4d70a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pab1_ss_indexes = ssf.get_all_sec_struc_boolean(pab1_stride_file) # boolean list of secondary structure assignements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "73cc1093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column\n",
    "\n",
    "pab1_df = add_sec_str_col(pab1_df, pab1_ss_indexes, 0)\n",
    "# need positionssplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a7d64e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['variant', 'num_mutations', 'score', 'WILD_TYPE_RES', 'MUTATED_RES',\n",
      "       'POSITION', 'positions_split', 'in_sec_str'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(pab1_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9e94e118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLY ASN ILE PHE ILE LYS ASN LEU HIS PRO ASP ILE ASP ASN LYS ALA LEU TYR ASP THR PHE SER VAL PHE GLY ASP ILE LEU SER SER LYS ILE ALA THR ASP GLU ASN GLY LYS SER LYS GLY PHE GLY PHE VAL HIS PHE GLU GLU GLU GLY ALA ALA LYS GLU ALA ILE ASP ALA LEU ASN GLY MET LEU LEU ASN GLY GLN GLU ILE TYR VAL ALA PRO\n"
     ]
    }
   ],
   "source": [
    "string_seq_pab1 = \"GNIFIKNLHPDIDNKALYDTFSVFGDILSSKIATDENGKSKGFGFVHFEEEGAAKEAIDALNGMLLNGQEIYVAP\"\n",
    "protein_seq_pab1 = ssf.get_expanded_seq(string_seq_pab1)\n",
    "print(protein_seq_pab1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ee412b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len37710\n",
      "133\n",
      "14\n",
      "Train Data Fraction: 0.905\n",
      "false_df len6264\n",
      "true_df len31446\n",
      "in fraction,df len37563\n",
      "Test Data Fraction: 0.91\n",
      "false_df len6250\n",
      "true_df len31313\n",
      "Size of Test Dataset: 34400\n",
      "Size of Total Dataset: 34547\n",
      "34547\n"
     ]
    }
   ],
   "source": [
    "pab1_train_df, pab1_test_df, pab1_remaining_df = get_train_and_test_df(pab1_df, 0.91, 147)\n",
    "pab1_df_format = pd.concat([pab1_train_df, pab1_test_df])\n",
    "print(len(pab1_df_format))\n",
    "# ssf.write_data_file(\"pab1_MLformat_147_train_20054_test_t3\", protein_seq_pab1, pab1_df_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a8002422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len37710\n",
      "182\n",
      "18\n",
      "Train Data Fraction: 0.91\n",
      "false_df len6264\n",
      "true_df len31446\n",
      "in fraction,df len37510\n",
      "Test Data Fraction: 0.91\n",
      "false_df len6246\n",
      "true_df len31264\n",
      "Size of Test Dataset: 34355\n",
      "Size of Total Dataset: 34555\n",
      "in fraction,df len34355\n",
      "18200\n",
      "1800\n",
      "Train Data Fraction: 0.91\n",
      "false_df len3092\n",
      "true_df len31263\n",
      "in fraction,df len14355\n",
      "Test Data Fraction: 0.91\n",
      "false_df len1292\n",
      "true_df len13063\n",
      "Size of Test Dataset: 14344\n",
      "Size of Total Dataset: 34344\n",
      "SMALL TEST\n",
      "14344\n",
      "14544\n",
      "Filename: pab1_MLformat_200_train_14344_test_t3.txt\n"
     ]
    }
   ],
   "source": [
    "pab1_train_df, pab1_test_df, pab1_remaining_df = get_train_and_test_df(pab1_df, 0.91, 147)\n",
    "pab1_train_dummy, pab1_small_test_df, pab1_remaining_df = get_train_and_test_df(pab1_test_df, 0.91, 20000)\n",
    "print(\"SMALL TEST\")\n",
    "print(len(pab1_small_test_df))\n",
    "pab1_df_format = pd.concat([pab1_train_df, pab1_small_test_df])\n",
    "print(len(pab1_df_format))\n",
    "ssf.write_data_file(\"pab1_MLformat_200_train_14344_test_t3\", protein_seq_pab1, pab1_df_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef390cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len37710\n",
      "101\n",
      "46\n",
      "Train Data Fraction: 0.687\n",
      "false_df len19683\n",
      "true_df len18027\n",
      "in fraction,df len37563\n",
      "Test Data Fraction: 0.69\n",
      "false_df len19637\n",
      "true_df len17926\n",
      "Size of Test Dataset: 25974\n",
      "Size of Total Dataset: 26121\n",
      "26121\n",
      "Filename: pab1_MLformat_147_train_25974_test_t2.txt\n"
     ]
    }
   ],
   "source": [
    "pab1_train_df_2, pab1_test_df_2, pab1_remaining_df_2 = get_train_and_test_df(pab1_df, 0.69, 147)\n",
    "pab1_df_format_2 = pd.concat([pab1_train_df_2, pab1_test_df_2])\n",
    "print(len(pab1_df_format_2))\n",
    "ssf.write_data_file(\"pab1_MLformat_147_train_25974_test_t2\", protein_seq_pab1, pab1_df_format_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ca678428",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len37710\n",
      "101\n",
      "46\n",
      "Train Data Fraction: 0.687\n",
      "false_df len19683\n",
      "true_df len18027\n",
      "in fraction,df len37563\n",
      "Test Data Fraction: 0.69\n",
      "false_df len19637\n",
      "true_df len17926\n",
      "Size of Test Dataset: 25974\n",
      "Size of Total Dataset: 26121\n",
      "26121\n",
      "Filename: pab1_MLformat_147_train_25974_test_t3.txt\n"
     ]
    }
   ],
   "source": [
    "pab1_train_df_3, pab1_test_df_3, pab1_remaining_df_3 = get_train_and_test_df(pab1_df, 0.69, 147)\n",
    "pab1_df_format_3 = pd.concat([pab1_train_df_3, pab1_test_df_3])\n",
    "print(len(pab1_df_format_3))\n",
    "ssf.write_data_file(\"pab1_MLformat_147_train_25974_test_t3\", protein_seq_pab1, pab1_df_format_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af84cacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n",
      "25974\n",
      "147\n",
      "25974\n",
      "147\n",
      "25974\n"
     ]
    }
   ],
   "source": [
    "print(len(pab1_train_df))\n",
    "print(len(pab1_test_df))\n",
    "print(len(pab1_train_df_2))\n",
    "print(len(pab1_test_df_2))\n",
    "print(len(pab1_train_df_3))\n",
    "print(len(pab1_test_df_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c0a78df4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len37710\n",
      "101\n",
      "46\n",
      "Train Data Fraction: 0.687\n",
      "false_df len19683\n",
      "true_df len18027\n",
      "in fraction,df len37563\n",
      "Test Data Fraction: 0.69\n",
      "false_df len19637\n",
      "true_df len17926\n",
      "Size of Test Dataset: 25974\n",
      "Size of Total Dataset: 26121\n",
      "10147\n",
      "Filename: pab1_MLformat_147_train_25974_test_t1.txt\n"
     ]
    }
   ],
   "source": [
    "# pab1_train_df, pab1_test_df, pab1_remaining_df = get_train_and_test_df(pab1_df, 0.69, 147)\n",
    "# pab1_test_10000 = pab1_test_df.head(10000)\n",
    "# pab1_df_format = pd.concat([pab1_train_df, pab1_test_10000])\n",
    "# print(len(pab1_df_format))\n",
    "# # writing data to txt file\n",
    "# ssf.write_data_file(\"pab1_MLformat_147_train_25974_test_t1\", protein_seq_pab1, pab1_df_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab15e3b",
   "metadata": {},
   "source": [
    "# Adding Noise to Pab1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78c0b46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37710\n"
     ]
    }
   ],
   "source": [
    "# importing and formatting data (25737 usable vals)\n",
    "pab1_df1 = pd.read_csv(\"../Raw Data/pab1.tsv.txt\", sep=\"\\t\")\n",
    "pab1_df = pab1_df1.dropna()\n",
    "\n",
    "# rounding score column to 6 decimal points\n",
    "pab1_df[\"score\"] = pab1_df[\"score\"].round(6)\n",
    "\n",
    "# remove values with wildcard star next to them\n",
    "pab1_df = pab1_df[pab1_df[\"variant\"].str.contains(\"\\*\") == False]\n",
    "\n",
    "# splitting variant list if there are multiple mutations\n",
    "pab1_mut = pab1_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "pab1_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(pab1_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "pab1_df[\"MUTATED_RES\"] = ssf.get_mutation_type(pab1_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "pab1_df[\"POSITION\"] = ssf.get_position(pab1_mut)\n",
    "pab1_df[\"positions_split\"] = ssf.get_positions_split(pab1_df)\n",
    "\n",
    "positions_split_subtracted = []\n",
    "for pos_list in pab1_df[\"positions_split\"]:\n",
    "    pos_list = [x - 126 for x in pos_list]\n",
    "    positions_split_subtracted.append(pos_list)  \n",
    "\n",
    "pab1_df[\"positions_split\"] = positions_split_subtracted    \n",
    "    \n",
    "new_positions = []\n",
    "pos_string = \"\"\n",
    "for pos_list in pab1_df[\"positions_split\"]:\n",
    "    pos_string = \",\".join(map(str, pos_list))\n",
    "    # print(pos_string)\n",
    "    new_positions.append(pos_string)\n",
    "    pos_string = \"\"\n",
    "# print(len(new_positions))\n",
    "# print(len(pab1_df[\"POSITION\"]))\n",
    "\n",
    "pab1_df[\"POSITION\"] = new_positions # changes positions into new adjusted values (0 index)\n",
    "# replace variant column with reformatted variant name\n",
    "pab1_df[\"variant\"] = ssf.get_mutations_names_list(pab1_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]\n",
    "\n",
    "print(len(pab1_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff931fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# secondary structure assignments\n",
    "path = \"../PDB and STRIDE Files/\" + 'pab1_stride.txt'\n",
    "pab1_stride_file = open(path, 'r')\n",
    "\n",
    "pab1_ss_indexes = ssf.get_sec_struc_boolean(pab1_stride_file) # not including turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06c66bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # need positionssplit\n",
    "# pab1_df[\"positions_split\"] = ssf.get_positions_split(pab1_df)\n",
    "\n",
    "# # add in_sec_str_col\n",
    "# pab1_df = add_sec_str_col(pab1_df, pab1_ss_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3537bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling data\n",
    "pab1_df = pab1_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "295cff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein sequence\n",
    "string_seq_pab1 = \"GNIFIKNLHPDIDNKALYDTFSVFGDILSSKIATDENGKSKGFGFVHFEEEGAAKEAIDALNGMLLNGQEIYVAP\"\n",
    "protein_seq_pab1 = ssf.get_expanded_seq(string_seq_pab1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84008af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # getting dataset with correct ratios (only using training dataset)\n",
    "# pab1_train_df, pab1_test_df_1, pab1_remaining_df = get_train_and_test_df(pab1_df, 0.69, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "add132f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pab1_train_df_2, pab1_test_df, pab1_remaining_df_1 = get_train_and_test_df(pab1_test_df_1, 0.69, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0106ffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need positionssplit\n",
    "pab1_df[\"positions_split\"] = ssf.get_positions_split(pab1_df)\n",
    "\n",
    "# pab1_only_ss_df = get_ss_dataset(pab1_df, pab1_ss_indexes, 0)\n",
    "# pab1_only_not_ss_df = get_not_ss_dataset(pab1_df, pab1_ss_indexes, 0)\n",
    "# pab1_no_mixed_pos_df = pd.concat([pab1_only_ss_df, pab1_only_not_ss_df])\n",
    "\n",
    "pab1_no_mixed_pos_df = pab1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b55a7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37710\n",
      "37710\n"
     ]
    }
   ],
   "source": [
    "print(len(pab1_df))\n",
    "print(len(pab1_no_mixed_pos_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e6ee520a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    19683\n",
      "True     18027\n",
      "Name: in_sec_str, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pab1_no_mixed_pos_df = add_sec_str_col(pab1_no_mixed_pos_df, pab1_ss_indexes, 0)\n",
    "print(pab1_no_mixed_pos_df['in_sec_str'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "195357dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37710\n"
     ]
    }
   ],
   "source": [
    "# shuffling data\n",
    "pab1_no_mixed_pos_df = pab1_no_mixed_pos_df.sample(frac=1)\n",
    "print(len(pab1_no_mixed_pos_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fd683ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     161\n",
      "False    161\n",
      "Name: in_sec_str, dtype: int64\n",
      "True     32\n",
      "False    32\n",
      "Name: in_sec_str, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# getting training set (5k in ss, 5k not in ss)\n",
    "pab1_train_ss = pab1_no_mixed_pos_df[pab1_no_mixed_pos_df['in_sec_str'] == True].sample(161)\n",
    "pab1_train_not_ss = pab1_no_mixed_pos_df[pab1_no_mixed_pos_df['in_sec_str'] == False].sample(161)\n",
    "pab1_train_df = pd.concat([pab1_train_ss, pab1_train_not_ss])\n",
    "\n",
    "pab1_test_ss = pab1_no_mixed_pos_df[pab1_no_mixed_pos_df['in_sec_str'] == True].sample(32)\n",
    "pab1_test_not_ss = pab1_no_mixed_pos_df[pab1_no_mixed_pos_df['in_sec_str'] == False].sample(32)\n",
    "pab1_test_df = pd.concat([pab1_test_ss, pab1_test_not_ss])\n",
    "\n",
    "# getting test set (2.5k in ss, 2.5k not in ss)\n",
    "print(pab1_train_df['in_sec_str'].value_counts())\n",
    "print(pab1_test_df['in_sec_str'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "53d749ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Standard Deviation: 1.853206689246909\n",
      "Dataset Mean: -1.4956708198757764\n",
      "Dataset Median: -0.6110165000000001\n",
      "Kurtosis: 2.967014257772422\n",
      "2088    -5.156153\n",
      "6796    -2.745225\n",
      "10254   -0.246060\n",
      "14771   -0.702386\n",
      "11830   -0.104403\n",
      "15131   -0.518916\n",
      "4414    -0.120950\n",
      "8329     0.189749\n",
      "6345    -1.465888\n",
      "3378    -2.878726\n",
      "Name: score, dtype: float64\n",
      "2088    -4.141341\n",
      "6796    -1.852789\n",
      "10254   -4.423478\n",
      "14771   -2.819053\n",
      "11830   -5.314758\n",
      "15131   -9.661592\n",
      "4414     1.410715\n",
      "8329     4.432901\n",
      "6345     9.455934\n",
      "3378     0.167918\n",
      "Name: score, dtype: float64\n",
      "2088    -5.156153\n",
      "6796    -2.745225\n",
      "10254   -0.246060\n",
      "14771   -0.702386\n",
      "11830   -0.104403\n",
      "15131   -0.518916\n",
      "4414    -0.120950\n",
      "8329     0.189749\n",
      "6345    -1.465888\n",
      "3378    -2.878726\n",
      "Name: score, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_10732\\4192645141.py:36: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(unchanged_scores[0:10])\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_10732\\4192645141.py:38: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(ss_scores[0:10])\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_10732\\4192645141.py:40: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(not_ss_scores[0:10])\n"
     ]
    }
   ],
   "source": [
    "# adding noise to values from uniform distribution and creating files\n",
    "\n",
    "# finding standard deviation of dataset scores\n",
    "std = pab1_train_df['score'].std()\n",
    "mean = pab1_train_df['score'].mean()\n",
    "median = pab1_train_df['score'].median()\n",
    "print(\"Dataset Standard Deviation: \" + str(std))\n",
    "print(\"Dataset Mean: \" + str(mean))\n",
    "print(\"Dataset Median: \" + str(median))\n",
    "print(\"Kurtosis: \" + str(kurtosis(pab1_train_df['score'], fisher=False)))\n",
    "\n",
    "# finding number of ss and not ss values\n",
    "num_ss_vals = (pab1_train_df.in_sec_str == True).sum()\n",
    "num_not_ss_vals = (pab1_train_df.in_sec_str == False).sum()\n",
    "\n",
    "# creating noise (std not the exact same, but similar) // 0 is the mean of the normal distribution\n",
    "noise_ss = np.random.normal(0, std * 3.0, num_ss_vals).tolist()\n",
    "noise_ss_v2 = noise_ss.copy()\n",
    "noise_not_ss = np.random.normal(0, std * 3.0, num_not_ss_vals).tolist()\n",
    "\n",
    "# filling in values for not ss indexes in noise_ss\n",
    "bool_ss_list = pab1_train_df.in_sec_str.values.tolist()\n",
    "\n",
    "noise_ss_to_add = []\n",
    "noise_not_ss_to_add = []\n",
    "\n",
    "for ss_assign in bool_ss_list:\n",
    "    if ss_assign: # if true (ss index)\n",
    "        noise_ss_to_add.append(noise_ss.pop(0))\n",
    "        noise_not_ss_to_add.append(0)\n",
    "    else: # if false (not ss index)\n",
    "        noise_ss_to_add.append(0)\n",
    "        noise_not_ss_to_add.append(noise_not_ss.pop(0))\n",
    "        \n",
    "unchanged_scores = pab1_train_df['score']\n",
    "print(unchanged_scores[0:10])\n",
    "ss_scores = pab1_train_df['score'] + noise_ss_to_add\n",
    "print(ss_scores[0:10])\n",
    "not_ss_scores = pab1_train_df['score'] + noise_not_ss_to_add\n",
    "print(not_ss_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "af058a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5572409689441005\n",
      "\n",
      "2.9552731178962017\n",
      "Percentage Change: 89.77622454282384\n",
      "3.2041282732541063\n",
      "Percentage Change: 105.75674138773081\n"
     ]
    }
   ],
   "source": [
    "abs_val_list = [abs(x) for x in pab1_train_df['score']]\n",
    "mean = sum(abs_val_list) / len(abs_val_list)\n",
    "print(mean)\n",
    "print()\n",
    "\n",
    "abs_ss_val_list = [abs(x) for x in ss_scores]\n",
    "mean_ss = sum(abs_ss_val_list) / len(abs_ss_val_list)\n",
    "print(mean_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_ss - mean) / mean) * 100))\n",
    "\n",
    "abs_not_ss_val_list = [abs(x) for x in not_ss_scores]\n",
    "mean_not_ss = sum(abs_not_ss_val_list) / len(abs_not_ss_val_list)\n",
    "print(mean_not_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_not_ss - mean) / mean) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5268b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: pab1_trainbatch_train_48_test_7542_t3.txt\n"
     ]
    }
   ],
   "source": [
    "# creating files (NO NOISE for test values)\n",
    "\n",
    "# unchanged\n",
    "# pab1_train_df['score'] = unchanged_scores\n",
    "pab1_full_df = pab1_no_mixed_pos_df.sample(7590)\n",
    "ssf.write_data_file(\"pab1_trainbatch_train_48_test_7542_t3\", protein_seq_pab1, pab1_full_df)\n",
    "\n",
    "# # ss\n",
    "# pab1_train_df['score'] = ss_scores\n",
    "# pab1_full_df = pd.concat([pab1_train_df, pab1_test_df])\n",
    "# ssf.write_data_file(\"pab1_MLformat_10000_train_5000_ss_noise_t2_v2\", protein_seq_pab1, pab1_full_df)\n",
    "\n",
    "# # not ss\n",
    "# pab1_train_df['score'] = not_ss_scores\n",
    "# pab1_full_df = pd.concat([pab1_train_df, pab1_test_df])\n",
    "# ssf.write_data_file(\"pab1_MLformat_10000_train_5000_not_ss_noise_t2_v2\", protein_seq_pab1, pab1_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2884a40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: pab1_trainbatch_train_48_test_7542_t3.txt\n"
     ]
    }
   ],
   "source": [
    "pab1_full_df = pab1_no_mixed_pos_df.sample(7590)\n",
    "ssf.write_data_file(\"pab1_trainbatch_train_48_test_7542_t3\", protein_seq_pab1, pab1_full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23865722",
   "metadata": {},
   "source": [
    "#### Bgl3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89f8c142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26653\n",
      "Index(['variant', 'num_mutations', 'inp', 'sel', 'score'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# importing Ube4b data from Gelman et al.\n",
    "bgl3_df1 = pd.read_csv(\"../Raw Data/bgl3.tsv.txt\", sep=\"\\t\")\n",
    "bgl3_df = bgl3_df1.dropna()\n",
    "print(len(bgl3_df))\n",
    "print(bgl3_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15bf5a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                 A104E\n",
      "1           A104E,A142E\n",
      "2           A104E,E152V\n",
      "3           A104E,K170R\n",
      "4                 A104G\n",
      "5                 A104P\n",
      "6                 A104S\n",
      "7           A104S,A116T\n",
      "8           A104S,A121V\n",
      "9           A104S,F111Y\n",
      "10    A104S,R114H,Q137L\n",
      "11                A104T\n",
      "12          A104T,A116V\n",
      "13          A104T,E156D\n",
      "14          A104T,G108S\n",
      "15          A104T,N141Y\n",
      "16          A104T,Q106L\n",
      "17          A104T,Q106R\n",
      "18          A104T,Q137H\n",
      "19                A104V\n",
      "Name: variant, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(bgl3_df[\"variant\"].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07c6ae39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26653\n",
      "25737\n",
      "25737\n"
     ]
    }
   ],
   "source": [
    "# rounding score column to 6 decimal points\n",
    "bgl3_df[\"score\"] = bgl3_df[\"score\"].round(6)\n",
    "print(len(bgl3_df))\n",
    "\n",
    "# remove values with wildcard star next to them\n",
    "bgl3_df = bgl3_df[bgl3_df[\"variant\"].str.contains(\"\\*\") == False]\n",
    "print(len(bgl3_df))\n",
    "\n",
    "bgl3_df = bgl3_df.sample(frac=1)\n",
    "print(len(bgl3_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "991cd58a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MET VAL PRO ALA ALA GLN GLN THR ALA MET ALA PRO ASP ALA ALA LEU THR PHE PRO GLU GLY PHE LEU TRP GLY SER ALA THR ALA SER TYR GLN ILE GLU GLY ALA ALA ALA GLU ASP GLY ARG THR PRO SER ILE TRP ASP THR TYR ALA ARG THR PRO GLY ARG VAL ARG ASN GLY ASP THR GLY ASP VAL ALA THR ASP HIS TYR HIS ARG TRP ARG GLU ASP VAL ALA LEU MET ALA GLU LEU GLY LEU GLY ALA TYR ARG PHE SER LEU ALA TRP PRO ARG ILE GLN PRO THR GLY ARG GLY PRO ALA LEU GLN LYS GLY LEU ASP PHE TYR ARG ARG LEU ALA ASP GLU LEU LEU ALA LYS GLY ILE GLN PRO VAL ALA THR LEU TYR HIS TRP ASP LEU PRO GLN GLU LEU GLU ASN ALA GLY GLY TRP PRO GLU ARG ALA THR ALA GLU ARG PHE ALA GLU TYR ALA ALA ILE ALA ALA ASP ALA LEU GLY ASP ARG VAL LYS THR TRP THR THR LEU ASN GLU PRO TRP CYS SER ALA PHE LEU GLY TYR GLY SER GLY VAL HIS ALA PRO GLY ARG THR ASP PRO VAL ALA ALA LEU ARG ALA ALA HIS HIS LEU ASN LEU GLY HIS GLY LEU ALA VAL GLN ALA LEU ARG ASP ARG LEU PRO ALA ASP ALA GLN CYS SER VAL THR LEU ASN ILE HIS HIS VAL ARG PRO LEU THR ASP SER ASP ALA ASP ALA ASP ALA VAL ARG ARG ILE ASP ALA LEU ALA ASN ARG VAL PHE THR GLY PRO MET LEU GLN GLY ALA TYR PRO GLU ASP LEU VAL LYS ASP THR ALA GLY LEU THR ASP TRP SER PHE VAL ARG ASP GLY ASP LEU ARG LEU ALA HIS GLN LYS LEU ASP PHE LEU GLY VAL ASN TYR TYR SER PRO THR LEU VAL SER GLU ALA ASP GLY SER GLY THR HIS ASN SER ASP GLY HIS GLY ARG SER ALA HIS SER PRO TRP PRO GLY ALA ASP ARG VAL ALA PHE HIS GLN PRO PRO GLY GLU THR THR ALA MET GLY TRP ALA VAL ASP PRO SER GLY LEU TYR GLU LEU LEU ARG ARG LEU SER SER ASP PHE PRO ALA LEU PRO LEU VAL ILE THR GLU ASN GLY ALA ALA PHE HIS ASP TYR ALA ASP PRO GLU GLY ASN VAL ASN ASP PRO GLU ARG ILE ALA TYR VAL ARG ASP HIS LEU ALA ALA VAL HIS ARG ALA ILE LYS ASP GLY SER ASP VAL ARG GLY TYR PHE LEU TRP SER LEU LEU ASP ASN PHE GLU TRP ALA HIS GLY TYR SER LYS ARG PHE GLY ALA VAL TYR VAL ASP TYR PRO THR GLY THR ARG ILE PRO LYS ALA SER ALA ARG TRP TYR ALA GLU VAL ALA ARG THR GLY VAL LEU PRO THR ALA GLY ASP PRO ASN SER SER SER VAL ASP LYS LEU ALA ALA ALA LEU GLU HIS HIS HIS HIS HIS HIS\n"
     ]
    }
   ],
   "source": [
    "# NOTE - no protein domain for bgl3\n",
    "# # get protein sequence from Gelman et al.\n",
    "string_seq = \"MVPAAQQTAMAPDAALTFPEGFLWGSATASYQIEGAAAEDGRTPSIWDTYARTPGRVRNGDTGDVATDHYHRWREDVALMAELGLGAYRFSLAWPRIQPTGRGPALQKGLDFYRRLADELLAKGIQPVATLYHWDLPQELENAGGWPERATAERFAEYAAIAADALGDRVKTWTTLNEPWCSAFLGYGSGVHAPGRTDPVAALRAAHHLNLGHGLAVQALRDRLPADAQCSVTLNIHHVRPLTDSDADADAVRRIDALANRVFTGPMLQGAYPEDLVKDTAGLTDWSFVRDGDLRLAHQKLDFLGVNYYSPTLVSEADGSGTHNSDGHGRSAHSPWPGADRVAFHQPPGETTAMGWAVDPSGLYELLRRLSSDFPALPLVITENGAAFHDYADPEGNVNDPERIAYVRDHLAAVHRAIKDGSDVRGYFLWSLLDNFEWAHGYSKRFGAVYVDYPTGTRIPKASARWYAEVARTGVLPTAGDPNSSSVDKLAAALEHHHHHH\"\n",
    "protein_seq_bgl3 = ssf.get_expanded_seq(string_seq)\n",
    "print(protein_seq_bgl3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e473b3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HIS'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_seq_bgl3_split = protein_seq_bgl3.split()\n",
    "protein_seq_bgl3_split[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cd26529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting variant list if there are multiple mutations\n",
    "bgl3_mut = bgl3_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "bgl3_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(bgl3_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "bgl3_df[\"MUTATED_RES\"] = ssf.get_mutation_type(bgl3_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "bgl3_df[\"POSITION\"] = ssf.get_position(bgl3_mut)\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "bgl3_df[\"variant\"] = ssf.get_mutations_names_list(bgl3_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]\n",
    "\n",
    "# bgl3_df = bgl3_df.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70f7fd51",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'add_sec_str_col' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8232\\310549820.py\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# add in_sec_str_col\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mbgl3_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_sec_str_col\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbgl3_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbgl3_ss_indexes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'add_sec_str_col' is not defined"
     ]
    }
   ],
   "source": [
    "# get ss position indexes\n",
    "path = \"../PDB and STRIDE Files/\" + 'bgl3_stride.txt'\n",
    "bgl3_stride_file = open(path, 'r')\n",
    "\n",
    "bgl3_ss_indexes = ssf.get_all_sec_struc_boolean(bgl3_stride_file)\n",
    "\n",
    "# need positionssplit\n",
    "bgl3_df[\"positions_split\"] = ssf.get_positions_split(bgl3_df)\n",
    "\n",
    "# add in_sec_str_col\n",
    "bgl3_df = add_sec_str_col(bgl3_df, bgl3_ss_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa13641d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# print(bgl3_ss_indexes)\n",
    "for val in bgl3_ss_indexes:\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bb1851",
   "metadata": {},
   "source": [
    "Trial 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "22b53891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len25737\n",
      "530\n",
      "452\n",
      "Train Data Fraction: 0.54\n",
      "false_df len11891\n",
      "true_df len13846\n",
      "in fraction,df len24755\n",
      "Test Data Fraction: 0.54\n",
      "false_df len11439\n",
      "true_df len13316\n",
      "Size of Test Dataset: 24658\n",
      "Size of Total Dataset: 25640\n",
      "25640\n"
     ]
    }
   ],
   "source": [
    "bgl3_train_df, bgl3_test_df, bgl3_remaining_df = get_train_and_test_df(bgl3_df, 0.54, 982)\n",
    "bgl3_df_format = pd.concat([bgl3_train_df, bgl3_test_df])\n",
    "print(len(bgl3_df_format))\n",
    "# ssf.write_data_file(\"bgl3_MLformat_982_train_13945_test_t3\", protein_seq_bgl3, bgl3_df_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "edebea79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len25737\n",
      "726\n",
      "256\n",
      "Train Data Fraction: 0.739\n",
      "false_df len11891\n",
      "true_df len13846\n",
      "in fraction,df len24755\n",
      "Test Data Fraction: 0.74\n",
      "false_df len11635\n",
      "true_df len13120\n",
      "Size of Test Dataset: 17726\n",
      "Size of Total Dataset: 18708\n",
      "in fraction,df len17726\n",
      "740\n",
      "260\n",
      "Train Data Fraction: 0.74\n",
      "false_df len4609\n",
      "true_df len13117\n",
      "in fraction,df len16726\n",
      "Test Data Fraction: 0.74\n",
      "false_df len4349\n",
      "true_df len12377\n",
      "Size of Test Dataset: 16723\n",
      "Size of Total Dataset: 17723\n",
      "SMALL TEST\n",
      "16723\n",
      "17705\n",
      "Filename: bgl3_MLformat_982_train_16723_test_t3.txt\n"
     ]
    }
   ],
   "source": [
    "bgl3_train_df, bgl3_test_df, bgl3_remaining_df = get_train_and_test_df(bgl3_df, 0.74, 982)\n",
    "bgl3_train_dummy, bgl3_small_test_df, bgl3_remaining_df = get_train_and_test_df(bgl3_test_df, 0.74, 1000)\n",
    "print(\"SMALL TEST\")\n",
    "print(len(bgl3_small_test_df))\n",
    "bgl3_df_format = pd.concat([bgl3_train_df, bgl3_small_test_df])\n",
    "print(len(bgl3_df_format))\n",
    "ssf.write_data_file(\"bgl3_MLformat_982_train_16723_test_t3\", protein_seq_bgl3, bgl3_df_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6780a809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len25737\n",
      "530\n",
      "452\n",
      "Train Data Fraction: 0.54\n",
      "false_df len17674\n",
      "true_df len8063\n",
      "in fraction,df len24755\n",
      "Test Data Fraction: 0.54\n",
      "false_df len17222\n",
      "true_df len7533\n",
      "Size of Test Dataset: 13945\n",
      "Size of Total Dataset: 14927\n",
      "14927\n",
      "Filename: bgl3_MLformat_982_train_13945_test_t2.txt\n"
     ]
    }
   ],
   "source": [
    "bgl3_train_df_2, bgl3_test_df_2, bgl3_remaining_df_2 = get_train_and_test_df(bgl3_df, 0.54, 982)\n",
    "bgl3_df_format_2 = pd.concat([bgl3_train_df_2, bgl3_test_df_2])\n",
    "print(len(bgl3_df_format_2))\n",
    "ssf.write_data_file(\"bgl3_MLformat_982_train_13945_test_t2\", protein_seq_bgl3, bgl3_df_format_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf225af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len25737\n",
      "530\n",
      "452\n",
      "Train Data Fraction: 0.54\n",
      "false_df len17674\n",
      "true_df len8063\n",
      "in fraction,df len24755\n",
      "Test Data Fraction: 0.54\n",
      "false_df len17222\n",
      "true_df len7533\n",
      "Size of Test Dataset: 13945\n",
      "Size of Total Dataset: 14927\n",
      "14927\n",
      "Filename: bgl3_MLformat_982_train_13945_test_t3.txt\n"
     ]
    }
   ],
   "source": [
    "bgl3_train_df_3, bgl3_test_df_3, bgl3_remaining_df_3 = get_train_and_test_df(bgl3_df, 0.54, 982)\n",
    "bgl3_df_format_3 = pd.concat([bgl3_train_df_3, bgl3_test_df_3])\n",
    "print(len(bgl3_df_format_3))\n",
    "ssf.write_data_file(\"bgl3_MLformat_982_train_13945_test_t3\", protein_seq_bgl3, bgl3_df_format_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da6df19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "982\n",
      "13945\n",
      "982\n",
      "13945\n",
      "982\n",
      "13945\n"
     ]
    }
   ],
   "source": [
    "print(len(bgl3_train_df))\n",
    "print(len(bgl3_test_df))\n",
    "print(len(bgl3_train_df_2))\n",
    "print(len(bgl3_test_df_2))\n",
    "print(len(bgl3_train_df_3))\n",
    "print(len(bgl3_test_df_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba92574e",
   "metadata": {},
   "source": [
    "### Adding Noise to Bgl3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f6a395e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25737\n"
     ]
    }
   ],
   "source": [
    "# importing and formatting data (25737 usable vals)\n",
    "bgl3_df1 = pd.read_csv(\"../Raw Data/bgl3.tsv.txt\", sep=\"\\t\")\n",
    "bgl3_df = bgl3_df1.dropna()\n",
    "\n",
    "# rounding score column to 6 decimal points\n",
    "bgl3_df[\"score\"] = bgl3_df[\"score\"].round(6)\n",
    "\n",
    "# remove values with wildcard star next to them\n",
    "bgl3_df = bgl3_df[bgl3_df[\"variant\"].str.contains(\"\\*\") == False]\n",
    "\n",
    "# splitting variant list if there are multiple mutations\n",
    "bgl3_mut = bgl3_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "bgl3_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(bgl3_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "bgl3_df[\"MUTATED_RES\"] = ssf.get_mutation_type(bgl3_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "bgl3_df[\"POSITION\"] = ssf.get_position(bgl3_mut)\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "bgl3_df[\"variant\"] = ssf.get_mutations_names_list(bgl3_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]\n",
    "print(len(bgl3_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c76b7a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# secondary structure assignments\n",
    "path = \"../PDB and STRIDE Files/\" + 'bgl3_stride.txt'\n",
    "bgl3_stride_file = open(path, 'r')\n",
    "\n",
    "bgl3_ss_indexes = ssf.get_sec_struc_boolean(bgl3_stride_file) # not including turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14da6e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling data\n",
    "bgl3_df = bgl3_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "839c02ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein sequence\n",
    "string_seq = \"MVPAAQQTAMAPDAALTFPEGFLWGSATASYQIEGAAAEDGRTPSIWDTYARTPGRVRNGDTGDVATDHYHRWREDVALMAELGLGAYRFSLAWPRIQPTGRGPALQKGLDFYRRLADELLAKGIQPVATLYHWDLPQELENAGGWPERATAERFAEYAAIAADALGDRVKTWTTLNEPWCSAFLGYGSGVHAPGRTDPVAALRAAHHLNLGHGLAVQALRDRLPADAQCSVTLNIHHVRPLTDSDADADAVRRIDALANRVFTGPMLQGAYPEDLVKDTAGLTDWSFVRDGDLRLAHQKLDFLGVNYYSPTLVSEADGSGTHNSDGHGRSAHSPWPGADRVAFHQPPGETTAMGWAVDPSGLYELLRRLSSDFPALPLVITENGAAFHDYADPEGNVNDPERIAYVRDHLAAVHRAIKDGSDVRGYFLWSLLDNFEWAHGYSKRFGAVYVDYPTGTRIPKASARWYAEVARTGVLPTAGDPNSSSVDKLAAALEHHHHHH\"\n",
    "protein_seq_bgl3 = ssf.get_expanded_seq(string_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10fe7e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # getting dataset with correct ratios (only using training dataset)\n",
    "# bgl3_train_df, bgl3_test_df, bgl3_remaining_df = get_train_and_test_df(bgl3_df, 0.54, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04959d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need positionssplit\n",
    "bgl3_df[\"positions_split\"] = ssf.get_positions_split(bgl3_df)\n",
    "\n",
    "# bgl3_only_ss_df = get_ss_dataset(bgl3_df, bgl3_ss_indexes, 0)\n",
    "# bgl3_only_not_ss_df = get_not_ss_dataset(bgl3_df, bgl3_ss_indexes, 0)\n",
    "# bgl3_no_mixed_pos_df = pd.concat([bgl3_only_ss_df, bgl3_only_not_ss_df])\n",
    "bgl3_no_mixed_pos_df = bgl3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad010e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25737\n",
      "25737\n"
     ]
    }
   ],
   "source": [
    "print(len(bgl3_df))\n",
    "print(len(bgl3_no_mixed_pos_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25e51be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    17674\n",
      "True      8063\n",
      "Name: in_sec_str, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "bgl3_no_mixed_pos_df = add_sec_str_col(bgl3_no_mixed_pos_df, bgl3_ss_indexes, 0)\n",
    "print(bgl3_no_mixed_pos_df['in_sec_str'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea3d696c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25737\n"
     ]
    }
   ],
   "source": [
    "# shuffling data\n",
    "bgl3_no_mixed_pos_df = bgl3_no_mixed_pos_df.sample(frac=1)\n",
    "print(len(bgl3_no_mixed_pos_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fc963820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting training set (5k in ss, 5k not in ss)\n",
    "# bgl3_train_ss = bgl3_no_mixed_pos_df[bgl3_no_mixed_pos_df['in_sec_str'] == True].sample(606)\n",
    "# bgl3_train_not_ss = bgl3_no_mixed_pos_df[bgl3_no_mixed_pos_df['in_sec_str'] == False].sample(606)\n",
    "# bgl3_train_df = pd.concat([bgl3_train_ss, bgl3_train_not_ss])\n",
    "# bgl3_train_df = bgl3_no_mixed_pos_df.sample()\n",
    "\n",
    "# bgl3_test_ss = bgl3_no_mixed_pos_df[bgl3_no_mixed_pos_df['in_sec_str'] == True].sample(122)\n",
    "# bgl3_test_not_ss = bgl3_no_mixed_pos_df[bgl3_no_mixed_pos_df['in_sec_str'] == False].sample(122)\n",
    "# bgl3_test_df = pd.concat([bgl3_test_ss, bgl3_test_not_ss])\n",
    "# bgl3_test_df = bgl3_no_mixed_pos_df.sample()\n",
    "\n",
    "# getting test set (2.5k in ss, 2.5k not in ss)\n",
    "# print(bgl3_train_df['in_sec_str'].value_counts())\n",
    "# print(bgl3_test_df['in_sec_str'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4ff8fc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Standard Deviation: 1.3533125398331025\n",
      "Dataset Mean: -0.29486490429042905\n",
      "Dataset Median: -0.251309\n",
      "Kurtosis: 3.0984392882112255\n",
      "7611    1.594518\n",
      "2258   -1.149250\n",
      "7101   -2.649204\n",
      "4654    1.358129\n",
      "725     1.483292\n",
      "2434   -1.046647\n",
      "7475   -0.310572\n",
      "8031   -0.050638\n",
      "267    -0.050638\n",
      "5073   -2.649204\n",
      "Name: score, dtype: float64\n",
      "7611   -4.955740\n",
      "2258   -1.862550\n",
      "7101   -6.398919\n",
      "4654   -1.336532\n",
      "725     5.819262\n",
      "2434    0.846996\n",
      "7475   -3.257343\n",
      "8031   -3.359982\n",
      "267     6.341048\n",
      "5073   -5.726102\n",
      "Name: score, dtype: float64\n",
      "7611    1.594518\n",
      "2258   -1.149250\n",
      "7101   -2.649204\n",
      "4654    1.358129\n",
      "725     1.483292\n",
      "2434   -1.046647\n",
      "7475   -0.310572\n",
      "8031   -0.050638\n",
      "267    -0.050638\n",
      "5073   -2.649204\n",
      "Name: score, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_10732\\1266127521.py:36: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(unchanged_scores[0:10])\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_10732\\1266127521.py:38: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(ss_scores[0:10])\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_10732\\1266127521.py:40: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(not_ss_scores[0:10])\n"
     ]
    }
   ],
   "source": [
    "# adding noise to values from uniform distribution and creating files\n",
    "\n",
    "# finding standard deviation of dataset scores\n",
    "std = bgl3_train_df['score'].std()\n",
    "mean = bgl3_train_df['score'].mean()\n",
    "median = bgl3_train_df['score'].median()\n",
    "print(\"Dataset Standard Deviation: \" + str(std))\n",
    "print(\"Dataset Mean: \" + str(mean))\n",
    "print(\"Dataset Median: \" + str(median))\n",
    "print(\"Kurtosis: \" + str(kurtosis(bgl3_train_df['score'], fisher=False)))\n",
    "\n",
    "# finding number of ss and not ss values\n",
    "num_ss_vals = (bgl3_train_df.in_sec_str == True).sum()\n",
    "num_not_ss_vals = (bgl3_train_df.in_sec_str == False).sum()\n",
    "\n",
    "# creating noise (std not the exact same, but similar) // 0 is the mean of the normal distribution\n",
    "noise_ss = np.random.normal(0, std * 3.0, num_ss_vals).tolist()\n",
    "noise_ss_v2 = noise_ss.copy()\n",
    "noise_not_ss = np.random.normal(0, std * 3.0, num_not_ss_vals).tolist()\n",
    "\n",
    "# filling in values for not ss indexes in noise_ss\n",
    "bool_ss_list = bgl3_train_df.in_sec_str.values.tolist()\n",
    "\n",
    "noise_ss_to_add = []\n",
    "noise_not_ss_to_add = []\n",
    "\n",
    "for ss_assign in bool_ss_list:\n",
    "    if ss_assign: # if true (ss index)\n",
    "        noise_ss_to_add.append(noise_ss.pop(0))\n",
    "        noise_not_ss_to_add.append(0)\n",
    "    else: # if false (not ss index)\n",
    "        noise_ss_to_add.append(0)\n",
    "        noise_not_ss_to_add.append(noise_not_ss.pop(0))\n",
    "        \n",
    "unchanged_scores = bgl3_train_df['score']\n",
    "print(unchanged_scores[0:10])\n",
    "ss_scores = bgl3_train_df['score'] + noise_ss_to_add\n",
    "print(ss_scores[0:10])\n",
    "not_ss_scores = bgl3_train_df['score'] + noise_not_ss_to_add\n",
    "print(not_ss_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d77ce7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.066996929042903\n",
      "\n",
      "2.209398098610665\n",
      "Percentage Change: 107.0669594703048\n",
      "2.259524187206808\n",
      "Percentage Change: 111.76482571825233\n"
     ]
    }
   ],
   "source": [
    "abs_val_list = [abs(x) for x in bgl3_train_df['score']]\n",
    "mean = sum(abs_val_list) / len(abs_val_list)\n",
    "print(mean)\n",
    "print()\n",
    "\n",
    "abs_ss_val_list = [abs(x) for x in ss_scores]\n",
    "mean_ss = sum(abs_ss_val_list) / len(abs_ss_val_list)\n",
    "print(mean_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_ss - mean) / mean) * 100))\n",
    "\n",
    "abs_not_ss_val_list = [abs(x) for x in not_ss_scores]\n",
    "mean_not_ss = sum(abs_not_ss_val_list) / len(abs_not_ss_val_list)\n",
    "print(mean_not_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_not_ss - mean) / mean) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5e902be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.hist(noise_ss_v2)\n",
    "# print(np.std(noise_ss_v2))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1aa92f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(bgl3_train_df['score'])\n",
    "# print(bgl3_train_df['score'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a14bf27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: bgl3_trainbatch_train_32_test_9_t3.txt\n"
     ]
    }
   ],
   "source": [
    "# creating files (NO NOISE for test values)\n",
    "\n",
    "# unchanged\n",
    "# bgl3_train_df['score'] = unchanged_scores\n",
    "bgl3_full_df = bgl3_no_mixed_pos_df.sample(41)\n",
    "ssf.write_data_file(\"bgl3_trainbatch_train_32_test_9_t3\", protein_seq_bgl3, bgl3_full_df)\n",
    "\n",
    "# # ss\n",
    "# bgl3_train_df['score'] = ss_scores\n",
    "# bgl3_full_df = pd.concat([bgl3_train_df, bgl3_test_df])\n",
    "# ssf.write_data_file(\"bgl3_MLformat_10000_train_5000_ss_noise_t3_v2\", protein_seq_bgl3, bgl3_full_df)\n",
    "\n",
    "# # not ssb\n",
    "# bgl3_train_df['score'] = not_ss_scores\n",
    "# bgl3_full_df = pd.concat([bgl3_train_df, bgl3_test_df])\n",
    "# ssf.write_data_file(\"bgl3_MLformat_10000_train_5000_not_ss_noise_t3_v2\", protein_seq_bgl3, bgl3_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee1fedf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: bgl3_trainbatch_train_32_test_5147_t3.txt\n"
     ]
    }
   ],
   "source": [
    "bgl3_train_df = bgl3_no_mixed_pos_df.sample(32)\n",
    "bgl3_test_df = bgl3_no_mixed_pos_df.sample(5147)\n",
    "bgl3_full_df = pd.concat([bgl3_train_df, bgl3_test_df])\n",
    "ssf.write_data_file(\"bgl3_trainbatch_train_32_test_5147_t3\", protein_seq_bgl3, bgl3_full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9c0f48",
   "metadata": {},
   "source": [
    "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0261829#sec014"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2309883b",
   "metadata": {},
   "source": [
    "### 1be9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f6e08281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "pro_1be9_df1 = pd.read_csv(\"../Raw Data/functional_1be9.csv\", sep=\",\")\n",
    "\n",
    "# renaming mutated residue column\n",
    "pro_1be9_df1 = pro_1be9_df1.rename(columns={\"Unnamed: 0\": \"mutated_res\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f6bdf411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganizing data to other form\n",
    "col_list_1be9 = list(pro_1be9_df1)\n",
    "col_list_1be9 = col_list_1be9[1:]\n",
    "\n",
    "# mutations going down from the leftmost column\n",
    "mutations_1be9 = []\n",
    "\n",
    "for column in col_list_1be9:\n",
    "    for mutation in pro_1be9_df1[\"mutated_res\"]:\n",
    "        mutations_1be9.append(column + mutation)\n",
    "\n",
    "# getting scores\n",
    "scores_1be9 = []\n",
    "\n",
    "for column in pro_1be9_df1.drop('mutated_res', axis=1):\n",
    "    for val in pro_1be9_df1[column]:\n",
    "        scores_1be9.append(val)\n",
    "    \n",
    "# adding to df and renaming variant and score to match formatting for other proteins\n",
    "pro_1be9_df = pd.DataFrame(list(zip(mutations_1be9, scores_1be9)),\n",
    "               columns =['variant', 'score'])\n",
    "\n",
    "# i have the data, next is formatting it so i can add the indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f1cefe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounding score column to 6 decimal points\n",
    "pro_1be9_df[\"score\"] = pro_1be9_df[\"score\"].round(6)\n",
    "\n",
    "# shuffling\n",
    "pro_1be9_df = pro_1be9_df.sample(frac=1)\n",
    "\n",
    "# splitting variant list if there are multiple mutations\n",
    "pro_1be9_mut = pro_1be9_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "pro_1be9_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(pro_1be9_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "pro_1be9_df[\"MUTATED_RES\"] = ssf.get_mutation_type(pro_1be9_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "pro_1be9_df[\"POSITION\"] = ssf.get_position(pro_1be9_mut)\n",
    "\n",
    "# need positionssplit\n",
    "pro_1be9_df[\"positions_split\"] = ssf.get_positions_split(pro_1be9_df)\n",
    "\n",
    "positions_split_subtracted = []\n",
    "for pos_list in pro_1be9_df[\"positions_split\"]:\n",
    "    pos_list = [x - 301 for x in pos_list] # reset index at 301\n",
    "    positions_split_subtracted.append(pos_list)  \n",
    "\n",
    "pro_1be9_df[\"positions_split\"] = positions_split_subtracted    \n",
    "    \n",
    "new_positions = []\n",
    "pos_string = \"\"\n",
    "for pos_list in pro_1be9_df[\"positions_split\"]:\n",
    "    pos_string = \",\".join(map(str, pos_list))\n",
    "    new_positions.append(pos_string)\n",
    "    pos_string = \"\"\n",
    "\n",
    "pro_1be9_df[\"POSITION\"] = new_positions # changes positions into new adjusted values (0 index)\n",
    "# replace variant column with reformatted variant name\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "pro_1be9_df[\"variant\"] = ssf.get_mutations_names_list(pro_1be9_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d68635d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_seq_1be9 = \"FLGEEDIPREPRRIVIHRGSTGLGFNIIGGEDGEGIFISFILAGGPADLSGELRKGDQILSVNGVDLRNASHEQAAIALKNAGQTVTIIAQYKPEEYSRFEANSRVNSSGRIVTNKQTSV\"\n",
    "protein_seq_1be9 = ssf.get_expanded_seq(string_seq_1be9)\n",
    "protein_seq_1be9_split = protein_seq_1be9.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d80052e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "path = \"../PDB and STRIDE Files/\" + '1be9_stride.txt'\n",
    "pro_1be9_stride_file = open(path, 'r')\n",
    "\n",
    "pro_1be9_ss_indexes = ssf.get_all_sec_struc_boolean(pro_1be9_stride_file)\n",
    "print(pro_1be9_ss_indexes.count(True))\n",
    "print(pro_1be9_ss_indexes.count(False))\n",
    "\n",
    "# add in_sec_str_col\n",
    "pro_1be9_df = add_sec_str_col(pro_1be9_df, pro_1be9_ss_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "900e168f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len1660\n",
      "190\n",
      "45\n",
      "Train Data Fraction: 0.809\n",
      "false_df len220\n",
      "true_df len1440\n",
      "in fraction,df len1425\n",
      "Test Data Fraction: 0.81\n",
      "false_df len175\n",
      "true_df len1250\n",
      "Size of Test Dataset: 915\n",
      "Size of Total Dataset: 1150\n",
      "1150\n",
      "Filename: pro_1be9_MLformat_235_train_915_test_t3.txt\n"
     ]
    }
   ],
   "source": [
    "pro_1be9_train_df, pro_1be9_test_df, pro_1be9_remaining_df = get_train_and_test_df(pro_1be9_df, 0.81, 235)\n",
    "pro_1be9_df_format = pd.concat([pro_1be9_train_df, pro_1be9_test_df])\n",
    "print(len(pro_1be9_df_format))\n",
    "ssf.write_data_file(\"pro_1be9_MLformat_235_train_915_test_t3\", protein_seq_1be9, pro_1be9_df_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07756573",
   "metadata": {},
   "source": [
    "# Adding Noise to 1be9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "188ac93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "pro_1be9_df1 = pd.read_csv(\"../Raw Data/functional_1be9.csv\", sep=\",\")\n",
    "\n",
    "# renaming mutated residue column\n",
    "pro_1be9_df1 = pro_1be9_df1.rename(columns={\"Unnamed: 0\": \"mutated_res\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "15ec6545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganizing data to other form\n",
    "col_list_1be9 = list(pro_1be9_df1)\n",
    "col_list_1be9 = col_list_1be9[1:]\n",
    "\n",
    "# mutations going down from the leftmost column\n",
    "mutations_1be9 = []\n",
    "\n",
    "for column in col_list_1be9:\n",
    "    for mutation in pro_1be9_df1[\"mutated_res\"]:\n",
    "        mutations_1be9.append(column + mutation)\n",
    "\n",
    "# getting scores\n",
    "scores_1be9 = []\n",
    "\n",
    "for column in pro_1be9_df1.drop('mutated_res', axis=1):\n",
    "    for val in pro_1be9_df1[column]:\n",
    "        scores_1be9.append(val)\n",
    "    \n",
    "# adding to df and renaming variant and score to match formatting for other proteins\n",
    "pro_1be9_df = pd.DataFrame(list(zip(mutations_1be9, scores_1be9)),\n",
    "               columns =['variant', 'score'])\n",
    "\n",
    "# i have the data, next is formatting it so i can add the indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "cef4b7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1660\n",
      "1660\n"
     ]
    }
   ],
   "source": [
    "print(len(pro_1be9_df))\n",
    "pro_1be9_df = pro_1be9_df.dropna(axis=0)\n",
    "print(len(pro_1be9_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c053e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounding score column to 6 decimal points\n",
    "pro_1be9_df[\"score\"] = pro_1be9_df[\"score\"].round(6)\n",
    "\n",
    "# shuffling\n",
    "pro_1be9_df = pro_1be9_df.sample(frac=1)\n",
    "\n",
    "# splitting variant list if there are multiple mutations\n",
    "pro_1be9_mut = pro_1be9_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "pro_1be9_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(pro_1be9_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "pro_1be9_df[\"MUTATED_RES\"] = ssf.get_mutation_type(pro_1be9_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "pro_1be9_df[\"POSITION\"] = ssf.get_position(pro_1be9_mut)\n",
    "\n",
    "# need positionssplit\n",
    "pro_1be9_df[\"positions_split\"] = ssf.get_positions_split(pro_1be9_df)\n",
    "\n",
    "positions_split_subtracted = []\n",
    "for pos_list in pro_1be9_df[\"positions_split\"]:\n",
    "    pos_list = [x - 301 for x in pos_list] # reset index at 301\n",
    "    positions_split_subtracted.append(pos_list)  \n",
    "\n",
    "pro_1be9_df[\"positions_split\"] = positions_split_subtracted    \n",
    "    \n",
    "new_positions = []\n",
    "pos_string = \"\"\n",
    "for pos_list in pro_1be9_df[\"positions_split\"]:\n",
    "    pos_string = \",\".join(map(str, pos_list))\n",
    "    new_positions.append(pos_string)\n",
    "    pos_string = \"\"\n",
    "\n",
    "pro_1be9_df[\"POSITION\"] = new_positions # changes positions into new adjusted values (0 index)\n",
    "# replace variant column with reformatted variant name\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "pro_1be9_df[\"variant\"] = ssf.get_mutations_names_list(pro_1be9_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8196adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../PDB and STRIDE Files/\" + '1be9_stride.txt'\n",
    "pro_1be9_stride_file = open(path, 'r')\n",
    "protein_seq_pro_1be9 = get_seq_from_stride(pro_1be9_stride_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f3a90fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "66\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "path = \"../PDB and STRIDE Files/\" + '1be9_stride.txt'\n",
    "pro_1be9_stride_file = open(path, 'r')\n",
    "\n",
    "pro_1be9_ss_indexes = ssf.get_sec_struc_boolean(pro_1be9_stride_file)\n",
    "print(len(pro_1be9_ss_indexes))\n",
    "print(pro_1be9_ss_indexes.count(True))\n",
    "print(pro_1be9_ss_indexes.count(False))\n",
    "\n",
    "# add in_sec_str_col\n",
    "pro_1be9_df = add_sec_str_col(pro_1be9_df, pro_1be9_ss_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0532e27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need positionssplit\n",
    "pro_1be9_df[\"positions_split\"] = ssf.get_positions_split(pro_1be9_df)\n",
    "\n",
    "# pro_1be9_only_ss_df = get_ss_dataset(pro_1be9_df, pro_1be9_ss_indexes, 0)\n",
    "# print(len(pro_1be9_only_ss_df))\n",
    "# pro_1be9_only_not_ss_df = get_not_ss_dataset(pro_1be9_df, pro_1be9_ss_indexes, 0)\n",
    "# print(len(pro_1be9_only_not_ss_df))\n",
    "# pro_1be9_no_mixed_pos_df = pd.concat([pro_1be9_only_ss_df, pro_1be9_only_not_ss_df])\n",
    "\n",
    "# # add in_sec_str_col\n",
    "# pro_1be9_no_mixed_pos_df = add_sec_str_col(pro_1be9_no_mixed_pos_df, pro_1be9_ss_indexes, 0)\n",
    "pro_1be9_no_mixed_pos_df = pro_1be9_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4f5156f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1660\n"
     ]
    }
   ],
   "source": [
    "# shuffling data\n",
    "pro_1be9_no_mixed_pos_df = pro_1be9_no_mixed_pos_df.sample(frac=1)\n",
    "print(len(pro_1be9_no_mixed_pos_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9932ba5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     178\n",
      "False    178\n",
      "Name: in_sec_str, dtype: int64\n",
      "True     36\n",
      "False    36\n",
      "Name: in_sec_str, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# getting training set (5k in ss, 5k not in ss)\n",
    "pro_1be9_train_ss = pro_1be9_no_mixed_pos_df[pro_1be9_no_mixed_pos_df['in_sec_str'] == True].sample(178)\n",
    "pro_1be9_train_not_ss = pro_1be9_no_mixed_pos_df[pro_1be9_no_mixed_pos_df['in_sec_str'] == False].sample(178)\n",
    "pro_1be9_train_df = pd.concat([pro_1be9_train_ss, pro_1be9_train_not_ss])\n",
    "\n",
    "pro_1be9_test_ss = pro_1be9_no_mixed_pos_df[pro_1be9_no_mixed_pos_df['in_sec_str'] == True].sample(36)\n",
    "pro_1be9_test_not_ss = pro_1be9_no_mixed_pos_df[pro_1be9_no_mixed_pos_df['in_sec_str'] == False].sample(36)\n",
    "pro_1be9_test_df = pd.concat([pro_1be9_test_ss, pro_1be9_test_not_ss])\n",
    "\n",
    "# getting test set (2.5k in ss, 2.5k not in ss)\n",
    "print(pro_1be9_train_df['in_sec_str'].value_counts())\n",
    "print(pro_1be9_test_df['in_sec_str'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "80ddc050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Standard Deviation: 0.39880771513249463\n",
      "Dataset Mean: -0.17268145786516853\n",
      "Dataset Median: -0.0249905\n",
      "Kurtosis: 6.661950587163273\n",
      "586   -0.100192\n",
      "55    -0.323379\n",
      "509    0.054576\n",
      "561   -0.129216\n",
      "804   -0.282136\n",
      "548    0.072821\n",
      "488   -1.606264\n",
      "292   -1.579241\n",
      "500    0.014864\n",
      "296   -0.076998\n",
      "Name: score, dtype: float64\n",
      "586   -0.138152\n",
      "55     0.667541\n",
      "509   -1.015849\n",
      "561   -1.807949\n",
      "804   -0.715653\n",
      "548   -0.887127\n",
      "488   -1.288199\n",
      "292   -1.732958\n",
      "500   -0.062239\n",
      "296    1.260609\n",
      "Name: score, dtype: float64\n",
      "586   -0.100192\n",
      "55    -0.323379\n",
      "509    0.054576\n",
      "561   -0.129216\n",
      "804   -0.282136\n",
      "548    0.072821\n",
      "488   -1.606264\n",
      "292   -1.579241\n",
      "500    0.014864\n",
      "296   -0.076998\n",
      "Name: score, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_18804\\1429027068.py:36: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(unchanged_scores[0:10])\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_18804\\1429027068.py:38: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(ss_scores[0:10])\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_18804\\1429027068.py:40: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(not_ss_scores[0:10])\n"
     ]
    }
   ],
   "source": [
    "# adding noise to values from uniform distribution and creating files\n",
    "\n",
    "# finding standard deviation of dataset scores\n",
    "std = pro_1be9_train_df['score'].std()\n",
    "mean = pro_1be9_train_df['score'].mean()\n",
    "median = pro_1be9_train_df['score'].median()\n",
    "print(\"Dataset Standard Deviation: \" + str(std))\n",
    "print(\"Dataset Mean: \" + str(mean))\n",
    "print(\"Dataset Median: \" + str(median))\n",
    "print(\"Kurtosis: \" + str(kurtosis(pro_1be9_train_df['score'], fisher=False)))\n",
    "\n",
    "# finding number of ss and not ss values\n",
    "num_ss_vals = (pro_1be9_train_df.in_sec_str == True).sum()\n",
    "num_not_ss_vals = (pro_1be9_train_df.in_sec_str == False).sum()\n",
    "\n",
    "# creating noise (std not the exact same, but similar) // 0 is the mean of the normal distribution\n",
    "noise_ss = np.random.normal(0, std * 2, num_ss_vals).tolist()\n",
    "noise_ss_v2 = noise_ss.copy()\n",
    "noise_not_ss = np.random.normal(0, std * 2, num_not_ss_vals).tolist()\n",
    "\n",
    "# filling in values for not ss indexes in noise_ss\n",
    "bool_ss_list = pro_1be9_train_df.in_sec_str.values.tolist()\n",
    "\n",
    "noise_ss_to_add = []\n",
    "noise_not_ss_to_add = []\n",
    "\n",
    "for ss_assign in bool_ss_list:\n",
    "    if ss_assign: # if true (ss index)\n",
    "        noise_ss_to_add.append(noise_ss.pop(0))\n",
    "        noise_not_ss_to_add.append(0)\n",
    "    else: # if false (not ss index)\n",
    "        noise_ss_to_add.append(0)\n",
    "        noise_not_ss_to_add.append(noise_not_ss.pop(0))\n",
    "        \n",
    "unchanged_scores = pro_1be9_train_df['score']\n",
    "print(unchanged_scores[0:10])\n",
    "ss_scores = pro_1be9_train_df['score'] + noise_ss_to_add\n",
    "print(ss_scores[0:10])\n",
    "not_ss_scores = pro_1be9_train_df['score'] + noise_not_ss_to_add\n",
    "print(not_ss_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8ba6582e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23818809269662913\n",
      "\n",
      "0.4478048558758358\n",
      "Percentage Change: 88.0047196339858\n",
      "0.5170718356606889\n",
      "Percentage Change: 117.08550994581546\n"
     ]
    }
   ],
   "source": [
    "abs_val_list = [abs(x) for x in pro_1be9_train_df['score']]\n",
    "mean = sum(abs_val_list) / len(abs_val_list)\n",
    "print(mean)\n",
    "print()\n",
    "\n",
    "abs_ss_val_list = [abs(x) for x in ss_scores]\n",
    "mean_ss = sum(abs_ss_val_list) / len(abs_ss_val_list)\n",
    "print(mean_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_ss - mean) / mean) * 100))\n",
    "\n",
    "abs_not_ss_val_list = [abs(x) for x in not_ss_scores]\n",
    "mean_not_ss = sum(abs_not_ss_val_list) / len(abs_not_ss_val_list)\n",
    "print(mean_not_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_not_ss - mean) / mean) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8e488766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: 1be9_trainbatch_train_52_test_14_t3.txt\n"
     ]
    }
   ],
   "source": [
    "# creating files (NO NOISE for test values)\n",
    "\n",
    "# unchanged\n",
    "# pro_1be9_train_df['score'] = unchanged_scores\n",
    "# pro_1be9_full_df = pd.concat([pro_1be9_train_df, pro_1be9_test_df])\n",
    "pro_1be9_full_df = pro_1be9_no_mixed_pos_df.sample(66)\n",
    "ssf.write_data_file(\"1be9_trainbatch_train_28_test_8_t3\", protein_seq_pro_1be9, pro_1be9_full_df)\n",
    "\n",
    "# # ss\n",
    "# pro_1be9_train_df['score'] = ss_scores\n",
    "# pro_1be9_full_df = pd.concat([pro_1be9_train_df, pro_1be9_test_df])\n",
    "# ssf.write_data_file(\"pro_1be9_MLformat_500_train_100_ss_noise_t2_v2\", protein_seq_pro_1be9, pro_1be9_full_df)\n",
    "\n",
    "# # not ss\n",
    "# pro_1be9_train_df['score'] = not_ss_scores\n",
    "# pro_1be9_full_df = pd.concat([pro_1be9_train_df, pro_1be9_test_df])\n",
    "# ssf.write_data_file(\"pro_1be9_MLformat_500_train_100_not_ss_noise_t2_v2\", protein_seq_pro_1be9, pro_1be9_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "20263ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: pro_1be9_trainbatch_train_52_test_332_t3.txt\n"
     ]
    }
   ],
   "source": [
    "pro_1be9_full_df = pro_1be9_no_mixed_pos_df.sample(384)\n",
    "ssf.write_data_file(\"pro_1be9_trainbatch_train_52_test_332_t3\", protein_seq_pro_1be9, pro_1be9_full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c7a208",
   "metadata": {},
   "source": [
    "### 1d5r (Adding Noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "80d47e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "pro_1d5r_df1 = pd.read_csv(\"../Raw Data/1d5r.csv\", sep=\",\")\n",
    "\n",
    "# renaming mutated residue column\n",
    "pro_1d5r_df1 = pro_1d5r_df1.rename(columns={\"Unnamed: 0\": \"mutated_res\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6bf84c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganizing data to other form\n",
    "col_list_1d5r = list(pro_1d5r_df1)\n",
    "col_list_1d5r = col_list_1d5r[1:]\n",
    "\n",
    "# mutations going down from the leftmost column\n",
    "mutations_1d5r = []\n",
    "\n",
    "for column in col_list_1d5r:\n",
    "    for mutation in pro_1d5r_df1[\"mutated_res\"]:\n",
    "        mutations_1d5r.append(column + mutation)\n",
    "\n",
    "# getting scores\n",
    "scores_1d5r = []\n",
    "\n",
    "for column in pro_1d5r_df1.drop('mutated_res', axis=1):\n",
    "    for val in pro_1d5r_df1[column]:\n",
    "        scores_1d5r.append(val)\n",
    "    \n",
    "# adding to df and renaming variant and score to match formatting for other proteins\n",
    "pro_1d5r_df = pd.DataFrame(list(zip(mutations_1d5r, scores_1d5r)),\n",
    "               columns =['variant', 'score'])\n",
    "\n",
    "# i have the data, next is formatting it so i can add the indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "98e4b67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5833\n"
     ]
    }
   ],
   "source": [
    "pro_1d5r_df = pro_1d5r_df.dropna(axis=0)\n",
    "print(len(pro_1d5r_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0753f959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variant      V351Y\n",
      "score     -0.76426\n",
      "Name: 6139, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(pro_1d5r_df.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9da7e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pro_1d5r_df = pro_1d5r_df.sample(frac=1)\n",
    "# print(pro_1d5r_df.head(120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "31736b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounding score column to 6 decimal points\n",
    "pro_1d5r_df[\"score\"] = pro_1d5r_df[\"score\"].round(6)\n",
    "\n",
    "# shuffling\n",
    "pro_1d5r_df = pro_1d5r_df.sample(frac=1)\n",
    "\n",
    "# splitting variant list if there are multiple mutations\n",
    "pro_1d5r_mut = pro_1d5r_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "pro_1d5r_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(pro_1d5r_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "pro_1d5r_df[\"MUTATED_RES\"] = ssf.get_mutation_type(pro_1d5r_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "pro_1d5r_df[\"POSITION\"] = ssf.get_position(pro_1d5r_mut)\n",
    "\n",
    "# need positionssplit\n",
    "pro_1d5r_df[\"positions_split\"] = ssf.get_positions_split(pro_1d5r_df)\n",
    "\n",
    "positions_split_subtracted = []\n",
    "for pos_list in pro_1d5r_df[\"positions_split\"]:\n",
    "    # pos_list = [int(x) for x in xs] # cast to int\n",
    "    pos_list = [x - 14 for x in pos_list] # reset index at 301\n",
    "    positions_split_subtracted.append(pos_list)  \n",
    "\n",
    "pro_1d5r_df[\"positions_split\"] = positions_split_subtracted    \n",
    "    \n",
    "new_positions = []\n",
    "pos_string = \"\"\n",
    "for pos_list in pro_1d5r_df[\"positions_split\"]:\n",
    "    pos_string = \",\".join(map(str, pos_list))\n",
    "    new_positions.append(pos_string)\n",
    "    pos_string = \"\"\n",
    "\n",
    "pro_1d5r_df[\"POSITION\"] = new_positions # changes positions into new adjusted values (0 index)\n",
    "# replace variant column with reformatted variant name\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "pro_1d5r_df[\"variant\"] = ssf.get_mutations_names_list(pro_1d5r_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03959d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if value is greater than "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c99c87fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5833\n",
      "variant               43ILE\n",
      "score             -0.475134\n",
      "WILD_TYPE_RES             L\n",
      "MUTATED_RES               I\n",
      "POSITION                 43\n",
      "positions_split        [43]\n",
      "Name: 867, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print(len(pro_1d5r_df))\n",
    "# pro_1d5r_df = pro_1d5r_df.dropna(axis=0)\n",
    "print(len(pro_1d5r_df))\n",
    "print(pro_1d5r_df.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "07e21183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepti\\OneDrive\\UW\\GitHub\\secondary-structure-CNN-learning\\Jupyter Notebooks\\secStrucFormatting.py:591: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  in_domain_df = in_domain_df.append(rows, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "pro_1d5r_df = ssf.get_domain_dataset_v2(pro_1d5r_df, 0, 268, [])\n",
    "print(len(pro_1d5r_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d7d326b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_from_stride(stride_file):    \n",
    "    aa_str = \"\"\n",
    "\n",
    "    for line in stride_file:\n",
    "        if line.startswith('ASG'):\n",
    "            split_line = line.split()\n",
    "            aa_str =  aa_str + split_line[1] + \" \"\n",
    "\n",
    "    return aa_str.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1cc35c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARG ARG TYR GLN GLU ASP GLY PHE ASP LEU ASP LEU THR TYR ILE TYR PRO ASN ILE ILE ALA MET GLY PHE PRO ALA GLU ARG LEU GLU GLY VAL TYR ARG ASN ASN ILE ASP ASP VAL VAL ARG PHE LEU ASP SER LYS HIS LYS ASN HIS TYR LYS ILE TYR ASN LEU CYS ALA GLU ARG HIS TYR ASP THR ALA LYS PHE ASN CYS ARG VAL ALA GLN TYR PRO PHE GLU ASP HIS ASN PRO PRO GLN LEU GLU LEU ILE LYS PRO PHE CYS GLU ASP LEU ASP GLN TRP LEU SER GLU ASP ASP ASN HIS VAL ALA ALA ILE HIS CYS LYS ALA GLY LYS GLY ARG THR GLY VAL MET ILE CYS ALA TYR LEU LEU HIS ARG GLY LYS PHE LEU LYS ALA GLN GLU ALA LEU ASP PHE TYR GLY GLU VAL ARG THR ARG ASP LYS LYS GLY VAL THR ILE PRO SER GLN ARG ARG TYR VAL TYR TYR TYR SER TYR LEU LEU LYS ASN HIS LEU ASP TYR ARG PRO VAL ALA LEU LEU PHE HIS LYS MET MET PHE GLU THR ILE PRO MET PHE SER GLY GLY THR CYS ASN PRO GLN PHE VAL VAL CYS GLN LEU LYS VAL LYS ILE TYR SER SER ASN SER GLY PRO THR ARG ARG GLU ASP LYS PHE MET TYR PHE GLU PHE PRO GLN PRO LEU PRO VAL CYS GLY ASP ILE LYS VAL GLU PHE PHE HIS LYS GLN ASN LYS MET LEU LYS LYS ASP LYS MET PHE HIS PHE TRP VAL ASN THR PHE PHE ILE PRO LYS GLU TYR LEU VAL LEU THR LEU THR LYS ASN ASP LEU ASP LYS ALA ASN LYS ASP LYS ALA ASN ARG TYR PHE SER PRO ASN PHE LYS VAL LYS LEU TYR PHE THR LYS THR VAL\n",
      "\n",
      "ARG ARG TYR GLN GLU ASP GLY PHE ASP LEU ASP LEU THR TYR ILE TYR PRO ASN ILE ILE ALA MET GLY PHE PRO ALA GLU ARG LEU GLU GLY VAL TYR ARG ASN ASN ILE ASP ASP VAL VAL ARG PHE LEU ASP SER LYS HIS LYS ASN HIS TYR LYS ILE TYR ASN LEU CYS ALA GLU ARG HIS TYR ASP THR ALA LYS PHE ASN CYS ARG VAL ALA GLN TYR PRO PHE GLU ASP HIS ASN PRO PRO GLN LEU GLU LEU ILE LYS PRO PHE CYS GLU ASP LEU ASP GLN TRP LEU SER GLU ASP ASP ASN HIS VAL ALA ALA ILE HIS CYS LYS ALA GLY LYS GLY ARG THR GLY VAL MET ILE CYS ALA TYR LEU LEU HIS ARG GLY LYS PHE LEU LYS ALA GLN GLU ALA LEU ASP PHE TYR GLY GLU VAL ARG THR ARG ASP LYS LYS GLY VAL THR ILE PRO SER GLN ARG ARG TYR VAL TYR TYR TYR SER TYR LEU LEU LYS ASN HIS LEU ASP TYR ARG PRO VAL ALA LEU LEU PHE HIS LYS MET MET PHE GLU THR ILE PRO MET PHE SER GLY GLY THR CYS ASN PRO GLN PHE VAL VAL CYS GLN LEU LYS VAL LYS ILE TYR SER SER ASN SER GLY PRO THR ARG ARG GLU ASP LYS PHE MET TYR PHE GLU PHE PRO GLN PRO LEU PRO VAL CYS GLY ASP ILE LYS VAL GLU PHE PHE HIS LYS GLN ASN LYS MET LEU LYS LYS ASP LYS MET PHE HIS PHE TRP VAL ASN THR PHE PHE ILE PRO\n"
     ]
    }
   ],
   "source": [
    "path = \"../PDB and STRIDE Files/\" + '1d5r_stride.txt'\n",
    "pro_1d5r_stride_file = open(path, 'r')\n",
    "protein_seq_1d5r = get_seq_from_stride(pro_1d5r_stride_file)\n",
    "print(protein_seq_1d5r)\n",
    "protein_seq_1d5r_split_281 = protein_seq_1d5r.split()[0:268]\n",
    "protein_seq_1d5r = \" \".join(protein_seq_1d5r_split_281).rstrip()\n",
    "print()\n",
    "print(protein_seq_1d5r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f28b849e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "path = \"../PDB and STRIDE Files/\" + '1d5r_stride.txt'\n",
    "pro_1d5r_stride_file = open(path, 'r')\n",
    "\n",
    "pro_1d5r_ss_indexes = ssf.get_sec_struc_boolean(pro_1d5r_stride_file)\n",
    "pro_1d5r_ss_indexes = pro_1d5r_ss_indexes[0:268]\n",
    "\n",
    "print(pro_1d5r_ss_indexes.count(True))\n",
    "print(pro_1d5r_ss_indexes.count(False))\n",
    "\n",
    "# add in_sec_str_col\n",
    "# ro_1d5r_df = add_sec_str_col(pro_1d5r_df, pro_1d5r_ss_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3c1843b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need positionssplit\n",
    "pro_1d5r_df[\"positions_split\"] = ssf.get_positions_split(pro_1d5r_df)\n",
    "\n",
    "# pro_1d5r_only_ss_df = get_ss_dataset(pro_1d5r_df, pro_1d5r_ss_indexes, 0)\n",
    "# print(len(pro_1d5r_only_ss_df))\n",
    "# pro_1d5r_only_not_ss_df = get_not_ss_dataset(pro_1d5r_df, pro_1d5r_ss_indexes, 0)\n",
    "# print(len(pro_1d5r_only_not_ss_df))\n",
    "# pro_1d5r_no_mixed_pos_df = pd.concat([pro_1d5r_only_ss_df, pro_1d5r_only_not_ss_df])\n",
    "\n",
    "# # add in_sec_str_col\n",
    "# pro_1d5r_no_mixed_pos_df = add_sec_str_col(pro_1d5r_no_mixed_pos_df, pro_1d5r_ss_indexes, 0)\n",
    "pro_1d5r_no_mixed_pos_df = pro_1d5r_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8eed8e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5833\n"
     ]
    }
   ],
   "source": [
    "# shuffling data\n",
    "pro_1d5r_no_mixed_pos_df = pro_1d5r_no_mixed_pos_df.sample(frac=1)\n",
    "print(len(pro_1d5r_no_mixed_pos_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "52b336aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     320\n",
      "False    320\n",
      "Name: in_sec_str, dtype: int64\n",
      "True     64\n",
      "False    64\n",
      "Name: in_sec_str, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# getting training set (5k in ss, 5k not in ss)\n",
    "pro_1d5r_train_ss = pro_1d5r_no_mixed_pos_df[pro_1d5r_no_mixed_pos_df['in_sec_str'] == True].sample(320)\n",
    "pro_1d5r_train_not_ss = pro_1d5r_no_mixed_pos_df[pro_1d5r_no_mixed_pos_df['in_sec_str'] == False].sample(320)\n",
    "pro_1d5r_train_df = pd.concat([pro_1d5r_train_ss, pro_1d5r_train_not_ss])\n",
    "\n",
    "pro_1d5r_test_ss = pro_1d5r_no_mixed_pos_df[pro_1d5r_no_mixed_pos_df['in_sec_str'] == True].sample(64)\n",
    "pro_1d5r_test_not_ss = pro_1d5r_no_mixed_pos_df[pro_1d5r_no_mixed_pos_df['in_sec_str'] == False].sample(64)\n",
    "pro_1d5r_test_df = pd.concat([pro_1d5r_test_ss, pro_1d5r_test_not_ss])\n",
    "\n",
    "# getting test set (2.5k in ss, 2.5k not in ss)\n",
    "print(pro_1d5r_train_df['in_sec_str'].value_counts())\n",
    "print(pro_1d5r_test_df['in_sec_str'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5de6a367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Standard Deviation: 1.4858919179171781\n",
      "Dataset Mean: -1.0202802421875\n",
      "Dataset Median: -0.411464\n",
      "Kurtosis: 2.761339252794029\n",
      "1778   -0.336968\n",
      "155    -4.666513\n",
      "2605   -0.470044\n",
      "703    -4.155849\n",
      "3042   -1.538191\n",
      "743    -0.118060\n",
      "2617   -0.549067\n",
      "985    -0.274268\n",
      "1561   -0.773588\n",
      "1149   -0.032162\n",
      "Name: score, dtype: float64\n",
      "1778    5.194196\n",
      "155    -4.297762\n",
      "2605   -5.067028\n",
      "703    -6.928572\n",
      "3042   -6.722060\n",
      "743     2.021911\n",
      "2617   -3.805880\n",
      "985     5.860685\n",
      "1561   -3.631555\n",
      "1149    2.925409\n",
      "Name: score, dtype: float64\n",
      "1778   -0.336968\n",
      "155    -4.666513\n",
      "2605   -0.470044\n",
      "703    -4.155849\n",
      "3042   -1.538191\n",
      "743    -0.118060\n",
      "2617   -0.549067\n",
      "985    -0.274268\n",
      "1561   -0.773588\n",
      "1149   -0.032162\n",
      "Name: score, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_18804\\2551423058.py:36: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(unchanged_scores[0:10])\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_18804\\2551423058.py:38: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(ss_scores[0:10])\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_18804\\2551423058.py:40: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(not_ss_scores[0:10])\n"
     ]
    }
   ],
   "source": [
    "# adding noise to values from uniform distribution and creating files\n",
    "\n",
    "# finding standard deviation of dataset scores\n",
    "std = pro_1d5r_train_df['score'].std()\n",
    "mean = pro_1d5r_train_df['score'].mean()\n",
    "median = pro_1d5r_train_df['score'].median()\n",
    "print(\"Dataset Standard Deviation: \" + str(std))\n",
    "print(\"Dataset Mean: \" + str(mean))\n",
    "print(\"Dataset Median: \" + str(median))\n",
    "print(\"Kurtosis: \" + str(kurtosis(pro_1d5r_train_df['score'], fisher=False)))\n",
    "\n",
    "# finding number of ss and not ss values\n",
    "num_ss_vals = (pro_1d5r_train_df.in_sec_str == True).sum()\n",
    "num_not_ss_vals = (pro_1d5r_train_df.in_sec_str == False).sum()\n",
    "\n",
    "# creating noise (std not the exact same, but similar) // 0 is the mean of the normal distribution\n",
    "noise_ss = np.random.normal(0, std * 3, num_ss_vals).tolist()\n",
    "noise_ss_v2 = noise_ss.copy()\n",
    "noise_not_ss = np.random.normal(0, std * 3, num_not_ss_vals).tolist()\n",
    "\n",
    "# filling in values for not ss indexes in noise_ss\n",
    "bool_ss_list = pro_1d5r_train_df.in_sec_str.values.tolist()\n",
    "\n",
    "noise_ss_to_add = []\n",
    "noise_not_ss_to_add = []\n",
    "\n",
    "for ss_assign in bool_ss_list:\n",
    "    if ss_assign: # if true (ss index)\n",
    "        noise_ss_to_add.append(noise_ss.pop(0))\n",
    "        noise_not_ss_to_add.append(0)\n",
    "    else: # if false (not ss index)\n",
    "        noise_ss_to_add.append(0)\n",
    "        noise_not_ss_to_add.append(noise_not_ss.pop(0))\n",
    "        \n",
    "unchanged_scores = pro_1d5r_train_df['score']\n",
    "print(unchanged_scores[0:10])\n",
    "ss_scores = pro_1d5r_train_df['score'] + noise_ss_to_add\n",
    "print(ss_scores[0:10])\n",
    "not_ss_scores = pro_1d5r_train_df['score'] + noise_not_ss_to_add\n",
    "print(not_ss_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "69591583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1884563796874992\n",
      "\n",
      "2.440543060039322\n",
      "Percentage Change: 105.35402912146048\n",
      "2.5532383129878267\n",
      "Percentage Change: 114.8365187504141\n"
     ]
    }
   ],
   "source": [
    "abs_val_list = [abs(x) for x in pro_1d5r_train_df['score']]\n",
    "mean = sum(abs_val_list) / len(abs_val_list)\n",
    "print(mean)\n",
    "print()\n",
    "\n",
    "abs_ss_val_list = [abs(x) for x in ss_scores]\n",
    "mean_ss = sum(abs_ss_val_list) / len(abs_ss_val_list)\n",
    "print(mean_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_ss - mean) / mean) * 100))\n",
    "\n",
    "abs_not_ss_val_list = [abs(x) for x in not_ss_scores]\n",
    "mean_not_ss = sum(abs_not_ss_val_list) / len(abs_not_ss_val_list)\n",
    "print(mean_not_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_not_ss - mean) / mean) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2a84bdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: 1d5r_trainbatch_train_36_test_10_t3.txt\n"
     ]
    }
   ],
   "source": [
    "# creating files (NO NOISE for test values)\n",
    "\n",
    "# unchanged\n",
    "# pro_1d5r_train_df['score'] = unchanged_scores\n",
    "# pro_1d5r_full_df = pd.concat([pro_1d5r_train_df, pro_1d5r_test_df])\n",
    "pro_1d5r_full_df = pro_1d5r_no_mixed_pos_df.sample(46)\n",
    "ssf.write_data_file(\"1d5r_trainbatch_train_36_test_10_t3\", protein_seq_1d5r, pro_1d5r_full_df)\n",
    "\n",
    "# # ss\n",
    "# pro_1d5r_train_df['score'] = ss_scores\n",
    "# pro_1d5r_full_df = pd.concat([pro_1d5r_train_df, pro_1d5r_test_df])\n",
    "# ssf.write_data_file(\"pro_1d5r_MLformat_500_train_200_ss_noise_t2_v2\", protein_seq_1d5r, pro_1d5r_full_df)\n",
    "\n",
    "# # not ss\n",
    "# pro_1d5r_train_df['score'] = not_ss_scores\n",
    "# pro_1d5r_full_df = pd.concat([pro_1d5r_train_df, pro_1d5r_test_df])\n",
    "# ssf.write_data_file(\"pro_1d5r_MLformat_500_train_200_not_ss_noise_t2_v2\", protein_seq_1d5r, pro_1d5r_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e534fb8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3a4d0b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pro_1d5r_train_df, pro_1d5r_test_df, pro_1d5r_remaining_df = get_train_and_test_df(pro_1d5r_df, 0.55, 235)\n",
    "# pro_1d5r_df_format = pd.concat([pro_1d5r_train_df, pro_1d5r_test_df])\n",
    "# print(len(pro_1d5r_df_format))\n",
    "# ssf.write_data_file(\"pro_1d5r_MLformat_235_train_1317_test_t3\", protein_seq_1d5r, pro_1d5r_df_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c1d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "## figure out protein sequence that is not working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e9e16",
   "metadata": {},
   "source": [
    "### 1nd4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "395cb654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "pro_1nd4_df1 = pd.read_csv(\"../Raw Data/1nd4.txt\", sep=\",\")\n",
    "\n",
    "# renaming mutated residue column\n",
    "pro_1nd4_df1 = pro_1nd4_df1.rename(columns={\"Unnamed: 0\": \"mutated_res\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a9345681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganizing data to other form\n",
    "col_list_1nd4 = list(pro_1nd4_df1)\n",
    "col_list_1nd4 = col_list_1nd4[1:]\n",
    "\n",
    "# mutations going down from the leftmost column\n",
    "mutations_1nd4 = []\n",
    "\n",
    "for column in col_list_1nd4:\n",
    "    for mutation in pro_1nd4_df1[\"mutated_res\"]:\n",
    "        mutations_1nd4.append(column + mutation)\n",
    "\n",
    "# getting scores\n",
    "scores_1nd4 = []\n",
    "\n",
    "for column in pro_1nd4_df1.drop('mutated_res', axis=1):\n",
    "    for val in pro_1nd4_df1[column]:\n",
    "        scores_1nd4.append(val)\n",
    "    \n",
    "# adding to df and renaming variant and score to match formatting for other proteins\n",
    "pro_1nd4_df = pd.DataFrame(list(zip(mutations_1nd4, scores_1nd4)),\n",
    "               columns =['variant', 'score'])\n",
    "\n",
    "# i have the data, next is formatting it so i can add the indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "463df3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100\n",
      "5095\n"
     ]
    }
   ],
   "source": [
    "# drop nans\n",
    "print(len(pro_1nd4_df))\n",
    "pro_1nd4_df = pro_1nd4_df.dropna(axis=0)\n",
    "pro_1nd4_df = pro_1nd4_df[pro_1nd4_df['score'] != 0.0]\n",
    "print(len(pro_1nd4_df))\n",
    "# print(pro_1nd4_df.tail(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "056eedbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounding score column to 6 decimal points\n",
    "pro_1nd4_df[\"score\"] = pro_1nd4_df[\"score\"].round(6)\n",
    "\n",
    "# shuffling\n",
    "pro_1nd4_df = pro_1nd4_df.sample(frac=1)\n",
    "\n",
    "# splitting variant list if there are multiple mutations\n",
    "pro_1nd4_mut = pro_1nd4_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "pro_1nd4_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(pro_1nd4_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "pro_1nd4_df[\"MUTATED_RES\"] = ssf.get_mutation_type(pro_1nd4_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "pro_1nd4_df[\"POSITION\"] = ssf.get_position(pro_1nd4_mut)\n",
    "\n",
    "# need positionssplit\n",
    "pro_1nd4_df[\"positions_split\"] = ssf.get_positions_split(pro_1nd4_df)\n",
    "\n",
    "positions_split_subtracted = []\n",
    "for pos_list in pro_1nd4_df[\"positions_split\"]:\n",
    "    pos_list = [x - 10 for x in pos_list] # reset index at 301\n",
    "    positions_split_subtracted.append(pos_list)  \n",
    "\n",
    "pro_1nd4_df[\"positions_split\"] = positions_split_subtracted    \n",
    "    \n",
    "new_positions = []\n",
    "pos_string = \"\"\n",
    "for pos_list in pro_1nd4_df[\"positions_split\"]:\n",
    "    pos_string = \",\".join(map(str, pos_list))\n",
    "    new_positions.append(pos_string)\n",
    "    pos_string = \"\"\n",
    "\n",
    "pro_1nd4_df[\"POSITION\"] = new_positions # changes positions into new adjusted values (0 index)\n",
    "# replace variant column with reformatted variant name\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "pro_1nd4_df[\"variant\"] = ssf.get_mutations_names_list(pro_1nd4_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "# to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "57efe78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5095\n"
     ]
    }
   ],
   "source": [
    "print(len(pro_1nd4_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dd75b5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510\n",
      "PHE\n"
     ]
    }
   ],
   "source": [
    "string_seq_1nd4 = \"GSPAAWVERLFGYDWAQQTIGCSDAAVFRLSAQGRPVLFVKTDLSGALNELQDEAARLSWLATTGVPCAAVLDVVTEAGRDWLLLGEVPGQDLLSSHLAPAEKVSIMADAMRRLHTLDPATCPFDHQAKHRIERARTRMEAGLVDQDDLDEEHQGLAPAELFARLKARMPDGEDLVVTHGDACLPNIMVENGRFSGFIDCGRLGVADRYQDIALATRDIAEELGGEWADRFLVLYGIAAPDSQRIAFYRLLDEFFGSPAAWVERLFGYDWAQQTIGCSDAAVFRLSAQGRPVLFVKTDLSGALNELQDEAARLSWLATTGVPCAAVLDVVTEAGRDWLLLGEVPGQDLLSSHLAPAEKVSIMADAMRRLHTLDPATCPFDHQAKHRIERARTRMEAGLVDQDDLDEEHQGLAPAELFARLKARMPDGEDLVVTHGDACLPNIMVENGRFSGFIDCGRLGVADRYQDIALATRDIAEELGGEWADRFLVLYGIAAPDSQRIAFYRLLDEFF\"\n",
    "protein_seq_1nd4 = ssf.get_expanded_seq(string_seq_1nd4)\n",
    "protein_seq_1nd4_split = protein_seq_1nd4.split()\n",
    "print(len(protein_seq_1nd4_split))\n",
    "print(protein_seq_1nd4_split[38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3585ebdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510\n",
      "415\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "path = \"../PDB and STRIDE Files/\" + '1nd4_stride.txt'\n",
    "pro_1nd4_stride_file = open(path, 'r')\n",
    "\n",
    "pro_1nd4_ss_indexes = ssf.get_all_sec_struc_boolean(pro_1nd4_stride_file)\n",
    "print(len(pro_1nd4_ss_indexes))\n",
    "print(pro_1nd4_ss_indexes.count(True))\n",
    "print(pro_1nd4_ss_indexes.count(False))\n",
    "\n",
    "# add in_sec_str_col\n",
    "pro_1nd4_df = add_sec_str_col(pro_1nd4_df, pro_1nd4_ss_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cddc6499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len5095\n",
      "810\n",
      "190\n",
      "Train Data Fraction: 0.81\n",
      "false_df len880\n",
      "true_df len4215\n",
      "in fraction,df len4095\n",
      "Test Data Fraction: 0.81\n",
      "false_df len690\n",
      "true_df len3405\n",
      "Size of Test Dataset: 3626\n",
      "Size of Total Dataset: 4626\n",
      "4626\n",
      "Filename: pro_1nd4_MLformat_1000_train_3626_test_t3.txt\n"
     ]
    }
   ],
   "source": [
    "pro_1nd4_train_df, pro_1nd4_test_df, pro_1nd4_remaining_df = get_train_and_test_df(pro_1nd4_df, 0.81, 1000)\n",
    "pro_1nd4_df_format = pd.concat([pro_1nd4_train_df, pro_1nd4_test_df])\n",
    "print(len(pro_1nd4_df_format))\n",
    "ssf.write_data_file(\"pro_1nd4_MLformat_1000_train_3626_test_t3\", protein_seq_1nd4, pro_1nd4_df_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f925074",
   "metadata": {},
   "source": [
    "# Adding Noise to 1nd4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c000ac33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100\n",
      "5095\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "pro_1nd4_df1 = pd.read_csv(\"../Raw Data/1nd4.txt\", sep=\",\")\n",
    "\n",
    "# renaming mutated residue column\n",
    "pro_1nd4_df1 = pro_1nd4_df1.rename(columns={\"Unnamed: 0\": \"mutated_res\"})\n",
    "\n",
    "# reorganizing data to other form\n",
    "col_list_1nd4 = list(pro_1nd4_df1)\n",
    "col_list_1nd4 = col_list_1nd4[1:]\n",
    "\n",
    "# mutations going down from the leftmost column\n",
    "mutations_1nd4 = []\n",
    "\n",
    "for column in col_list_1nd4:\n",
    "    for mutation in pro_1nd4_df1[\"mutated_res\"]:\n",
    "        mutations_1nd4.append(column + mutation)\n",
    "\n",
    "# getting scores\n",
    "scores_1nd4 = []\n",
    "\n",
    "for column in pro_1nd4_df1.drop('mutated_res', axis=1):\n",
    "    for val in pro_1nd4_df1[column]:\n",
    "        scores_1nd4.append(val)\n",
    "    \n",
    "# adding to df and renaming variant and score to match formatting for other proteins\n",
    "pro_1nd4_df = pd.DataFrame(list(zip(mutations_1nd4, scores_1nd4)),\n",
    "               columns =['variant', 'score'])\n",
    "\n",
    "# i have the data, next is formatting it so i can add the indexes\n",
    "\n",
    "# drop nans\n",
    "print(len(pro_1nd4_df))\n",
    "pro_1nd4_df = pro_1nd4_df.dropna(axis=0)\n",
    "pro_1nd4_df = pro_1nd4_df[pro_1nd4_df['score'] != 0.0]\n",
    "print(len(pro_1nd4_df))\n",
    "# print(pro_1nd4_df.tail(30))\n",
    "\n",
    "# rounding score column to 6 decimal points\n",
    "pro_1nd4_df[\"score\"] = pro_1nd4_df[\"score\"].round(6)\n",
    "\n",
    "# shuffling\n",
    "pro_1nd4_df = pro_1nd4_df.sample(frac=1)\n",
    "\n",
    "# splitting variant list if there are multiple mutations\n",
    "pro_1nd4_mut = pro_1nd4_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "pro_1nd4_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(pro_1nd4_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "pro_1nd4_df[\"MUTATED_RES\"] = ssf.get_mutation_type(pro_1nd4_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "pro_1nd4_df[\"POSITION\"] = ssf.get_position(pro_1nd4_mut)\n",
    "\n",
    "# need positionssplit\n",
    "pro_1nd4_df[\"positions_split\"] = ssf.get_positions_split(pro_1nd4_df)\n",
    "\n",
    "positions_split_subtracted = []\n",
    "for pos_list in pro_1nd4_df[\"positions_split\"]:\n",
    "    pos_list = [x - 10 for x in pos_list] # reset index at 301\n",
    "    positions_split_subtracted.append(pos_list)  \n",
    "\n",
    "pro_1nd4_df[\"positions_split\"] = positions_split_subtracted    \n",
    "    \n",
    "new_positions = []\n",
    "pos_string = \"\"\n",
    "for pos_list in pro_1nd4_df[\"positions_split\"]:\n",
    "    pos_string = \",\".join(map(str, pos_list))\n",
    "    new_positions.append(pos_string)\n",
    "    pos_string = \"\"\n",
    "\n",
    "pro_1nd4_df[\"POSITION\"] = new_positions # changes positions into new adjusted values (0 index)\n",
    "# replace variant column with reformatted variant name\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "pro_1nd4_df[\"variant\"] = ssf.get_mutations_names_list(pro_1nd4_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "# to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0b38ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# secondary structure assignments\n",
    "path = \"../PDB and STRIDE Files/\" + '1nd4_stride.txt'\n",
    "pro_1nd4_stride_file = open(path, 'r')\n",
    "\n",
    "pro_1nd4_ss_indexes = ssf.get_sec_struc_boolean(pro_1nd4_stride_file) # not including turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "841bd421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # need positionssplit\n",
    "# pro_1nd4_df[\"positions_split\"] = ssf.get_positions_split(pro_1nd4_df)\n",
    "\n",
    "# pro_1nd4_only_ss_df = get_ss_dataset(pro_1nd4_df, pro_1nd4_ss_indexes, 0)\n",
    "# pro_1nd4_only_not_ss_df = get_not_ss_dataset(pro_1nd4_df, pro_1nd4_ss_indexes, 0)\n",
    "# pro_1nd4_no_mixed_pos_df = pd.concat([pro_1nd4_only_ss_df, pro_1nd4_only_not_ss_df])\n",
    "\n",
    "# add in_sec_str_col\n",
    "# pro_1nd4_no_mixed_pos_df = add_sec_str_col(pro_1nd4_no_mixed_pos_df, pro_1nd4_ss_indexes, 0)\n",
    "pro_1nd4_no_mixed_pos_df = pro_1nd4_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "15ac647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # need positionssplit\n",
    "# pro_1nd4_df[\"positions_split\"] = ssf.get_positions_split(pro_1nd4_df)\n",
    "\n",
    "# # add in_sec_str_col\n",
    "# pro_1nd4_df = add_sec_str_col(pro_1nd4_df, pro_1nd4_ss_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "dac2bef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5095\n"
     ]
    }
   ],
   "source": [
    "# shuffling data\n",
    "pro_1nd4_no_mixed_pos_df = pro_1nd4_no_mixed_pos_df.sample(frac=1)\n",
    "print(len(pro_1nd4_no_mixed_pos_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4bf993ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pro_1nd4_no_mixed_pos_df['in_sec_str'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c4f6500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein sequence\n",
    "string_seq_1nd4 = \"GSPAAWVERLFGYDWAQQTIGCSDAAVFRLSAQGRPVLFVKTDLSGALNELQDEAARLSWLATTGVPCAAVLDVVTEAGRDWLLLGEVPGQDLLSSHLAPAEKVSIMADAMRRLHTLDPATCPFDHQAKHRIERARTRMEAGLVDQDDLDEEHQGLAPAELFARLKARMPDGEDLVVTHGDACLPNIMVENGRFSGFIDCGRLGVADRYQDIALATRDIAEELGGEWADRFLVLYGIAAPDSQRIAFYRLLDEFFGSPAAWVERLFGYDWAQQTIGCSDAAVFRLSAQGRPVLFVKTDLSGALNELQDEAARLSWLATTGVPCAAVLDVVTEAGRDWLLLGEVPGQDLLSSHLAPAEKVSIMADAMRRLHTLDPATCPFDHQAKHRIERARTRMEAGLVDQDDLDEEHQGLAPAELFARLKARMPDGEDLVVTHGDACLPNIMVENGRFSGFIDCGRLGVADRYQDIALATRDIAEELGGEWADRFLVLYGIAAPDSQRIAFYRLLDEFF\"\n",
    "protein_seq_pro_1nd4 = ssf.get_expanded_seq(string_seq_1nd4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c274ae2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     848\n",
      "False    848\n",
      "Name: in_sec_str, dtype: int64\n",
      "True     110\n",
      "False    110\n",
      "Name: in_sec_str, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# getting training set (5k in ss, 5k not in ss)\n",
    "pro_1nd4_train_ss = pro_1nd4_no_mixed_pos_df[pro_1nd4_no_mixed_pos_df['in_sec_str'] == True].sample(848)\n",
    "pro_1nd4_train_not_ss = pro_1nd4_no_mixed_pos_df[pro_1nd4_no_mixed_pos_df['in_sec_str'] == False].sample(848)\n",
    "pro_1nd4_train_df = pd.concat([pro_1nd4_train_ss, pro_1nd4_train_not_ss])\n",
    "\n",
    "pro_1nd4_test_ss = pro_1nd4_no_mixed_pos_df[pro_1nd4_no_mixed_pos_df['in_sec_str'] == True].sample(110)\n",
    "pro_1nd4_test_not_ss = pro_1nd4_no_mixed_pos_df[pro_1nd4_no_mixed_pos_df['in_sec_str'] == False].sample(110)\n",
    "pro_1nd4_test_df = pd.concat([pro_1nd4_test_ss, pro_1nd4_test_not_ss])\n",
    "\n",
    "# getting test set (2.5k in ss, 2.5k not in ss)\n",
    "print(pro_1nd4_train_df['in_sec_str'].value_counts())\n",
    "print(pro_1nd4_test_df['in_sec_str'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2b75f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # getting dataset with correct ratios (only using training dataset)\n",
    "# pro_1nd4_train_df, pro_1nd4_test_df, pro_1nd4_remaining_df = get_train_and_test_df(pro_1nd4_df, 0.61, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "9297dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pro_1nd4_train_df_2, pro_1nd4_test_df, pro_1nd4_remaining_df_1 = get_train_and_test_df(pro_1nd4_test_df_1, 0.69, 371000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "070998b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Standard Deviation: 0.5679105222231424\n",
      "Dataset Mean: -0.37685712794811327\n",
      "Dataset Median: -0.4297575\n",
      "Kurtosis: 2.326323089196269\n",
      "562     0.037068\n",
      "707     0.033625\n",
      "1611    0.411098\n",
      "942    -0.048808\n",
      "136     0.000911\n",
      "723    -0.784098\n",
      "39     -1.040005\n",
      "535    -1.205512\n",
      "2036   -0.310869\n",
      "865    -1.097453\n",
      "Name: score, dtype: float64\n",
      "562    -0.854241\n",
      "707     0.444865\n",
      "1611   -0.033634\n",
      "942     0.831728\n",
      "136     1.140703\n",
      "723     0.074176\n",
      "39     -2.303285\n",
      "535    -2.517019\n",
      "2036    1.237661\n",
      "865    -5.594755\n",
      "Name: score, dtype: float64\n",
      "562     0.037068\n",
      "707     0.033625\n",
      "1611    0.411098\n",
      "942    -0.048808\n",
      "136     0.000911\n",
      "723    -0.784098\n",
      "39     -1.040005\n",
      "535    -1.205512\n",
      "2036   -0.310869\n",
      "865    -1.097453\n",
      "Name: score, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_18804\\2300427979.py:36: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(unchanged_scores[0:10])\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_18804\\2300427979.py:38: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(ss_scores[0:10])\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_18804\\2300427979.py:40: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(not_ss_scores[0:10])\n"
     ]
    }
   ],
   "source": [
    "# adding noise to values from uniform distribution and creating files\n",
    "\n",
    "# finding standard deviation of dataset scores\n",
    "std = pro_1nd4_train_df['score'].std()\n",
    "mean = pro_1nd4_train_df['score'].mean()\n",
    "median = pro_1nd4_train_df['score'].median()\n",
    "print(\"Dataset Standard Deviation: \" + str(std))\n",
    "print(\"Dataset Mean: \" + str(mean))\n",
    "print(\"Dataset Median: \" + str(median))\n",
    "print(\"Kurtosis: \" + str(kurtosis(pro_1nd4_train_df['score'], fisher=False)))\n",
    "\n",
    "# finding number of ss and not ss values\n",
    "num_ss_vals = (pro_1nd4_train_df.in_sec_str == True).sum()\n",
    "num_not_ss_vals = (pro_1nd4_train_df.in_sec_str == False).sum()\n",
    "\n",
    "# creating noise (std not the exact same, but similar) // 0 is the mean of the normal distribution\n",
    "noise_ss = np.random.normal(0, std * 3.0, num_ss_vals).tolist()\n",
    "noise_ss_v2 = noise_ss.copy()\n",
    "noise_not_ss = np.random.normal(0, std * 3.0, num_not_ss_vals).tolist()\n",
    "\n",
    "# filling in values for not ss indexes in noise_ss\n",
    "bool_ss_list = pro_1nd4_train_df.in_sec_str.values.tolist()\n",
    "\n",
    "noise_ss_to_add = []\n",
    "noise_not_ss_to_add = []\n",
    "\n",
    "for ss_assign in bool_ss_list:\n",
    "    if ss_assign: # if true (ss index)\n",
    "        noise_ss_to_add.append(noise_ss.pop(0))\n",
    "        noise_not_ss_to_add.append(0)\n",
    "    else: # if false (not ss index)\n",
    "        noise_ss_to_add.append(0)\n",
    "        noise_not_ss_to_add.append(noise_not_ss.pop(0))\n",
    "        \n",
    "unchanged_scores = pro_1nd4_train_df['score']\n",
    "print(unchanged_scores[0:10])\n",
    "ss_scores = pro_1nd4_train_df['score'] + noise_ss_to_add\n",
    "print(ss_scores[0:10])\n",
    "not_ss_scores = pro_1nd4_train_df['score'] + noise_not_ss_to_add\n",
    "print(not_ss_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f6e14578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5893515495000006\n",
      "\n",
      "1.0294614104536104\n",
      "Percentage Change: 74.67696679969607\n",
      "1.045960498225399\n",
      "Percentage Change: 77.4764992325515\n"
     ]
    }
   ],
   "source": [
    "abs_val_list = [abs(x) for x in pro_1nd4_train_df['score']]\n",
    "mean = sum(abs_val_list) / len(abs_val_list)\n",
    "print(mean)\n",
    "print()\n",
    "\n",
    "abs_ss_val_list = [abs(x) for x in ss_scores]\n",
    "mean_ss = sum(abs_ss_val_list) / len(abs_ss_val_list)\n",
    "print(mean_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_ss - mean) / mean) * 100))\n",
    "\n",
    "abs_not_ss_val_list = [abs(x) for x in not_ss_scores]\n",
    "mean_not_ss = sum(abs_not_ss_val_list) / len(abs_not_ss_val_list)\n",
    "print(mean_not_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_not_ss - mean) / mean) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "236fed2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: pro_1nd4_MLformat_3000_train_1979_no_noise_t1.txt\n",
      "Filename: pro_1nd4_MLformat_3000_train_1979_ss_noise_t1.txt\n",
      "Filename: pro_1nd4_MLformat_3000_train_1979_not_ss_noise_t1.txt\n"
     ]
    }
   ],
   "source": [
    "# # creating files (NO NOISE for test values)\n",
    "\n",
    "# # unchanged\n",
    "# pro_1nd4_train_df['score'] = unchanged_scores\n",
    "# pro_1nd4_full_df = pd.concat([pro_1nd4_train_df, pro_1nd4_test_df])\n",
    "# ssf.write_data_file(\"pro_1nd4_MLformat_3000_train_1979_no_noise_t1\", protein_seq_pro_1nd4, pro_1nd4_full_df)\n",
    "\n",
    "# # ss\n",
    "# pro_1nd4_train_df['score'] = ss_scores\n",
    "# pro_1nd4_full_df = pd.concat([pro_1nd4_train_df, pro_1nd4_test_df])\n",
    "# ssf.write_data_file(\"pro_1nd4_MLformat_3000_train_1979_ss_noise_t1\", protein_seq_pro_1nd4, pro_1nd4_full_df)\n",
    "\n",
    "# # not ss\n",
    "# pro_1nd4_train_df['score'] = not_ss_scores\n",
    "# pro_1nd4_full_df = pd.concat([pro_1nd4_train_df, pro_1nd4_test_df])\n",
    "# ssf.write_data_file(\"pro_1nd4_MLformat_3000_train_1979_not_ss_noise_t1\", protein_seq_pro_1nd4, pro_1nd4_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7c27592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: 1nd4_trainbatch_train_32_test_8_t3.txt\n"
     ]
    }
   ],
   "source": [
    "# creating files (NO NOISE for test values)\n",
    "\n",
    "# unchanged\n",
    "# pro_1nd4_train_df['score'] = unchanged_scores\n",
    "# pro_1nd4_full_df = pd.concat([pro_1nd4_train_df, pro_1nd4_test_df])\n",
    "pro_1nd4_full_df = pro_1nd4_no_mixed_pos_df.sample(40)\n",
    "ssf.write_data_file(\"1nd4_trainbatch_train_32_test_8_t3\", protein_seq_pro_1nd4, pro_1nd4_full_df)\n",
    "\n",
    "# # ss\n",
    "# pro_1nd4_train_df['score'] = ss_scores\n",
    "# pro_1nd4_full_df = pd.concat([pro_1nd4_train_df, pro_1nd4_test_df])\n",
    "# ssf.write_data_file(\"pro_1nd4_MLformat_2000_train_1000_ss_noise_t2_v2\", protein_seq_pro_1nd4, pro_1nd4_full_df)\n",
    "\n",
    "# # not ss\n",
    "# pro_1nd4_train_df['score'] = not_ss_scores\n",
    "# pro_1nd4_full_df = pd.concat([pro_1nd4_train_df, pro_1nd4_test_df])\n",
    "# ssf.write_data_file(\"pro_1nd4_MLformat_2000_train_1000_not_ss_noise_t2_v2\", protein_seq_pro_1nd4, pro_1nd4_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ea8f664e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: pro_1nd4_trainbatch_train_32_test_1019_t3.txt\n"
     ]
    }
   ],
   "source": [
    "pro_1nd4_full_df = pro_1nd4_no_mixed_pos_df.sample(1051)\n",
    "ssf.write_data_file(\"pro_1nd4_trainbatch_train_32_test_1019_t3\", protein_seq_pro_1nd4, pro_1nd4_full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61c2acf",
   "metadata": {},
   "source": [
    "### 3dqw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cd73fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "pro_3dqw_df1 = pd.read_csv(\"../Raw Data/3dqw.txt\", sep=\",\")\n",
    "\n",
    "# renaming mutated residue column\n",
    "pro_3dqw_df1 = pro_3dqw_df1.rename(columns={\"Unnamed: 0\": \"mutated_res\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "033342eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganizing data to other form\n",
    "col_list_3dqw = list(pro_3dqw_df1)\n",
    "col_list_3dqw = col_list_3dqw[1:]\n",
    "\n",
    "# mutations going down from the leftmost column\n",
    "mutations_3dqw = []\n",
    "\n",
    "for column in col_list_3dqw:\n",
    "    for mutation in pro_3dqw_df1[\"mutated_res\"]:\n",
    "        mutations_3dqw.append(column + mutation)\n",
    "\n",
    "# getting scores\n",
    "scores_3dqw = []\n",
    "\n",
    "for column in pro_3dqw_df1.drop('mutated_res', axis=1):\n",
    "    for val in pro_3dqw_df1[column]:\n",
    "        scores_3dqw.append(val)\n",
    "    \n",
    "# adding to df and renaming variant and score to match formatting for other proteins\n",
    "pro_3dqw_df = pd.DataFrame(list(zip(mutations_3dqw, scores_3dqw)),\n",
    "               columns =['variant', 'score'])\n",
    "\n",
    "# i have the data, next is formatting it so i can add the indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84c03b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3315\n"
     ]
    }
   ],
   "source": [
    "pro_3dqw_df = pro_3dqw_df.dropna(axis=0)\n",
    "print(len(pro_3dqw_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1845e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounding score column to 6 decimal points\n",
    "pro_3dqw_df[\"score\"] = pro_3dqw_df[\"score\"].round(6)\n",
    "\n",
    "# shuffling\n",
    "pro_3dqw_df = pro_3dqw_df.sample(frac=1)\n",
    "\n",
    "# splitting variant list if there are multiple mutations\n",
    "pro_3dqw_mut = pro_3dqw_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "pro_3dqw_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(pro_3dqw_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "pro_3dqw_df[\"MUTATED_RES\"] = ssf.get_mutation_type(pro_3dqw_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "pro_3dqw_df[\"POSITION\"] = ssf.get_position(pro_3dqw_mut)\n",
    "\n",
    "# need positionssplit\n",
    "pro_3dqw_df[\"positions_split\"] = ssf.get_positions_split(pro_3dqw_df)\n",
    "\n",
    "positions_split_subtracted = []\n",
    "for pos_list in pro_3dqw_df[\"positions_split\"]:\n",
    "    pos_list = [x - 255 for x in pos_list] # reset index at 301\n",
    "    positions_split_subtracted.append(pos_list)  \n",
    "\n",
    "pro_3dqw_df[\"positions_split\"] = positions_split_subtracted    \n",
    "    \n",
    "new_positions = []\n",
    "pos_string = \"\"\n",
    "for pos_list in pro_3dqw_df[\"positions_split\"]:\n",
    "    pos_string = \",\".join(map(str, pos_list))\n",
    "    new_positions.append(pos_string)\n",
    "    pos_string = \"\"\n",
    "\n",
    "pro_3dqw_df[\"POSITION\"] = new_positions # changes positions into new adjusted values (0 index)\n",
    "# replace variant column with reformatted variant name\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "pro_3dqw_df[\"variant\"] = ssf.get_mutations_names_list(pro_3dqw_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ac17bd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3315\n"
     ]
    }
   ],
   "source": [
    "print(len(pro_3dqw_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7f7a2e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../PDB and STRIDE Files/\" + '3dqw_stride.txt'\n",
    "pro_3dqw_stride_file = open(path, 'r')\n",
    "protein_seq_3dqw = get_seq_from_stride(pro_3dqw_stride_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2b535d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1107\n",
      "VAL\n"
     ]
    }
   ],
   "source": [
    "protein_seq_3dqw_split = protein_seq_3dqw.split()\n",
    "print(len(protein_seq_3dqw_split))\n",
    "print(protein_seq_3dqw_split[128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "37fd9cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1107\n",
      "926\n",
      "181\n"
     ]
    }
   ],
   "source": [
    "path = \"../PDB and STRIDE Files/\" + '3dqw_stride.txt'\n",
    "pro_3dqw_stride_file = open(path, 'r')\n",
    "\n",
    "pro_3dqw_ss_indexes = ssf.get_all_sec_struc_boolean(pro_3dqw_stride_file)\n",
    "print(len(pro_3dqw_ss_indexes))\n",
    "print(pro_3dqw_ss_indexes.count(True))\n",
    "print(pro_3dqw_ss_indexes.count(False))\n",
    "\n",
    "# add in_sec_str_col\n",
    "pro_3dqw_df = add_sec_str_col(pro_3dqw_df, pro_3dqw_ss_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "64e2986f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len3315\n",
      "1822\n",
      "348\n",
      "Train Data Fraction: 0.84\n",
      "false_df len579\n",
      "true_df len2736\n",
      "in fraction,df len1145\n",
      "Test Data Fraction: 0.84\n",
      "false_df len231\n",
      "true_df len914\n",
      "Size of Test Dataset: 1087\n",
      "Size of Total Dataset: 3257\n",
      "3257\n",
      "Filename: pro_3dqw_MLformat_2170_train_1087_test_t3.txt\n"
     ]
    }
   ],
   "source": [
    "pro_3dqw_train_df, pro_3dqw_test_df, pro_3dqw_remaining_df = get_train_and_test_df(pro_3dqw_df, 0.84, 2170)\n",
    "pro_3dqw_df_format = pd.concat([pro_3dqw_train_df, pro_3dqw_test_df])\n",
    "print(len(pro_3dqw_df_format))\n",
    "ssf.write_data_file(\"pro_3dqw_MLformat_2170_train_1087_test_t3\", protein_seq_3dqw, pro_3dqw_df_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da28e58",
   "metadata": {},
   "source": [
    "# Adding Noise to 3dqw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c18e2084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "pro_3dqw_df1 = pd.read_csv(\"../Raw Data/3dqw.txt\", sep=\",\")\n",
    "\n",
    "# renaming mutated residue column\n",
    "pro_3dqw_df1 = pro_3dqw_df1.rename(columns={\"Unnamed: 0\": \"mutated_res\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b6a211b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganizing data to other form\n",
    "col_list_3dqw = list(pro_3dqw_df1)\n",
    "col_list_3dqw = col_list_3dqw[1:]\n",
    "\n",
    "# mutations going down from the leftmost column\n",
    "mutations_3dqw = []\n",
    "\n",
    "for column in col_list_3dqw:\n",
    "    for mutation in pro_3dqw_df1[\"mutated_res\"]:\n",
    "        mutations_3dqw.append(column + mutation)\n",
    "\n",
    "# getting scores\n",
    "scores_3dqw = []\n",
    "\n",
    "for column in pro_3dqw_df1.drop('mutated_res', axis=1):\n",
    "    for val in pro_3dqw_df1[column]:\n",
    "        scores_3dqw.append(val)\n",
    "    \n",
    "# adding to df and renaming variant and score to match formatting for other proteins\n",
    "pro_3dqw_df = pd.DataFrame(list(zip(mutations_3dqw, scores_3dqw)),\n",
    "               columns =['variant', 'score'])\n",
    "\n",
    "# i have the data, next is formatting it so i can add the indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dec9c03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3315\n"
     ]
    }
   ],
   "source": [
    "pro_3dqw_df = pro_3dqw_df.dropna(axis=0)\n",
    "print(len(pro_3dqw_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7bd73e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounding score column to 6 decimal points\n",
    "pro_3dqw_df[\"score\"] = pro_3dqw_df[\"score\"].round(6)\n",
    "\n",
    "# shuffling\n",
    "pro_3dqw_df = pro_3dqw_df.sample(frac=1)\n",
    "\n",
    "# splitting variant list if there are multiple mutations\n",
    "pro_3dqw_mut = pro_3dqw_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "pro_3dqw_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(pro_3dqw_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "pro_3dqw_df[\"MUTATED_RES\"] = ssf.get_mutation_type(pro_3dqw_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "pro_3dqw_df[\"POSITION\"] = ssf.get_position(pro_3dqw_mut)\n",
    "\n",
    "# need positionssplit\n",
    "pro_3dqw_df[\"positions_split\"] = ssf.get_positions_split(pro_3dqw_df)\n",
    "\n",
    "positions_split_subtracted = []\n",
    "for pos_list in pro_3dqw_df[\"positions_split\"]:\n",
    "    pos_list = [x - 255 for x in pos_list] # reset index at 301\n",
    "    positions_split_subtracted.append(pos_list)  \n",
    "\n",
    "pro_3dqw_df[\"positions_split\"] = positions_split_subtracted    \n",
    "    \n",
    "new_positions = []\n",
    "pos_string = \"\"\n",
    "for pos_list in pro_3dqw_df[\"positions_split\"]:\n",
    "    pos_string = \",\".join(map(str, pos_list))\n",
    "    new_positions.append(pos_string)\n",
    "    pos_string = \"\"\n",
    "\n",
    "pro_3dqw_df[\"POSITION\"] = new_positions # changes positions into new adjusted values (0 index)\n",
    "# replace variant column with reformatted variant name\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "pro_3dqw_df[\"variant\"] = ssf.get_mutations_names_list(pro_3dqw_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "# to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6969da4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# secondary structure assignments\n",
    "path = \"../PDB and STRIDE Files/\" + '3dqw_stride.txt'\n",
    "pro_3dqw_stride_file = open(path, 'r')\n",
    "\n",
    "pro_3dqw_ss_indexes = ssf.get_sec_struc_boolean(pro_3dqw_stride_file) # not including turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2de1dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need positionssplit\n",
    "pro_3dqw_df[\"positions_split\"] = ssf.get_positions_split(pro_3dqw_df)\n",
    "\n",
    "# pro_3dqw_only_ss_df = get_ss_dataset(pro_3dqw_df, pro_3dqw_ss_indexes, 0)\n",
    "# pro_3dqw_only_not_ss_df = get_not_ss_dataset(pro_3dqw_df, pro_3dqw_ss_indexes, 0)\n",
    "# pro_3dqw_no_mixed_pos_df = pd.concat([pro_3dqw_only_ss_df, pro_3dqw_only_not_ss_df])\n",
    "\n",
    "# # add in_sec_str_col\n",
    "# pro_3dqw_no_mixed_pos_df = add_sec_str_col(pro_3dqw_no_mixed_pos_df, pro_3dqw_ss_indexes, 0)\n",
    "pro_3dqw_no_mixed_pos_df = pro_3dqw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b81cc1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # need positionssplit\n",
    "# # pro_3dqw_df[\"positions_split\"] = ssf.get_positions_split(pro_3dqw_df)\n",
    "\n",
    "# # add in_sec_str_col\n",
    "# pro_3dqw_df = add_sec_str_col(pro_3dqw_df, pro_3dqw_ss_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a5483e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3315\n"
     ]
    }
   ],
   "source": [
    "# shuffling data\n",
    "pro_3dqw_no_mixed_pos_df = pro_3dqw_no_mixed_pos_df.sample(frac=1)\n",
    "print(len(pro_3dqw_no_mixed_pos_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e458516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     2014\n",
      "False    1301\n",
      "Name: in_sec_str, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pro_3dqw_no_mixed_pos_df['in_sec_str'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "599dd614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein sequence\n",
    "path = \"../PDB and STRIDE Files/\" + '3dqw_stride.txt'\n",
    "pro_3dqw_stride_file = open(path, 'r')\n",
    "protein_seq_pro_3dqw = get_seq_from_stride(pro_3dqw_stride_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54a89f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pro_3dqw_train_df, pro_3dqw_test_df, pro_3dqw_remaining_df_1 = get_train_and_test_df(pro_3dqw_df, 0.60, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "502580b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     1114\n",
      "False    1114\n",
      "Name: in_sec_str, dtype: int64\n",
      "True     223\n",
      "False    223\n",
      "Name: in_sec_str, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# getting training set (5k in ss, 5k not in ss)\n",
    "pro_3dqw_train_ss = pro_3dqw_no_mixed_pos_df[pro_3dqw_no_mixed_pos_df['in_sec_str'] == True].sample(1114)\n",
    "pro_3dqw_train_not_ss = pro_3dqw_no_mixed_pos_df[pro_3dqw_no_mixed_pos_df['in_sec_str'] == False].sample(1114)\n",
    "pro_3dqw_train_df = pd.concat([pro_3dqw_train_ss, pro_3dqw_train_not_ss])\n",
    "\n",
    "pro_3dqw_test_ss = pro_3dqw_no_mixed_pos_df[pro_3dqw_no_mixed_pos_df['in_sec_str'] == True].sample(223)\n",
    "pro_3dqw_test_not_ss = pro_3dqw_no_mixed_pos_df[pro_3dqw_no_mixed_pos_df['in_sec_str'] == False].sample(223)\n",
    "pro_3dqw_test_df = pd.concat([pro_3dqw_test_ss, pro_3dqw_test_not_ss])\n",
    "\n",
    "# getting test set (2.5k in ss, 2.5k not in ss)\n",
    "print(pro_3dqw_train_df['in_sec_str'].value_counts())\n",
    "print(pro_3dqw_test_df['in_sec_str'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11aeb125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Standard Deviation: 0.9601949754210555\n",
      "Dataset Mean: -0.4266024263913824\n",
      "Dataset Median: -0.447528\n",
      "Kurtosis: 4.456284767555409\n",
      "713    -1.198838\n",
      "1105   -0.163726\n",
      "1789    0.848719\n",
      "195    -1.458887\n",
      "1520   -1.197281\n",
      "367    -0.123741\n",
      "89      0.657071\n",
      "615     1.646656\n",
      "900     0.496893\n",
      "1833   -1.367562\n",
      "Name: score, dtype: float64\n",
      "713     1.309077\n",
      "1105   -1.282152\n",
      "1789    1.022495\n",
      "195     0.375488\n",
      "1520   -1.827581\n",
      "367    -4.479125\n",
      "89      3.313320\n",
      "615     1.892513\n",
      "900    -0.517704\n",
      "1833    2.584142\n",
      "Name: score, dtype: float64\n",
      "713    -1.198838\n",
      "1105   -0.163726\n",
      "1789    0.848719\n",
      "195    -1.458887\n",
      "1520   -1.197281\n",
      "367    -0.123741\n",
      "89      0.657071\n",
      "615     1.646656\n",
      "900     0.496893\n",
      "1833   -1.367562\n",
      "Name: score, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_18804\\4025490882.py:36: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(unchanged_scores[0:10])\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_18804\\4025490882.py:38: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(ss_scores[0:10])\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_18804\\4025490882.py:40: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(not_ss_scores[0:10])\n"
     ]
    }
   ],
   "source": [
    "# adding noise to values from uniform distribution and creating files\n",
    "\n",
    "# finding standard deviation of dataset scores\n",
    "std = pro_3dqw_train_df['score'].std()\n",
    "mean = pro_3dqw_train_df['score'].mean()\n",
    "median = pro_3dqw_train_df['score'].median()\n",
    "print(\"Dataset Standard Deviation: \" + str(std))\n",
    "print(\"Dataset Mean: \" + str(mean))\n",
    "print(\"Dataset Median: \" + str(median))\n",
    "print(\"Kurtosis: \" + str(kurtosis(pro_3dqw_train_df['score'], fisher=False)))\n",
    "\n",
    "# finding number of ss and not ss values\n",
    "num_ss_vals = (pro_3dqw_train_df.in_sec_str == True).sum()\n",
    "num_not_ss_vals = (pro_3dqw_train_df.in_sec_str == False).sum()\n",
    "\n",
    "# creating noise (std not the exact same, but similar) // 0 is the mean of the normal distribution\n",
    "noise_ss = np.random.normal(0, std * 3, num_ss_vals).tolist()\n",
    "noise_ss_v2 = noise_ss.copy()\n",
    "noise_not_ss = np.random.normal(0, std * 3, num_not_ss_vals).tolist()\n",
    "\n",
    "# filling in values for not ss indexes in noise_ss\n",
    "bool_ss_list = pro_3dqw_train_df.in_sec_str.values.tolist()\n",
    "\n",
    "noise_ss_to_add = []\n",
    "noise_not_ss_to_add = []\n",
    "\n",
    "for ss_assign in bool_ss_list:\n",
    "    if ss_assign: # if true (ss index)\n",
    "        noise_ss_to_add.append(noise_ss.pop(0))\n",
    "        noise_not_ss_to_add.append(0)\n",
    "    else: # if false (not ss index)\n",
    "        noise_ss_to_add.append(0)\n",
    "        noise_not_ss_to_add.append(noise_not_ss.pop(0))\n",
    "        \n",
    "unchanged_scores = pro_3dqw_train_df['score']\n",
    "print(unchanged_scores[0:10])\n",
    "ss_scores = pro_3dqw_train_df['score'] + noise_ss_to_add\n",
    "print(ss_scores[0:10])\n",
    "not_ss_scores = pro_3dqw_train_df['score'] + noise_not_ss_to_add\n",
    "print(not_ss_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee9c87d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8500389120287265\n",
      "\n",
      "1.5773390421758977\n",
      "Percentage Change: 85.56080431793134\n",
      "1.655334011230213\n",
      "Percentage Change: 94.73626298819038\n"
     ]
    }
   ],
   "source": [
    "abs_val_list = [abs(x) for x in pro_3dqw_train_df['score']]\n",
    "mean = sum(abs_val_list) / len(abs_val_list)\n",
    "print(mean)\n",
    "print()\n",
    "\n",
    "abs_ss_val_list = [abs(x) for x in ss_scores]\n",
    "mean_ss = sum(abs_ss_val_list) / len(abs_ss_val_list)\n",
    "print(mean_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_ss - mean) / mean) * 100))\n",
    "\n",
    "abs_not_ss_val_list = [abs(x) for x in not_ss_scores]\n",
    "mean_not_ss = sum(abs_not_ss_val_list) / len(abs_not_ss_val_list)\n",
    "print(mean_not_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_not_ss - mean) / mean) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "3eaab064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: pro_3dqw_MLformat_10000_train_1250_no_noise_t1.txt\n",
      "Filename: pro_3dqw_MLformat_10000_train_1250_ss_noise_t1.txt\n",
      "Filename: pro_3dqw_MLformat_10000_train_1250_not_ss_noise_t1.txt\n"
     ]
    }
   ],
   "source": [
    "# # creating files (NO NOISE for test values)\n",
    "\n",
    "# # unchanged\n",
    "# pro_3dqw_train_df['score'] = unchanged_scores\n",
    "# pro_3dqw_full_df = pd.concat([pro_3dqw_train_df, pro_3dqw_test_df])\n",
    "# ssf.write_data_file(\"pro_3dqw_MLformat_10000_train_1250_no_noise_t1\", protein_seq_pro_3dqw, pro_3dqw_full_df)\n",
    "\n",
    "# # ss\n",
    "# pro_3dqw_train_df['score'] = ss_scores\n",
    "# pro_3dqw_full_df = pd.concat([pro_3dqw_train_df, pro_3dqw_test_df])\n",
    "# ssf.write_data_file(\"pro_3dqw_MLformat_10000_train_1250_ss_noise_t1\", protein_seq_pro_3dqw, pro_3dqw_full_df)\n",
    "\n",
    "# # not ss\n",
    "# pro_3dqw_train_df['score'] = not_ss_scores\n",
    "# pro_3dqw_full_df = pd.concat([pro_3dqw_train_df, pro_3dqw_test_df])\n",
    "# ssf.write_data_file(\"pro_3dqw_MLformat_10000_train_1250_not_ss_noise_t1\", protein_seq_pro_3dqw, pro_3dqw_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57df1c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: 3dqw_trainbatch_train_20_test_6_t3.txt\n"
     ]
    }
   ],
   "source": [
    "# creating files (NO NOISE for test values)\n",
    "\n",
    "# unchanged\n",
    "# pro_3dqw_train_df['score'] = unchanged_scores\n",
    "pro_3dqw_full_df = pro_3dqw_no_mixed_pos_df.sample(26)\n",
    "ssf.write_data_file(\"3dqw_trainbatch_train_20_test_6_t3\", protein_seq_pro_3dqw, pro_3dqw_full_df)\n",
    "\n",
    "# # ss\n",
    "# pro_3dqw_train_df['score'] = ss_scores\n",
    "# pro_3dqw_full_df = pd.concat([pro_3dqw_train_df, pro_3dqw_test_df])\n",
    "# ssf.write_data_file(\"pro_3dqw_MLformat_700_train_300_ss_noise_t2_v2\", protein_seq_pro_3dqw, pro_3dqw_full_df)\n",
    "\n",
    "# # not ss\n",
    "# pro_3dqw_train_df['score'] = not_ss_scores\n",
    "# pro_3dqw_full_df = pd.concat([pro_3dqw_train_df, pro_3dqw_test_df])\n",
    "# ssf.write_data_file(\"pro_3dqw_MLformat_700_train_300_not_ss_noise_t2_v2\", protein_seq_pro_3dqw, pro_3dqw_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5ab0a742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: pro_3dqw_trainbatch_train_20_test_663_t3.txt\n"
     ]
    }
   ],
   "source": [
    "pro_3dqw_full_df = pro_3dqw_no_mixed_pos_df.sample(683)\n",
    "ssf.write_data_file(\"pro_3dqw_trainbatch_train_20_test_663_t3\", protein_seq_pro_3dqw, pro_3dqw_full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db4ee2d",
   "metadata": {},
   "source": [
    "### 4bz3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4cb6e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "pro_4bz3_df1 = pd.read_csv(\"../Raw Data/4bz3.txt\", sep=\",\")\n",
    "\n",
    "# renaming mutated residue column\n",
    "pro_4bz3_df1 = pro_4bz3_df1.rename(columns={\"Unnamed: 0\": \"mutated_res\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6762a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganizing data to other form\n",
    "col_list_4bz3 = list(pro_4bz3_df1)\n",
    "col_list_4bz3 = col_list_4bz3[1:]\n",
    "\n",
    "# mutations going down from the leftmost column\n",
    "mutations_4bz3 = []\n",
    "\n",
    "for column in col_list_4bz3:\n",
    "    for mutation in pro_4bz3_df1[\"mutated_res\"]:\n",
    "        mutations_4bz3.append(column + mutation)\n",
    "\n",
    "# getting scores\n",
    "scores_4bz3 = []\n",
    "\n",
    "for column in pro_4bz3_df1.drop('mutated_res', axis=1):\n",
    "    for val in pro_4bz3_df1[column]:\n",
    "        scores_4bz3.append(val)\n",
    "    \n",
    "# adding to df and renaming variant and score to match formatting for other proteins\n",
    "pro_4bz3_df = pd.DataFrame(list(zip(mutations_4bz3, scores_4bz3)),\n",
    "               columns =['variant', 'score'])\n",
    "\n",
    "# i have the data, next is formatting it so i can add the indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "af2fc11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4620\n",
      "4554\n"
     ]
    }
   ],
   "source": [
    "print(len(pro_4bz3_df))\n",
    "pro_4bz3_df = pro_4bz3_df.dropna(axis=0)\n",
    "print(len(pro_4bz3_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37e59c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounding score column to 6 decimal points\n",
    "pro_4bz3_df[\"score\"] = pro_4bz3_df[\"score\"].round(6)\n",
    "\n",
    "# shuffling\n",
    "pro_4bz3_df = pro_4bz3_df.sample(frac=1)\n",
    "\n",
    "# splitting variant list if there are multiple mutations\n",
    "pro_4bz3_mut = pro_4bz3_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "pro_4bz3_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(pro_4bz3_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "pro_4bz3_df[\"MUTATED_RES\"] = ssf.get_mutation_type(pro_4bz3_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "pro_4bz3_df[\"POSITION\"] = ssf.get_position(pro_4bz3_mut)\n",
    "\n",
    "# need positionssplit\n",
    "pro_4bz3_df[\"positions_split\"] = ssf.get_positions_split(pro_4bz3_df)\n",
    "\n",
    "positions_split_subtracted = []\n",
    "for pos_list in pro_4bz3_df[\"positions_split\"]:\n",
    "    pos_list = [x - 32 for x in pos_list] # reset index at 301\n",
    "    positions_split_subtracted.append(pos_list)  \n",
    "\n",
    "pro_4bz3_df[\"positions_split\"] = positions_split_subtracted    \n",
    "    \n",
    "new_positions = []\n",
    "pos_string = \"\"\n",
    "for pos_list in pro_4bz3_df[\"positions_split\"]:\n",
    "    pos_string = \",\".join(map(str, pos_list))\n",
    "    new_positions.append(pos_string)\n",
    "    pos_string = \"\"\n",
    "\n",
    "pro_4bz3_df[\"POSITION\"] = new_positions # changes positions into new adjusted values (0 index)\n",
    "# replace variant column with reformatted variant name\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "pro_4bz3_df[\"variant\"] = ssf.get_mutations_names_list(pro_4bz3_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "792a05e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4554\n"
     ]
    }
   ],
   "source": [
    "print(len(pro_4bz3_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "245d5a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     variant     score WILD_TYPE_RES MUTATED_RES POSITION positions_split\n",
      "3586  180HIS -0.099294             A           H      180           [180]\n",
      "4181  210CYS -1.664693             L           C      210           [210]\n",
      "3596  180THR -0.182043             A           T      180           [180]\n",
      "2623  131GLU -0.395186             D           E      131           [131]\n",
      "487    24ILE -7.565904             H           I       24            [24]\n",
      "1171   58ASN  0.503021             K           N       58            [58]\n",
      "3765  189GLY  0.076992             T           G      189           [189]\n",
      "1904   95PHE -1.452111             R           F       95            [95]\n",
      "4434  222ARG  0.030239             N           R      222           [222]\n",
      "4034  202ARG -0.102308             Q           R      202           [202]\n"
     ]
    }
   ],
   "source": [
    "print(pro_4bz3_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e248e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../PDB and STRIDE Files/\" + '4bz3_stride.txt'\n",
    "pro_4bz3_stride_file = open(path, 'r')\n",
    "protein_seq_4bz3 = get_seq_from_stride(pro_4bz3_stride_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc094524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n",
      "ILE\n"
     ]
    }
   ],
   "source": [
    "protein_seq_4bz3_split = protein_seq_4bz3.split()\n",
    "print(len(protein_seq_4bz3_split))\n",
    "print(protein_seq_4bz3_split[51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4f3ccd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n",
      "380\n",
      "83\n"
     ]
    }
   ],
   "source": [
    "path = \"../PDB and STRIDE Files/\" + '4bz3_stride.txt'\n",
    "pro_4bz3_stride_file = open(path, 'r')\n",
    "\n",
    "pro_4bz3_ss_indexes = ssf.get_all_sec_struc_boolean(pro_4bz3_stride_file)\n",
    "print(len(pro_4bz3_ss_indexes))\n",
    "print(pro_4bz3_ss_indexes.count(True))\n",
    "print(pro_4bz3_ss_indexes.count(False))\n",
    "\n",
    "# add in_sec_str_col\n",
    "pro_4bz3_df = add_sec_str_col(pro_4bz3_df, pro_4bz3_ss_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b8e4e35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fraction,df len4554\n",
      "744\n",
      "164\n",
      "Train Data Fraction: 0.819\n",
      "false_df len811\n",
      "true_df len3743\n",
      "in fraction,df len3646\n",
      "Test Data Fraction: 0.82\n",
      "false_df len647\n",
      "true_df len2999\n",
      "Size of Test Dataset: 3588\n",
      "Size of Total Dataset: 4496\n",
      "4496\n",
      "Filename: pro_4bz3_MLformat_908_train_3588_test_t3.txt\n"
     ]
    }
   ],
   "source": [
    "pro_4bz3_train_df, pro_4bz3_test_df, pro_4bz3_remaining_df = get_train_and_test_df(pro_4bz3_df, 0.82, 908)\n",
    "pro_4bz3_df_format = pd.concat([pro_4bz3_train_df, pro_4bz3_test_df])\n",
    "print(len(pro_4bz3_df_format))\n",
    "ssf.write_data_file(\"pro_4bz3_MLformat_908_train_3588_test_t3\", protein_seq_4bz3, pro_4bz3_df_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a92601d",
   "metadata": {},
   "source": [
    "# Adding Noise to 4bz3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c2fa985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "pro_4bz3_df1 = pd.read_csv(\"../Raw Data/4bz3.txt\", sep=\",\")\n",
    "\n",
    "# renaming mutated residue column\n",
    "pro_4bz3_df1 = pro_4bz3_df1.rename(columns={\"Unnamed: 0\": \"mutated_res\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9f311af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganizing data to other form\n",
    "col_list_4bz3 = list(pro_4bz3_df1)\n",
    "col_list_4bz3 = col_list_4bz3[1:]\n",
    "\n",
    "# mutations going down from the leftmost column\n",
    "mutations_4bz3 = []\n",
    "\n",
    "for column in col_list_4bz3:\n",
    "    for mutation in pro_4bz3_df1[\"mutated_res\"]:\n",
    "        mutations_4bz3.append(column + mutation)\n",
    "\n",
    "# getting scores\n",
    "scores_4bz3 = []\n",
    "\n",
    "for column in pro_4bz3_df1.drop('mutated_res', axis=1):\n",
    "    for val in pro_4bz3_df1[column]:\n",
    "        scores_4bz3.append(val)\n",
    "    \n",
    "# adding to df and renaming variant and score to match formatting for other proteins\n",
    "pro_4bz3_df = pd.DataFrame(list(zip(mutations_4bz3, scores_4bz3)),\n",
    "               columns =['variant', 'score'])\n",
    "\n",
    "# i have the data, next is formatting it so i can add the indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "13ee3527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4620\n",
      "4554\n"
     ]
    }
   ],
   "source": [
    "print(len(pro_4bz3_df))\n",
    "pro_4bz3_df = pro_4bz3_df.dropna(axis=0)\n",
    "print(len(pro_4bz3_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "292a0901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounding score column to 6 decimal points\n",
    "pro_4bz3_df[\"score\"] = pro_4bz3_df[\"score\"].round(6)\n",
    "\n",
    "# shuffling\n",
    "pro_4bz3_df = pro_4bz3_df.sample(frac=1)\n",
    "\n",
    "# splitting variant list if there are multiple mutations\n",
    "pro_4bz3_mut = pro_4bz3_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "# get wild type of residue and place in seperate col\n",
    "pro_4bz3_df[\"WILD_TYPE_RES\"] = ssf.get_wild_type(pro_4bz3_mut)\n",
    "\n",
    "# get mutated residue and place in seperate col\n",
    "pro_4bz3_df[\"MUTATED_RES\"] = ssf.get_mutation_type(pro_4bz3_mut)\n",
    "\n",
    "# get position and place in seperate col\n",
    "pro_4bz3_df[\"POSITION\"] = ssf.get_position(pro_4bz3_mut)\n",
    "\n",
    "# need positionssplit\n",
    "pro_4bz3_df[\"positions_split\"] = ssf.get_positions_split(pro_4bz3_df)\n",
    "\n",
    "positions_split_subtracted = []\n",
    "for pos_list in pro_4bz3_df[\"positions_split\"]:\n",
    "    pos_list = [x - 32 for x in pos_list] # reset index at 301\n",
    "    positions_split_subtracted.append(pos_list)  \n",
    "\n",
    "pro_4bz3_df[\"positions_split\"] = positions_split_subtracted    \n",
    "    \n",
    "new_positions = []\n",
    "pos_string = \"\"\n",
    "for pos_list in pro_4bz3_df[\"positions_split\"]:\n",
    "    pos_string = \",\".join(map(str, pos_list))\n",
    "    new_positions.append(pos_string)\n",
    "    pos_string = \"\"\n",
    "\n",
    "pro_4bz3_df[\"POSITION\"] = new_positions # changes positions into new adjusted values (0 index)\n",
    "# replace variant column with reformatted variant name\n",
    "\n",
    "# replace variant column with reformatted variant name\n",
    "pro_4bz3_df[\"variant\"] = ssf.get_mutations_names_list(pro_4bz3_df)\n",
    "\n",
    "# drop unneccesary columns\n",
    "to_drop = [\"WILD_TYPE_RES\", \"MUTATED_RES\", \"POSITION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1072f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../PDB and STRIDE Files/\" + '4bz3_stride.txt'\n",
    "pro_4bz3_stride_file = open(path, 'r')\n",
    "protein_seq_pro_4bz3 = get_seq_from_stride(pro_4bz3_stride_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d465f2e",
   "metadata": {},
   "source": [
    "# technically they should not be off but i'm not sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1ee16f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n",
      "272\n",
      "191\n"
     ]
    }
   ],
   "source": [
    "path = \"../PDB and STRIDE Files/\" + '4bz3_stride.txt'\n",
    "pro_4bz3_stride_file = open(path, 'r')\n",
    "\n",
    "pro_4bz3_ss_indexes = ssf.get_sec_struc_boolean(pro_4bz3_stride_file)\n",
    "print(len(pro_4bz3_ss_indexes))\n",
    "print(pro_4bz3_ss_indexes.count(True))\n",
    "print(pro_4bz3_ss_indexes.count(False))\n",
    "\n",
    "# add in_sec_str_col\n",
    "pro_4bz3_df = add_sec_str_col(pro_4bz3_df, pro_4bz3_ss_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5ceea7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need positionssplit\n",
    "pro_4bz3_df[\"positions_split\"] = ssf.get_positions_split(pro_4bz3_df)\n",
    "\n",
    "# pro_4bz3_only_ss_df = get_ss_dataset(pro_4bz3_df, pro_4bz3_ss_indexes, 0)\n",
    "# print(len(pro_4bz3_only_ss_df))\n",
    "# pro_4bz3_only_not_ss_df = get_not_ss_dataset(pro_4bz3_df, pro_4bz3_ss_indexes, 0)\n",
    "# print(len(pro_4bz3_only_not_ss_df))\n",
    "# pro_4bz3_no_mixed_pos_df = pd.concat([pro_4bz3_only_ss_df, pro_4bz3_only_not_ss_df])\n",
    "\n",
    "# # add in_sec_str_col\n",
    "# pro_4bz3_no_mixed_pos_df = add_sec_str_col(pro_4bz3_no_mixed_pos_df, pro_4bz3_ss_indexes, 0)\n",
    "pro_4bz3_no_mixed_pos_df = pro_4bz3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "86dc8bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4554\n"
     ]
    }
   ],
   "source": [
    "# shuffling data\n",
    "pro_4bz3_no_mixed_pos_df = pro_4bz3_no_mixed_pos_df.sample(frac=1)\n",
    "print(len(pro_4bz3_no_mixed_pos_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df8e7bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     504\n",
      "False    504\n",
      "Name: in_sec_str, dtype: int64\n",
      "True     101\n",
      "False    101\n",
      "Name: in_sec_str, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# getting training set (5k in ss, 5k not in ss)\n",
    "pro_4bz3_train_ss = pro_4bz3_no_mixed_pos_df[pro_4bz3_no_mixed_pos_df['in_sec_str'] == True].sample(504)\n",
    "pro_4bz3_train_not_ss = pro_4bz3_no_mixed_pos_df[pro_4bz3_no_mixed_pos_df['in_sec_str'] == False].sample(504)\n",
    "pro_4bz3_train_df = pd.concat([pro_4bz3_train_ss, pro_4bz3_train_not_ss])\n",
    "\n",
    "pro_4bz3_test_ss = pro_4bz3_no_mixed_pos_df[pro_4bz3_no_mixed_pos_df['in_sec_str'] == True].sample(101)\n",
    "pro_4bz3_test_not_ss = pro_4bz3_no_mixed_pos_df[pro_4bz3_no_mixed_pos_df['in_sec_str'] == False].sample(101)\n",
    "pro_4bz3_test_df = pd.concat([pro_4bz3_test_ss, pro_4bz3_test_not_ss])\n",
    "\n",
    "# getting test set (2.5k in ss, 2.5k not in ss)\n",
    "print(pro_4bz3_train_df['in_sec_str'].value_counts())\n",
    "print(pro_4bz3_test_df['in_sec_str'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf4eccda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pro_4bz3_train_ss['score'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b908efa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Standard Deviation: 3.161432234738241\n",
      "Dataset Mean: -3.1403119533730157\n",
      "Dataset Median: -2.6138250000000003\n",
      "Kurtosis: 1.9522568613027869\n",
      "1138   -0.210795\n",
      "358    -5.189036\n",
      "1669    0.644054\n",
      "2405   -0.564345\n",
      "1710   -7.708300\n",
      "800    -7.634800\n",
      "144    -0.447536\n",
      "1871   -0.022609\n",
      "1552   -7.538054\n",
      "2169   -3.078179\n",
      "Name: score, dtype: float64\n",
      "1138     8.054521\n",
      "358     -5.704312\n",
      "1669    13.719632\n",
      "2405    -0.184954\n",
      "1710    -4.832574\n",
      "800     -8.120727\n",
      "144      1.611017\n",
      "1871    -9.409404\n",
      "1552   -12.041428\n",
      "2169   -19.209349\n",
      "Name: score, dtype: float64\n",
      "1138   -0.210795\n",
      "358    -5.189036\n",
      "1669    0.644054\n",
      "2405   -0.564345\n",
      "1710   -7.708300\n",
      "800    -7.634800\n",
      "144    -0.447536\n",
      "1871   -0.022609\n",
      "1552   -7.538054\n",
      "2169   -3.078179\n",
      "Name: score, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_18804\\2495936073.py:36: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(unchanged_scores[0:10])\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_18804\\2495936073.py:38: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(ss_scores[0:10])\n",
      "C:\\Users\\deepti\\AppData\\Local\\Temp\\ipykernel_18804\\2495936073.py:40: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(not_ss_scores[0:10])\n"
     ]
    }
   ],
   "source": [
    "# adding noise to values from uniform distribution and creating files\n",
    "\n",
    "# finding standard deviation of dataset scores\n",
    "std = pro_4bz3_train_df['score'].std()\n",
    "mean = pro_4bz3_train_df['score'].mean()\n",
    "median = pro_4bz3_train_df['score'].median()\n",
    "print(\"Dataset Standard Deviation: \" + str(std))\n",
    "print(\"Dataset Mean: \" + str(mean))\n",
    "print(\"Dataset Median: \" + str(median))\n",
    "print(\"Kurtosis: \" + str(kurtosis(pro_4bz3_train_df['score'], fisher=False)))\n",
    "\n",
    "# finding number of ss and not ss values\n",
    "num_ss_vals = (pro_4bz3_train_df.in_sec_str == True).sum()\n",
    "num_not_ss_vals = (pro_4bz3_train_df.in_sec_str == False).sum()\n",
    "\n",
    "# creating noise (std not the exact same, but similar) // 0 is the mean of the normal distribution\n",
    "noise_ss = np.random.normal(0, std * 3, num_ss_vals).tolist()\n",
    "noise_ss_v2 = noise_ss.copy()\n",
    "noise_not_ss = np.random.normal(0, std * 3, num_not_ss_vals).tolist()\n",
    "\n",
    "# filling in values for not ss indexes in noise_ss\n",
    "bool_ss_list = pro_4bz3_train_df.in_sec_str.values.tolist()\n",
    "\n",
    "noise_ss_to_add = []\n",
    "noise_not_ss_to_add = []\n",
    "\n",
    "for ss_assign in bool_ss_list:\n",
    "    if ss_assign: # if true (ss index)\n",
    "        noise_ss_to_add.append(noise_ss.pop(0))\n",
    "        noise_not_ss_to_add.append(0)\n",
    "    else: # if false (not ss index)\n",
    "        noise_ss_to_add.append(0)\n",
    "        noise_not_ss_to_add.append(noise_not_ss.pop(0))\n",
    "        \n",
    "unchanged_scores = pro_4bz3_train_df['score']\n",
    "print(unchanged_scores[0:10])\n",
    "ss_scores = pro_4bz3_train_df['score'] + noise_ss_to_add\n",
    "print(ss_scores[0:10])\n",
    "not_ss_scores = pro_4bz3_train_df['score'] + noise_not_ss_to_add\n",
    "print(not_ss_scores[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4aee667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2971541101190502\n",
      "\n",
      "5.84255271262265\n",
      "Percentage Change: 77.19986744604101\n",
      "5.719099355543033\n",
      "Percentage Change: 73.45562762720041\n"
     ]
    }
   ],
   "source": [
    "abs_val_list = [abs(x) for x in pro_4bz3_train_df['score']]\n",
    "mean = sum(abs_val_list) / len(abs_val_list)\n",
    "print(mean)\n",
    "print()\n",
    "\n",
    "abs_ss_val_list = [abs(x) for x in ss_scores]\n",
    "mean_ss = sum(abs_ss_val_list) / len(abs_ss_val_list)\n",
    "print(mean_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_ss - mean) / mean) * 100))\n",
    "\n",
    "abs_not_ss_val_list = [abs(x) for x in not_ss_scores]\n",
    "mean_not_ss = sum(abs_not_ss_val_list) / len(abs_not_ss_val_list)\n",
    "print(mean_not_ss)\n",
    "print(\"Percentage Change: \" + str(((mean_not_ss - mean) / mean) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "965a8f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: 4bz3_trainbatch_train_28_test_8_t3.txt\n"
     ]
    }
   ],
   "source": [
    "# creating files (NO NOISE for test values)\n",
    "\n",
    "# unchanged\n",
    "# pro_4bz3_train_df['score'] = unchanged_scores\n",
    "# pro_4bz3_full_df = pd.concat([pro_4bz3_train_df, pro_4bz3_test_df])\n",
    "pro_4bz3_full_df = pro_4bz3_df.sample(36)\n",
    "ssf.write_data_file(\"4bz3_trainbatch_train_28_test_8_t3\", protein_seq_pro_4bz3, pro_4bz3_full_df)\n",
    "\n",
    "# # ss\n",
    "# pro_4bz3_train_df['score'] = ss_scores\n",
    "# pro_4bz3_full_df = pd.concat([pro_4bz3_train_df, pro_4bz3_test_df])\n",
    "# ssf.write_data_file(\"pro_4bz3_MLformat_500_train_200_ss_noise_t2_v2\", protein_seq_pro_4bz3, pro_4bz3_full_df)\n",
    "\n",
    "# # not ss\n",
    "# pro_4bz3_train_df['score'] = not_ss_scores\n",
    "# pro_4bz3_full_df = pd.concat([pro_4bz3_train_df, pro_4bz3_test_df])\n",
    "# ssf.write_data_file(\"pro_4bz3_MLformat_500_train_200_not_ss_noise_t2_v2\", protein_seq_pro_4bz3, pro_4bz3_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "647f3414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: pro_4bz3_trainbatch_train_28_test_911_t3.txt\n"
     ]
    }
   ],
   "source": [
    "pro_4bz3_full_df = pro_4bz3_no_mixed_pos_df.sample(939)\n",
    "ssf.write_data_file(\"pro_4bz3_trainbatch_train_28_test_911_t3\", protein_seq_pro_4bz3, pro_4bz3_full_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
