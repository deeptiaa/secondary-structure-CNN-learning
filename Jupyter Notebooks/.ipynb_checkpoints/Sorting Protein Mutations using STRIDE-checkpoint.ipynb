{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0718f70",
   "metadata": {},
   "source": [
    "# Sorting Protein Mutations Using STRIDE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0758cbdf",
   "metadata": {},
   "source": [
    "This notebook divides the dataset into seperate datasets depended on a mutations secondary structure assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ed88bc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from Bio import SeqIO\n",
    "from io import StringIO\n",
    "import Bio.PDB.Polypeptide\n",
    "import random\n",
    "import itertools\n",
    "import more_itertools as mit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d443211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting jupyter notebook viewing options\n",
    "max_rows = 1000\n",
    "max_cols = 1000\n",
    "pd.set_option(\"display.max_rows\", max_rows, \"display.max_columns\", max_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0748eb30",
   "metadata": {},
   "source": [
    "### Methods Used to Format Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f031f61a",
   "metadata": {},
   "source": [
    "Formatting protein sequence into form for machine learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54768902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters:\n",
    "#      \"uniprot_id\" - string representing uniprot id of desired protein.\n",
    "# This method uses a given uniprot id to query the uniprot data and \n",
    "# return a string respresention of the protein sequence. \n",
    "# E.g. MADIT\n",
    "def get_protein_seq(uniprot_id):\n",
    "    \n",
    "    # importing fasta file from uniprot.org and getting protein sequence\n",
    "    # taken from StackOverflow: \n",
    "    # https://stackoverflow.com/questions/52569622/protein-sequence-from-uniprot-protein-id-python\n",
    "    url = \"http://www.uniprot.org/uniprot/\"\n",
    "    complete_url = url + uniprot_id + \".fasta\"\n",
    "    response = requests.post(complete_url)\n",
    "    data =''.join(response.text)\n",
    "    sequence =StringIO(data)\n",
    "    protein_seq=list(SeqIO.parse(sequence,'fasta'))\n",
    "\n",
    "    # protein sequence as string (single-letter amino acids)\n",
    "    string_seq = str(protein_seq[0].seq)\n",
    "    \n",
    "    # protein sequence w/ three-letter convention\n",
    "    protein_seq = get_expanded_seq(string_seq)\n",
    "    return protein_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f0f7a7",
   "metadata": {},
   "source": [
    "Expanding protein sequence (1 letter AA -> 3 letter AA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "feff7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter:\n",
    "#      \"seq\" - string representing protein sequence in 1-letter convention.\n",
    "# This method takes protein sequence string with 1-letter convention and returns\n",
    "# a protein sequence with 3-letter convention.\n",
    "# E.g. ADE -> ALA ASP GLU\n",
    "def get_expanded_seq(seq):\n",
    "    expanded_list = []\n",
    "    split_seq = list(seq)\n",
    "    for letter in split_seq:\n",
    "        three_letter_abbr = Bio.PDB.Polypeptide.one_to_three(letter)\n",
    "        expanded_list.append(three_letter_abbr)\n",
    "    exanded_string = \" \".join(expanded_list)\n",
    "    return(exanded_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b58ef07",
   "metadata": {},
   "source": [
    "Returning index range of protein domain within protein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec3f7d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters: \n",
    "#      \"full_protein_split\" - list of amino acids in full protein in 3 letter convention.\n",
    "#                             E.g. [\"ALA\", \"GLY\", \"TYR\"]\n",
    "#      \"domain_split\" - list of amino acids in protein domain in 3 letter convention.\n",
    "#                       E.g. [\"ALA\", \"GLY\"]\n",
    "# This method prints the index of the given domain within the given protein.\n",
    "# Starting value is inclusive and the ending value is exclusive. \n",
    "# E.g. [(0, 3)]\n",
    "def get_index_range(full_protein_split, domain_split):\n",
    "    indexes = []\n",
    "    for i in range(len(full_protein_split)):\n",
    "        if full_protein_split[i:i+len(domain_split)] == domain_split:\n",
    "            indexes.append((i, i+len(domain_split)))\n",
    "    print(indexes)\n",
    "    indexes.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0190a9f0",
   "metadata": {},
   "source": [
    "Get variant in mutation-position form from wild-type-position-mutation form: (E.g. G126A -> 126ALA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0954fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter: \n",
    "#      \"split_mutation_column\" - list of mutations, split by comma if there are multiple.\n",
    "# This method returns a list with wild-type residue (first letter) from variant.\n",
    "def get_wild_type(split_mutation_column):\n",
    "    wild_type_list = []\n",
    "    w_letters = []\n",
    "    for string in split_mutation_column:\n",
    "        if \"wild-type\" in string[0]:\n",
    "            wild_type = \"wild_type\"\n",
    "        elif \"-\" in string[0] or len(string) == 0:\n",
    "            wild_type = np.nan\n",
    "        else:\n",
    "            for val in string:\n",
    "                mutation_name = val.strip(\" \")\n",
    "                w_letters.append(mutation_name[0])\n",
    "                wild_type = \",\".join(w_letters)\n",
    "        wild_type_list.append(wild_type)\n",
    "        w_letters.clear()\n",
    "    return wild_type_list\n",
    "\n",
    "\n",
    "# parameter: \n",
    "#      \"split_mutation_column\" - list of mutations, split by comma if there are multiple.\n",
    "# This method returns a list with mutation residue (last letter) from variant.\n",
    "def get_mutation_type(split_mutation_column):\n",
    "    mutation_list = []\n",
    "    m_letters = []\n",
    "    for string in split_mutation_column:\n",
    "        if \"wild-type\" in string[0]:\n",
    "            mutation = \"wild-type\"\n",
    "        elif \"-\" in string[0] or len(string) == 0:\n",
    "            mutation = np.nan\n",
    "        else:\n",
    "            for val in string:\n",
    "                mutation_name = val.strip(\" \")\n",
    "                m_letters.append(mutation_name[-1])\n",
    "                mutation = \",\".join(m_letters)\n",
    "        mutation_list.append(mutation)\n",
    "        m_letters.clear()\n",
    "    return mutation_list\n",
    "\n",
    "\n",
    "# parameter: \n",
    "#      \"split_mutation_column\" - list of mutations, split by comma if there are multiple.\n",
    "# This method returns a list with the position of mutation (number) from variant.\n",
    "def get_position(split_mutation_column):\n",
    "    position_list = []\n",
    "    p_letters = []\n",
    "    for string in split_mutation_column:\n",
    "        if \"wild-type\" in string[0]:\n",
    "            position = \"wild-type\"\n",
    "        elif \"-\" in string[0] or len(string) == 0:\n",
    "            position = np.nan\n",
    "        else:\n",
    "            for val in string:\n",
    "                mutation_name = val.strip(\" \")\n",
    "                p_letters.append(mutation_name[1:-1])\n",
    "                position = \",\".join(p_letters)\n",
    "        position_list.append(position)\n",
    "        p_letters.clear()\n",
    "    return(position_list)\n",
    "\n",
    "\n",
    "# parameter:\n",
    "#      \"df\" - dataframe of protein data with \"MUTATED_RES\" and \"POSITION\" columns.\n",
    "# This method returns a list with the correctly formatted variant (mutation-position form).\n",
    "def get_mutations_names_list(df):\n",
    "    formatted_list = []\n",
    "    expanded_abbv = []\n",
    "    for mutation, position in zip(df[\"MUTATED_RES\"], df[\"POSITION\"]):\n",
    "        split_mutations = mutation.split(\",\")\n",
    "        split_positions = position.split(\",\")\n",
    "        if \"wild-type\" in split_mutations[0].lower() or \"wild-type\" in split_positions[0].lower():\n",
    "            abbv_names = \"WT\"\n",
    "        else:  \n",
    "            for mut, pos in zip(split_mutations, split_positions):\n",
    "                three_letter_mut = Bio.PDB.Polypeptide.one_to_three(mut.upper())\n",
    "                position = str(int(pos))\n",
    "                combined_name = position + three_letter_mut\n",
    "                expanded_abbv.append(combined_name)\n",
    "                abbv_names = \", \".join(expanded_abbv)\n",
    "        expanded_abbv.clear()\n",
    "        formatted_list.append(abbv_names)\n",
    "    return(formatted_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508fb13e",
   "metadata": {},
   "source": [
    "Splits positions in intermediary \"POSITION\" column to help remove mutations with a certain position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93b6ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "#      \"df\" - protein data dataframe with \"POSITION\" column \n",
    "# This method takes the position column in the dataframe and splits it in order\n",
    "# to help remove or keep mutatations depending on their position.\n",
    "def get_positions_split(df):\n",
    "    position_list_split = []\n",
    "\n",
    "    for item in df[\"POSITION\"]:\n",
    "        item = item.split(\",\") # splits positions into list\n",
    "        int_item = [int(i) for i in item]\n",
    "        position_list_split.append(int_item)\n",
    "    \n",
    "    return position_list_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60f8f6e",
   "metadata": {},
   "source": [
    "Getting Secondary Structure assignmnt from STRIDE file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75a6ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters: \n",
    "#      \"stride file\" - stride file of protein\n",
    "#      \"is_sec_struc\" - list of boolean values for each secondary structure value\n",
    "#                       if it is, true, else false\n",
    "# returns list of boolean values indicating if position is secondary strcuture or not\n",
    "def get_sec_struc_boolean(stride_file):\n",
    "    is_sec_struc = []\n",
    "    sec_struc_assign = []\n",
    "\n",
    "    for line in stride_file:\n",
    "        if line.startswith('ASG'):\n",
    "            split_line = line.split();\n",
    "            sec_struc_assign.append(split_line[5])\n",
    "\n",
    "    for sec_struc in sec_struc_assign:\n",
    "        if (sec_struc =='C' or sec_struc =='T'):\n",
    "            is_sec_struc.append(False)\n",
    "        else:\n",
    "            is_sec_struc.append(True)\n",
    "            \n",
    "    return is_sec_struc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf14f381",
   "metadata": {},
   "source": [
    "Getting Dataset of Mutations within Domain in PDB File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4772de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "#      \"orig_df\" - \n",
    "#      \"start\" -\n",
    "#      \"end\" - \n",
    "#      \"not_included_list\"\n",
    "# This method does even more helpful stuff\n",
    "def get_domain_dataset(orig_df, start, end, not_included_list):\n",
    "    in_domain_list = []\n",
    "    \n",
    "    for val in orig_df[\"positions_split\"]:\n",
    "        for position in val:\n",
    "            if not_included_list.count(position - start) == 0: # if value is not in the list of values to exclude\n",
    "                if position >= start and position < end:\n",
    "                    in_domain = True\n",
    "                else:\n",
    "                    in_domain = False\n",
    "            else:\n",
    "                in_domain = False\n",
    "        in_domain_list.append(in_domain)\n",
    "    \n",
    "    orig_df['in_domain'] = in_domain_list\n",
    "    # print(in_domain_list)\n",
    "    condition = orig_df['in_domain'] == True\n",
    "    rows = orig_df.loc[condition, :]\n",
    "    \n",
    "    in_domain_df = pd.DataFrame(columns=orig_df.columns)\n",
    "    in_domain_df = in_domain_df.append(rows, ignore_index=True)\n",
    "    in_domain_df = in_domain_df.drop(['in_domain'], axis=1)\n",
    "    return in_domain_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5107976f",
   "metadata": {},
   "source": [
    "Getting Dataset of Mutations _in_ Secondary Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "105cc5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "# - orig_df: original dataframe with all mutations and \"positions_split\" column which has mutation positions in split list\n",
    "#            as ints\n",
    "# - sec_st_df: new dataframe with all rows that have mutations in the secondary structure of protein\n",
    "# - mixed_df: new dataframe with all rows that have mutations in both in and out of the secondary stucture of the protein\n",
    "# - start: (inclusive) index where the domain of the protein in PDB file starts\n",
    "# - end: (inclusive) index where the domain of the protein in PDB file ends\n",
    "def get_ss_dataset(orig_df, bool_ss_list, domain_start_index):\n",
    "    \n",
    "    has_sec_str = []\n",
    "    \n",
    "    for val in orig_df[\"positions_split\"]:\n",
    "        # list of boolean values that are true if all mutation positions in line are sec. strc.\n",
    "        all_pos_sec_struc = []\n",
    "        \n",
    "        for position in val:\n",
    "            # print(position - domain_start_index)\n",
    "            # print(str(position) + \" \" + str(domain_start_index))\n",
    "            if (bool_ss_list[position - domain_start_index] == False): # line up ss_indexes w/ position\n",
    "                all_pos_sec_struc.append(False)\n",
    "            else:\n",
    "                all_pos_sec_struc.append(True)\n",
    "        \n",
    "        # all pos sec struc should match val list\n",
    "        # if there's a value in all_pos_sec_struc that's false, append false\n",
    "        # otherwise, append true\n",
    "        # print(\"val\")\n",
    "        # print(val)\n",
    "        # print(\"bool\")\n",
    "        # print(all_pos_sec_struc)\n",
    "        if (all_pos_sec_struc.count(False) == 0):\n",
    "            has_only_sec_str = True\n",
    "        else:\n",
    "            has_only_sec_str = False\n",
    "        \n",
    "        # print(has_only_sec_str)\n",
    "        has_sec_str.append(has_only_sec_str)\n",
    "        all_pos_sec_struc.clear()\n",
    "        \n",
    "        \n",
    "    # print(len(has_sec_str)) # should match dataframe length\n",
    "    orig_df['has_sec_str'] = has_sec_str\n",
    "    \n",
    "    condition = orig_df['has_sec_str'] == True\n",
    "    rows = orig_df.loc[condition, :]\n",
    "    \n",
    "    sec_str_df = pd.DataFrame(columns=orig_df.columns)\n",
    "    sec_str_df = sec_str_df.append(rows, ignore_index=True)\n",
    "    sec_str_df = sec_str_df.drop(['has_sec_str'], axis=1)\n",
    "    orig_df = orig_df.drop(['has_sec_str'], axis=1)\n",
    "    \n",
    "    return sec_str_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebcd87b",
   "metadata": {},
   "source": [
    "Getting Dataset of Mutations _not_ in Secondary Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c91576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_not_ss_dataset(orig_df, bool_ss_list, domain_start_index):\n",
    "    is_not_sec_str = []\n",
    "    \n",
    "    for val in orig_df[\"positions_split\"]:\n",
    "        \n",
    "        all_pos_sec_struc = []\n",
    "        \n",
    "        for position in val:\n",
    "            # print(position - domain_start_index)\n",
    "            # print(str(position) + \" \" + str(domain_start_index))\n",
    "            if (bool_ss_list[position - domain_start_index] == False):\n",
    "                all_pos_sec_struc.append(False)\n",
    "            else:\n",
    "                all_pos_sec_struc.append(True)\n",
    "    \n",
    "        \n",
    "        if (all_pos_sec_struc.count(True) == 0):\n",
    "            has_no_sec_str = True\n",
    "        else:\n",
    "            has_no_sec_str = False\n",
    "        \n",
    "        is_not_sec_str.append(has_no_sec_str)\n",
    "        all_pos_sec_struc.clear()\n",
    "        \n",
    "    orig_df['is_not_sec_str'] = is_not_sec_str\n",
    "     \n",
    "    condition = orig_df['is_not_sec_str'] == True\n",
    "    rows = orig_df.loc[condition, :]\n",
    "    \n",
    "    not_sec_str_df = pd.DataFrame(columns=orig_df.columns)\n",
    "    not_sec_str_df = not_sec_str_df.append(rows, ignore_index=True)\n",
    "    not_sec_str_df = not_sec_str_df.drop(['is_not_sec_str'], axis=1)\n",
    "    orig_df = orig_df.drop(['is_not_sec_str'], axis=1)\n",
    "    \n",
    "    return not_sec_str_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a73920",
   "metadata": {},
   "source": [
    "Writing formatted data to txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0047251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters:\n",
    "#      \"txt_name\" - desired name of formatted txt file for network. E.g. \"pab1\"\n",
    "#      \"protein_seq\" - string of protein sequence in 3 letter convention. E.g. ALA GLU TYR\n",
    "#      \"df\" - dataframe with cleaned protein data. Must contain \"variant\" and \"score\" \n",
    "#             columns.\n",
    "# This method cleans the protein data and formats it into a txt that can be processed by the \n",
    "# network. It also prints the name of the file out for reference.\n",
    "def write_data_file(txt_name, protein_seq, df):\n",
    "    file_name = txt_name + \".txt\"\n",
    "    path_name = \"../ML Script Data Files/\" + file_name\n",
    "    print(\"Filename: \" + file_name)\n",
    "    \n",
    "    datafile = open(path_name, \"w+\")\n",
    "    datafile.write(protein_seq + \"\\n\")\n",
    "    for index in range(len(df)-1):\n",
    "        datafile.write(df[\"variant\"].iloc[index] + \": \" + str(df[\"score\"].iloc[index]) + \"\\n\")\n",
    "    datafile.write(df[\"variant\"].iloc[len(df) - 1] + \": \" + str(df[\"score\"].iloc[len(df) - 1]))\n",
    "    datafile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d879d11f",
   "metadata": {},
   "source": [
    "Getting dataset of mutations that are in alpha helices: (H, G, I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2874018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters: \n",
    "#      \"stride file\" - stride file of protein\n",
    "#      \"is_sec_struc\" - list of boolean values for each secondary structure value\n",
    "#                       if it is, true, else false\n",
    "# returns list of boolean values indicating if position is secondary strcuture or not\n",
    "def get_alpha_boolean(stride_file):\n",
    "    # print('hi')\n",
    "    is_alpha = []\n",
    "    alpha_assign = []\n",
    "\n",
    "    for line in stride_file:\n",
    "        # print(line)\n",
    "        # print(\"why isn't this working\")\n",
    "        if line.startswith('ASG'):\n",
    "            split_line = line.split();\n",
    "            # print(split_line[5])\n",
    "            alpha_assign.append(split_line[5])\n",
    "    \n",
    "    print(alpha_assign)\n",
    "    \n",
    "    alpha_letters = ['H','G','I']\n",
    "    for alpha in alpha_assign:\n",
    "        if (alpha_letters.count(alpha) != 0):\n",
    "            is_alpha.append(True)\n",
    "        else:\n",
    "            is_alpha.append(False)\n",
    "    \n",
    "    print(alpha_assign)\n",
    "    print(is_alpha)\n",
    "    \n",
    "    return is_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab006f3",
   "metadata": {},
   "source": [
    "Getting dataset of mutations that are in beta sheets: (E, B or b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf1c76e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beta_boolean(stride_file):\n",
    "    # print('hi')\n",
    "    is_beta = []\n",
    "    beta_assign = []\n",
    "\n",
    "    for line in stride_file:\n",
    "        # print(line)\n",
    "        # print(\"why isn't this working\")\n",
    "        if line.startswith('ASG'):\n",
    "            split_line = line.split();\n",
    "            # print(split_line[5])\n",
    "            beta_assign.append(split_line[5])\n",
    "    \n",
    "    # print(beta_assign)\n",
    "    \n",
    "    beta_letters = ['E','B','b']\n",
    "    for beta in beta_assign:\n",
    "        if (beta_letters.count(beta) != 0):\n",
    "            is_beta.append(True)\n",
    "        else:\n",
    "            is_beta.append(False)\n",
    "    \n",
    "    print(beta_assign)\n",
    "    print(is_beta)\n",
    "    \n",
    "    return is_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d53435a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'E', 'E', 'E', 'E', 'E', 'T', 'T', 'T', 'T', 'T', 'T', 'C', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'C', 'C', 'C', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'T', 'T', 'T', 'T', 'C', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'T', 'T', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'T', 'T', 'E', 'E', 'E', 'T', 'T', 'E', 'E', 'E', 'E', 'E', 'E', 'C']\n",
      "[False, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, False, False, True, True, True, True, True, True, False]\n"
     ]
    }
   ],
   "source": [
    "pab1_beta_indices = get_beta_boolean(pab1_stride_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6458b0cf",
   "metadata": {},
   "source": [
    "Getting dataset of mutations that are turns: (T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c142c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_turns_boolean(stride_file):\n",
    "    # print('hi')\n",
    "    is_turn = []\n",
    "    turn_assign = []\n",
    "\n",
    "    for line in stride_file:\n",
    "        # print(line)\n",
    "        # print(\"why isn't this working\")\n",
    "        if line.startswith('ASG'):\n",
    "            split_line = line.split();\n",
    "            # print(split_line[5])\n",
    "            turn_assign.append(split_line[5])\n",
    "    \n",
    "    # print(beta_assign)\n",
    "    \n",
    "    for turn in turn_assign:\n",
    "        if (turn == \"T\"):\n",
    "            is_turn.append(True)\n",
    "        else:\n",
    "            is_turn.append(False)\n",
    "    \n",
    "    print(turn_assign)\n",
    "    print(is_turn)\n",
    "    \n",
    "    return is_turn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f0c59b",
   "metadata": {},
   "source": [
    "Getting dataset of mutations in secondary structure **including turns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6228b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters: \n",
    "#      \"stride file\" - stride file of protein\n",
    "#      \"is_sec_struc\" - list of boolean values for each secondary structure value\n",
    "#                       if it is, true, else false\n",
    "# returns list of boolean values indicating if position is secondary strcuture or not\n",
    "def get_all_sec_struc_boolean(stride_file):\n",
    "    is_sec_struc = []\n",
    "    sec_struc_assign = []\n",
    "\n",
    "    for line in stride_file:\n",
    "        if line.startswith('ASG'):\n",
    "            split_line = line.split();\n",
    "            sec_struc_assign.append(split_line[5])\n",
    "\n",
    "    for sec_struc in sec_struc_assign:\n",
    "        if (sec_struc =='C'):\n",
    "            is_sec_struc.append(False)\n",
    "        else:\n",
    "            is_sec_struc.append(True)\n",
    "            \n",
    "    return is_sec_struc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e7dfdd",
   "metadata": {},
   "source": [
    "Matching Segments of Non Secondary Structure to Secondary Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f5db1760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit number of mutations to some number\n",
    "# **use after get_domain dataset\n",
    "\n",
    "\n",
    "# same number of secondary structure assignments to not include\n",
    "# eg. []\n",
    "def get_excluded_res(indexes):\n",
    "    \n",
    "    # find the groups of secondary structure\n",
    "    ss_ind = [i for i,val in enumerate(indexes) if val==True]\n",
    "    ss_ind_groups = list(find_index_range(ss_ind))\n",
    "    print(ss_ind_groups)\n",
    "    \n",
    "    # find the groups of non secondary structure\n",
    "    not_ss_ind = [i for i,val in enumerate(indexes) if val==False]\n",
    "    not_ss_ind_groups = list(find_index_range(not_ss_ind))\n",
    "    print(not_ss_ind_groups)\n",
    "\n",
    "    ind_to_remove = []\n",
    "    # scenarios - less than, greater than, equal\n",
    "    \n",
    "    if (indexes.count(False) < indexes.count(True)): #is mostly ss\n",
    "        ind_to_remove = remove_indices_helper(not_ss_ind_groups, ss_ind_groups)\n",
    "    else: # NOT mostly ss and starts with ss\n",
    "          # chunk w/ ss elements\n",
    "        # print(\"in mostly not ss branch\")\n",
    "        ind_to_remove = remove_indices_helper(ss_ind_groups, not_ss_ind_groups)\n",
    "    \n",
    "    # print(ind_to_remove)\n",
    "    # ind_to_remove = list(itertools.chain.from_iterable(ind_to_remove))\n",
    "    return ind_to_remove\n",
    "    # more secondary structure groups or more pab1 indices\n",
    "    # return list of indices to NOT include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d5f62804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunked list, smaller values\n",
    "\n",
    "# returns list of indices to remove\n",
    "\n",
    "def remove_indices_helper(chunked_list, to_chunk_list):\n",
    "    remainder = []\n",
    "    count_to_remove = 0\n",
    "\n",
    "    for chunk, to_chunk in zip(chunked_list, to_chunk_list): # zip goes through the smallest of the lists\n",
    "        \n",
    "        chunk_exp_list = expand_list(chunk)\n",
    "        to_chunk_exp_list = expand_list(to_chunk)\n",
    "        \n",
    "        if (len(chunk_exp_list) < len(to_chunk_exp_list)):\n",
    "            remainder.append(to_chunk_exp_list[len(chunk_exp_list):]) # will add indices to remove to remainder list\n",
    "        elif (len(chunk_exp_list) > len(to_chunk_exp_list)):\n",
    "            count_to_remove = count_to_remove + (len(chunk_exp_list) - len(to_chunk_exp_list))\n",
    "    \n",
    "    remainder = list(itertools.chain.from_iterable(remainder))\n",
    "    if (count_to_remove != 0):\n",
    "        remainder = delete_random_elems(remainder, count_to_remove)\n",
    "    \n",
    "    return remainder         \n",
    "    # returns indices of values that are not to be included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e38256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out which one to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "92cdce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_list(val):\n",
    "    val_list = []\n",
    "    if isinstance(val, int):\n",
    "        val_list.append(val)\n",
    "    else:\n",
    "        val_list = list(range(val[0], val[-1]))\n",
    "    \n",
    "    return val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0c6dbafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.codegrepper.com/code-examples/python/python+remove+n+random+elements+from+a+list\n",
    "def delete_random_elems(input_list, n):\n",
    "    to_delete = set(random.sample(range(len(input_list)), n))\n",
    "    return [x for i,x in enumerate(input_list) if not i in to_delete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "209085f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining the ranges of false values \n",
    "# https://stackoverflow.com/questions/2154249/identify-groups-of-continuous-numbers-in-a-list\n",
    "\n",
    "# helper method - determines consecuetive values in list\n",
    "def find_index_range(indexes):\n",
    "    for segment in mit.consecutive_groups(indexes):\n",
    "        segment = list(segment)\n",
    "        if len(segment) == 1:\n",
    "            yield segment[0] # yield is like return, except that it\n",
    "                             # retains state to enable function to resume where\n",
    "                             # it left off (sequenve of vals vs. 1)\n",
    "        else:\n",
    "            yield segment[0], segment[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6774f1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 5), (13, 22), (26, 33), (39, 47), (50, 60), (63, 65), (68, 73)]\n",
      "[0, (6, 12), (23, 25), (34, 38), (48, 49), (61, 62), (66, 67), 74]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 3,\n",
       " 4,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 64,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_excluded_res(pab1_ss_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f8ed9981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 5), (13, 22), (26, 33), (39, 47), (50, 60), (63, 65), (68, 73)]\n",
      "[0, (6, 12), (23, 25), (34, 38), (48, 49), (61, 62), (66, 67), 74]\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "num_to_exclude = len(get_excluded_res(pab1_ss_indexes))\n",
    "print(num_to_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3192b31a",
   "metadata": {},
   "source": [
    "## Pab1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d91e646",
   "metadata": {},
   "source": [
    "Formatting Pab1 Data to Split Dataset into Values in Secondary Structure and NOT in Secondary Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9d6c77b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE - stride files + jupyter notebook in winter dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fbb4029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../PDB and STRIDE Files/\" + 'pab1_stride.txt'\n",
    "pab1_stride_file = open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a106180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pab1_ss_indexes = get_sec_struc_boolean(pab1_stride_file) # boolean list of secondary structure assignements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "de4fc2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "[False, True, True, True, True, True, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, False, False, True, True, True, True, True, True, False]\n"
     ]
    }
   ],
   "source": [
    "print(len(pab1_ss_indexes)) # <- domain is 75 AA long\n",
    "print(pab1_ss_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9c8f8918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "# number of mutations not in secondary structure\n",
    "count_false = pab1_ss_indexes.count(False)\n",
    "print(count_false)\n",
    "count_true = pab1_ss_indexes.count(True)\n",
    "print(count_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e7632a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# alpha helices \n",
    "# pab1_alpha_indices = get_alpha_boolean(pab1_stride_file)\n",
    "true = pab1_alpha_indices.count(True)\n",
    "false = pab1_alpha_indices.count(False)\n",
    "print(true)\n",
    "print(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a2a35dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'E', 'E', 'E', 'E', 'E', 'T', 'T', 'T', 'T', 'T', 'T', 'C', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'C', 'C', 'C', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'T', 'T', 'T', 'T', 'C', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'T', 'T', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'T', 'T', 'E', 'E', 'E', 'T', 'T', 'E', 'E', 'E', 'E', 'E', 'E', 'C']\n",
      "[False, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, False, False, True, True, True, True, True, True, False]\n"
     ]
    }
   ],
   "source": [
    "# beta sheets\n",
    "pab1_beta_indices = get_beta_boolean(pab1_stride_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "21fdbf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'E', 'E', 'E', 'E', 'E', 'T', 'T', 'T', 'T', 'T', 'T', 'C', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'C', 'C', 'C', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'T', 'T', 'T', 'T', 'C', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'T', 'T', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'T', 'T', 'E', 'E', 'E', 'T', 'T', 'E', 'E', 'E', 'E', 'E', 'E', 'C']\n",
      "[False, False, False, False, False, False, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, True, True, False, False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "# turns\n",
    "pab1_turn_indices = get_turns_boolean(pab1_stride_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c7d3f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# including turns\n",
    "\n",
    "pab1_all_ss_indices = get_all_sec_struc_boolean(pab1_stride_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7315ca",
   "metadata": {},
   "source": [
    "- Pab1 has 23 Mutations not in Secondary Structure, so limiting Number of Secondary Structure Mutations to 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e32610b7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "[1, 2, 3, 4, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 33, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 68, 69, 70, 71, 72, 73]\n",
      "[40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 68, 69, 70, 71, 72, 73]\n"
     ]
    }
   ],
   "source": [
    "# index of 23rd true\n",
    "\n",
    "highest_true_index = [i for i, n in enumerate(pab1_ss_indexes) if n == True][23]\n",
    "print(highest_true_index)\n",
    "# need list of indices in secondary structure past this index in order to remove them from dataset\n",
    "\n",
    "true_indices = [i for i,val in enumerate(pab1_ss_indexes) if val==True]\n",
    "print(true_indices)\n",
    "\n",
    "not_included_pab1 = [i for i in true_indices if i > 39]\n",
    "print(not_included_pab1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0a8e55",
   "metadata": {},
   "source": [
    "Limiting Number of Secondary Structure Mutations and Number in alpha helices versus out of it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f30d923",
   "metadata": {},
   "source": [
    "### Sorting Pab1 Mutations Into 2 Datasets (w & w/o mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de5b607e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40852\n",
      "Index(['variant', 'num_mutations', 'score'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# importing pab1 data from Gelman et al.\n",
    "pab1_df1 = pd.read_csv(\"../Raw Data/pab1.tsv.txt\", sep=\"\\t\")\n",
    "pab1_df = pab1_df1.dropna()\n",
    "print(len(pab1_df))\n",
    "print(pab1_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92bdfb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40852\n",
      "37710\n"
     ]
    }
   ],
   "source": [
    "# rounding score column to 2 decimal points\n",
    "pab1_df[\"score\"] = pab1_df[\"score\"].round(6)\n",
    "print(len(pab1_df))\n",
    "\n",
    "# remove values with wildcard star thing cause idk what it means\n",
    "pab1_df = pab1_df[pab1_df[\"variant\"].str.contains(\"\\*\") == False]\n",
    "\n",
    "# pab1_df = pab1_df.head(37600)\n",
    "print(len(pab1_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82cef935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split variant name into wild-type, position, and mutation type\n",
    "pab1_mut = pab1_df[\"variant\"].str.split(\",\")\n",
    "pab1_df[\"WILD_TYPE_RES\"] = get_wild_type(pab1_mut)\n",
    "pab1_df[\"MUTATED_RES\"] = get_mutation_type(pab1_mut)\n",
    "pab1_df[\"POSITION\"] = get_position(pab1_mut)\n",
    "pab1_df[\"variant\"] = get_mutations_names_list(pab1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96f5364b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['variant', 'num_mutations', 'score', 'WILD_TYPE_RES', 'MUTATED_RES',\n",
      "       'POSITION'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print(pab1_df.head)\n",
    "print(pab1_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1418269c",
   "metadata": {},
   "source": [
    "Moving rows with Secondary Structure position into a different dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e529c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pab1_df[\"positions_split\"] = get_positions_split(pab1_df)\n",
    "# print(pab1_df[\"positions_split\"].tail(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7134aba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pab_in_domain_df = get_domain_dataset(pab1_df, 126, 201, not_included_pab1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49bbf2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22318\n"
     ]
    }
   ],
   "source": [
    "print(len(pab_in_domain_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40275ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5828\n"
     ]
    }
   ],
   "source": [
    "pab1_ss_df = get_ss_dataset(pab_in_domain_df, pab1_ss_indexes, 126)\n",
    "print(len(pab1_ss_df))\n",
    "# 5828 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c3738f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2880\n"
     ]
    }
   ],
   "source": [
    "# mini-dataset of 2880 values to compare mutations to non mutations:\n",
    "pab1_ss_df_3000 = pab1_ss_df.sample(n=2880)\n",
    "print(len(pab1_ss_df_3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb3adce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3927\n"
     ]
    }
   ],
   "source": [
    "pab1_not_ss_df = get_not_ss_dataset(pab_in_domain_df, pab1_ss_indexes, 126)\n",
    "print(len(pab1_not_ss_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "613a1296",
   "metadata": {},
   "outputs": [],
   "source": [
    "pab1_not_ss_df_3000 = pab1_not_ss_df.sample(n=2880)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed227be",
   "metadata": {},
   "source": [
    "### Putting Pab1 Datasets into Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a561f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_seq_pab1 = get_protein_seq(\"P04147\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b09da365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577\n"
     ]
    }
   ],
   "source": [
    "split_pab1 = protein_seq_pab1.split()\n",
    "print(len(split_pab1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "149349f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE - 3000 vals is actually 2880"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3aa2bc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: pab1_MLformat_ss_2880_lim.txt\n",
      "Filename: pab1_MLformat_not_ss_2880_lim.txt\n"
     ]
    }
   ],
   "source": [
    "# write data to formatted txt file\n",
    "\n",
    "write_data_file(\"pab1_MLformat_ss_2880_lim\", protein_seq_pab1, pab1_ss_df_3000)\n",
    "write_data_file(\"pab1_MLformat_not_ss_2880_lim\", protein_seq_pab1, pab1_not_ss_df_3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feea517",
   "metadata": {},
   "source": [
    "## Bgl3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f3127",
   "metadata": {},
   "source": [
    "Formatting Bgl3 Data to Split Dataset into Values in Secondary Structure and NOT in Secondary Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0cdf7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../PDB and STRIDE Files/\" + 'bgl3_stride.txt'\n",
    "bgl3_stride_file = open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "09af26c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgl3_ss_indexes = get_sec_struc_boolean(bgl3_stride_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2f0e47d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, True, True, True, True, True, False, False, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, False, False, True, True, True, True, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, False, False, False, False, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, True, True, False, False, False, True, True, True, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, False, False, False, False, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, True, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, False, True, True, True, False, False, False, True, True, True, True, True, False, False, False, True, False, True, True, True, True, True, True, False, False, False, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "print(len(bgl3_ss_indexes))\n",
    "print(bgl3_ss_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3983dd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229\n",
      "272\n"
     ]
    }
   ],
   "source": [
    "# number of mutations in secondary structure (True), and not in secondary structure (False)\n",
    "count_false = bgl3_ss_indexes.count(False)\n",
    "print(count_false)\n",
    "\n",
    "count_true = bgl3_ss_indexes.count(True)\n",
    "print(count_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "70dc8219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(15, 16), (22, 26), (29, 33), (44, 51), (57, 59), (71, 82), (86, 90), (93, 96), (106, 122), (125, 131), (136, 142), (148, 166), (171, 176), (178, 187), (198, 222), (228, 234), (238, 240), (245, 268), (273, 279), (292, 296), (302, 306), (311, 313), 343, 350, 356, (359, 372), (378, 383), 387, (400, 419), (423, 428), (430, 432), (436, 440), 444, (446, 451), (456, 459), (461, 472), (474, 475)]\n",
      "[(0, 14), (17, 21), (27, 28), (34, 43), (52, 56), (60, 70), (83, 85), (91, 92), (97, 105), (123, 124), (132, 135), (143, 147), (167, 170), 177, (188, 197), (223, 227), (235, 237), (241, 244), (269, 272), (280, 291), (297, 301), (307, 310), (314, 342), (344, 349), (351, 355), (357, 358), (373, 377), (384, 386), (388, 399), (420, 422), 429, (433, 435), (441, 443), 445, (452, 455), 460, 473, (476, 500)]\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "num_to_exclude = len(get_excluded_res(bgl3_ss_indexes))\n",
    "print(num_to_exclude) # should be 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e933d060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416\n"
     ]
    }
   ],
   "source": [
    "# index of 416 true\n",
    "\n",
    "highest_true_index = [i for i, n in enumerate(bgl3_ss_indexes) if n == True][229]\n",
    "print(highest_true_index)\n",
    "# need list of indices past this index\n",
    "\n",
    "true_indices = [i for i,val in enumerate(bgl3_ss_indexes) if val==True]\n",
    "# print(true_indices)\n",
    "\n",
    "not_included_bgl3 = [i for i in true_indices if i > highest_true_index]\n",
    "# print(not_included_bgl3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b4fd710b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26653\n",
      "Index(['variant', 'num_mutations', 'inp', 'sel', 'score'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# importing bgl3 data from Gelman et al.\n",
    "bgl3_df1 = pd.read_csv(\"../Raw Data/bgl3.tsv.txt\", sep=\"\\t\")\n",
    "bgl3_df = bgl3_df1.dropna()\n",
    "print(len(bgl3_df))\n",
    "print(bgl3_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4bb31c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26653\n",
      "25737\n"
     ]
    }
   ],
   "source": [
    "# rounding score column to 6 decimal points\n",
    "bgl3_df[\"score\"] = bgl3_df[\"score\"].round(6)\n",
    "print(len(bgl3_df))\n",
    "\n",
    "# remove values with wildcard star\n",
    "bgl3_df = bgl3_df[bgl3_df[\"variant\"].str.contains(\"\\*\") == False]\n",
    "# bgl3_df = bgl3_df.head(25600)\n",
    "print(len(bgl3_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d48be577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bgl3 protein sequence\n",
    "string_seq = \"MVPAAQQTAMAPDAALTFPEGFLWGSATASYQIEGAAAEDGRTPSIWDTYARTPGRVRNGDTGDVATDHYHRWREDVALMAELGLGAYRFSLAWPRIQPTGRGPALQKGLDFYRRLADELLAKGIQPVATLYHWDLPQELENAGGWPERATAERFAEYAAIAADALGDRVKTWTTLNEPWCSAFLGYGSGVHAPGRTDPVAALRAAHHLNLGHGLAVQALRDRLPADAQCSVTLNIHHVRPLTDSDADADAVRRIDALANRVFTGPMLQGAYPEDLVKDTAGLTDWSFVRDGDLRLAHQKLDFLGVNYYSPTLVSEADGSGTHNSDGHGRSAHSPWPGADRVAFHQPPGETTAMGWAVDPSGLYELLRRLSSDFPALPLVITENGAAFHDYADPEGNVNDPERIAYVRDHLAAVHRAIKDGSDVRGYFLWSLLDNFEWAHGYSKRFGAVYVDYPTGTRIPKASARWYAEVARTGVLPTAGDPNSSSVDKLAAALEHHHHHH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "712c0b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n"
     ]
    }
   ],
   "source": [
    "print(len(string_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ebf68fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MET VAL PRO ALA ALA GLN GLN THR ALA MET ALA PRO ASP ALA ALA LEU THR PHE PRO GLU GLY PHE LEU TRP GLY SER ALA THR ALA SER TYR GLN ILE GLU GLY ALA ALA ALA GLU ASP GLY ARG THR PRO SER ILE TRP ASP THR TYR ALA ARG THR PRO GLY ARG VAL ARG ASN GLY ASP THR GLY ASP VAL ALA THR ASP HIS TYR HIS ARG TRP ARG GLU ASP VAL ALA LEU MET ALA GLU LEU GLY LEU GLY ALA TYR ARG PHE SER LEU ALA TRP PRO ARG ILE GLN PRO THR GLY ARG GLY PRO ALA LEU GLN LYS GLY LEU ASP PHE TYR ARG ARG LEU ALA ASP GLU LEU LEU ALA LYS GLY ILE GLN PRO VAL ALA THR LEU TYR HIS TRP ASP LEU PRO GLN GLU LEU GLU ASN ALA GLY GLY TRP PRO GLU ARG ALA THR ALA GLU ARG PHE ALA GLU TYR ALA ALA ILE ALA ALA ASP ALA LEU GLY ASP ARG VAL LYS THR TRP THR THR LEU ASN GLU PRO TRP CYS SER ALA PHE LEU GLY TYR GLY SER GLY VAL HIS ALA PRO GLY ARG THR ASP PRO VAL ALA ALA LEU ARG ALA ALA HIS HIS LEU ASN LEU GLY HIS GLY LEU ALA VAL GLN ALA LEU ARG ASP ARG LEU PRO ALA ASP ALA GLN CYS SER VAL THR LEU ASN ILE HIS HIS VAL ARG PRO LEU THR ASP SER ASP ALA ASP ALA ASP ALA VAL ARG ARG ILE ASP ALA LEU ALA ASN ARG VAL PHE THR GLY PRO MET LEU GLN GLY ALA TYR PRO GLU ASP LEU VAL LYS ASP THR ALA GLY LEU THR ASP TRP SER PHE VAL ARG ASP GLY ASP LEU ARG LEU ALA HIS GLN LYS LEU ASP PHE LEU GLY VAL ASN TYR TYR SER PRO THR LEU VAL SER GLU ALA ASP GLY SER GLY THR HIS ASN SER ASP GLY HIS GLY ARG SER ALA HIS SER PRO TRP PRO GLY ALA ASP ARG VAL ALA PHE HIS GLN PRO PRO GLY GLU THR THR ALA MET GLY TRP ALA VAL ASP PRO SER GLY LEU TYR GLU LEU LEU ARG ARG LEU SER SER ASP PHE PRO ALA LEU PRO LEU VAL ILE THR GLU ASN GLY ALA ALA PHE HIS ASP TYR ALA ASP PRO GLU GLY ASN VAL ASN ASP PRO GLU ARG ILE ALA TYR VAL ARG ASP HIS LEU ALA ALA VAL HIS ARG ALA ILE LYS ASP GLY SER ASP VAL ARG GLY TYR PHE LEU TRP SER LEU LEU ASP ASN PHE GLU TRP ALA HIS GLY TYR SER LYS ARG PHE GLY ALA VAL TYR VAL ASP TYR PRO THR GLY THR ARG ILE PRO LYS ALA SER ALA ARG TRP TYR ALA GLU VAL ALA ARG THR GLY VAL LEU PRO THR ALA GLY ASP PRO ASN SER SER SER VAL ASP LYS LEU ALA ALA ALA LEU GLU HIS HIS HIS HIS HIS HIS\n"
     ]
    }
   ],
   "source": [
    "protein_seq_bgl3 = get_expanded_seq(string_seq)\n",
    "print(protein_seq_bgl3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "97b4d710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n"
     ]
    }
   ],
   "source": [
    "split = protein_seq_bgl3.split()\n",
    "print(len(split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "26360a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split variant name into wild-type, position, and mutation type\n",
    "bgl3_mut = bgl3_df[\"variant\"].str.split(\",\")\n",
    "bgl3_df[\"WILD_TYPE_RES\"] = get_wild_type(bgl3_mut)\n",
    "bgl3_df[\"MUTATED_RES\"] = get_mutation_type(bgl3_mut)\n",
    "bgl3_df[\"POSITION\"] = get_position(bgl3_mut)\n",
    "bgl3_df[\"variant\"] = get_mutations_names_list(bgl3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0863038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgl3_df[\"positions_split\"] = get_positions_split(bgl3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2610e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgl3_in_domain_df = get_domain_dataset(bgl3_df, 0, 550, not_included_bgl3) # ending is larger than sequence length bc. all mutations inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f99d15c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6869\n"
     ]
    }
   ],
   "source": [
    "bgl3_ss_df = get_ss_dataset(bgl3_in_domain_df, bgl3_ss_indexes, 0)\n",
    "print(len(bgl3_ss_df))\n",
    "bgl3_ss_df_3000 = bgl3_ss_df.sample(n=2880)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8b8d4ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7537\n"
     ]
    }
   ],
   "source": [
    "bgl3_not_ss_df = get_not_ss_dataset(bgl3_in_domain_df, bgl3_ss_indexes, 0)\n",
    "print(len(bgl3_not_ss_df))\n",
    "bgl3_not_ss_df_3000 = bgl3_not_ss_df.sample(n=2880)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "62b4d3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: bgl3_MLformat_ss_2880_lim.txt\n",
      "Filename: bgl3_MLformat_not_ss_2880_lim.txt\n"
     ]
    }
   ],
   "source": [
    "# write data to formatted txt file\n",
    "\n",
    "write_data_file(\"bgl3_MLformat_ss_2880_lim\", protein_seq_bgl3, bgl3_ss_df_3000)\n",
    "write_data_file(\"bgl3_MLformat_not_ss_2880_lim\", protein_seq_bgl3, bgl3_not_ss_df_3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d27ff8",
   "metadata": {},
   "source": [
    "## Ube4B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a9a214a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../PDB and STRIDE Files/\" + 'ube4b_stride.txt'\n",
    "ube4b_stride_file = open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "48cc9526",
   "metadata": {},
   "outputs": [],
   "source": [
    "ube4b_ss_indexes = get_sec_struc_boolean(ube4b_stride_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "95bcc598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "[False, False, False, False, False, False, False, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, False, False, False, False, True, True, False, False, False, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, True, True, False, False, False, False, True, True, False, False, False, False, False, False, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "print(len(ube4b_ss_indexes))\n",
    "print(ube4b_ss_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7e2d521e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7, 13), (29, 33), (38, 39), (43, 46), (50, 62), (66, 67), (72, 73), (80, 81), (83, 98)]\n",
      "[(0, 6), (14, 28), (34, 37), (40, 42), (47, 49), (63, 65), (68, 71), (74, 79), 82, (99, 101)]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6544/283876809.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnum_to_exclude\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_excluded_res\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mube4b_ss_indexes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_to_exclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6544/695056269.py\u001b[0m in \u001b[0;36mget_excluded_res\u001b[1;34m(indexes)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#is mostly ss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mind_to_remove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_indices_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_ss_ind_groups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mss_ind_groups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# NOT mostly ss and starts with ss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m           \u001b[1;31m# chunk w/ ss elements\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6544/497980707.py\u001b[0m in \u001b[0;36mremove_indices_helper\u001b[1;34m(chunked_list, to_chunk_list)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# randomly remove number of extra terms needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcount_to_remove\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mdelete_random_elems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremainder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount_to_remove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# print(remainder)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6544/3574809666.py\u001b[0m in \u001b[0;36mdelete_random_elems\u001b[1;34m(input_list, n)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# https://www.codegrepper.com/code-examples/python/python+remove+n+random+elements+from+a+list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdelete_random_elems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mto_delete\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto_delete\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\random.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, population, k, counts)\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[0mrandbelow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m21\u001b[0m        \u001b[1;31m# size of a small set minus size of an empty list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "num_to_exclude = len(get_excluded_res(ube4b_ss_indexes))\n",
    "print(num_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8974bc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "[7, 8, 9, 10, 11, 12, 13, 29, 30, 31, 32, 33, 38, 39, 43, 44, 45, 46, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 66, 67, 72, 73, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]\n",
      "[96, 97, 98]\n"
     ]
    }
   ],
   "source": [
    "# index of 23rd true\n",
    "\n",
    "highest_true_index = [i for i, n in enumerate(ube4b_ss_indexes) if n == True][49]\n",
    "print(highest_true_index)\n",
    "# need list of indices past this index\n",
    "\n",
    "true_indices = [i for i,val in enumerate(ube4b_ss_indexes) if val==True]\n",
    "print(true_indices)\n",
    "\n",
    "not_included_ube4b = [i for i in true_indices if i > highest_true_index]\n",
    "# [x for x in a if x <= 5]\n",
    "print(not_included_ube4b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c071e5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "# number of mutations in secondary structure (True), and not in secondary structure (False)\n",
    "count_false = ube4b_ss_indexes.count(False)\n",
    "print(count_false)\n",
    "\n",
    "count_true = ube4b_ss_indexes.count(True)\n",
    "print(count_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6f5eada7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98297\n",
      "Index(['variant', 'num_mutations', 'score'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# importing Ube4b data from Gelman et al.\n",
    "ube4b_df1 = pd.read_csv(\"../Raw Data/ube4b.tsv.txt\", sep=\"\\t\")\n",
    "ube4b_df = ube4b_df1.dropna()\n",
    "print(len(ube4b_df))\n",
    "print(ube4b_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "08b1e5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98297\n",
      "91031\n"
     ]
    }
   ],
   "source": [
    "# rounding score column to 6 decimal points\n",
    "ube4b_df[\"score\"] = ube4b_df[\"score\"].round(6)\n",
    "print(len(ube4b_df))\n",
    "\n",
    "# remove values with wildcard star\n",
    "ube4b_df = ube4b_df[ube4b_df[\"variant\"].str.contains(\"\\*\") == False]\n",
    "print(len(ube4b_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "99e2ef8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n"
     ]
    }
   ],
   "source": [
    "protein_seq_ube4b = get_protein_seq(\"Q9ES00\")\n",
    "split_entire = protein_seq_ube4b.split()\n",
    "print(len(split_entire))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "97916a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "string_seq = \"IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLNSPTDPFNRQMLTESMLEPVPELKEQIQAWMREKQSSDH\"\n",
    "print(len(string_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "360f08e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILE GLU LYS PHE LYS LEU LEU ALA GLU LYS VAL GLU GLU ILE VAL ALA LYS ASN ALA ARG ALA GLU ILE ASP TYR SER ASP ALA PRO ASP GLU PHE ARG ASP PRO LEU MET ASP THR LEU MET THR ASP PRO VAL ARG LEU PRO SER GLY THR VAL MET ASP ARG SER ILE ILE LEU ARG HIS LEU LEU ASN SER PRO THR ASP PRO PHE ASN ARG GLN MET LEU THR GLU SER MET LEU GLU PRO VAL PRO GLU LEU LYS GLU GLN ILE GLN ALA TRP MET ARG GLU LYS GLN SER SER ASP HIS\n"
     ]
    }
   ],
   "source": [
    "protein_seq_ube4b_domain = get_expanded_seq(string_seq)\n",
    "print(protein_seq_ube4b_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9dd10e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "LYS\n"
     ]
    }
   ],
   "source": [
    "split = protein_seq_ube4b_domain.split()\n",
    "print(len(split)) \n",
    "print(split[96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "bfb86cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['variant', 'num_mutations', 'score', 'WILD_TYPE_RES', 'MUTATED_RES',\n",
      "       'POSITION'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ube4b_mut = ube4b_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "ube4b_df[\"WILD_TYPE_RES\"] = get_wild_type(ube4b_mut)\n",
    "ube4b_df[\"MUTATED_RES\"] = get_mutation_type(ube4b_mut)\n",
    "ube4b_df[\"POSITION\"] = get_position(ube4b_mut)\n",
    "\n",
    "ube4b_df[\"variant\"] = get_mutations_names_list(ube4b_df)\n",
    "print(ube4b_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "14216eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ube4b_df[\"positions_split\"] = get_positions_split(ube4b_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e7e9c6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81832\n"
     ]
    }
   ],
   "source": [
    "# ube4b_in_domain_df = get_domain_dataset(ube4b_df, 0, 1200)\n",
    "ube4b_in_domain_df = get_domain_dataset(ube4b_df, 0, 2000, not_included_ube4b)\n",
    "print(len(ube4b_in_domain_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d4d200c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11450\n"
     ]
    }
   ],
   "source": [
    "ube4b_ss_df = get_ss_dataset(ube4b_in_domain_df, ube4b_ss_indexes, 0)\n",
    "print(len(ube4b_ss_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "56954c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20301\n"
     ]
    }
   ],
   "source": [
    "ube4b_not_ss_df = get_not_ss_dataset(ube4b_in_domain_df, ube4b_ss_indexes, 0)\n",
    "print(len(ube4b_not_ss_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "769dc7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ube4b_ss_df_3000 = ube4b_ss_df.sample(n=2880)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "07768344",
   "metadata": {},
   "outputs": [],
   "source": [
    "ube4b_not_ss_df_3000 = ube4b_not_ss_df.sample(n=2880)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d5a48140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: ube4b_MLformat_ss_2880_lim.txt\n",
      "Filename: ube4b_MLformat_not_ss_2880_lim.txt\n"
     ]
    }
   ],
   "source": [
    "# write data to formatted txt file\n",
    "\n",
    "write_data_file(\"ube4b_MLformat_ss_2880_lim\", protein_seq_ube4b, ube4b_ss_df_3000)\n",
    "write_data_file(\"ube4b_MLformat_not_ss_2880_lim\", protein_seq_ube4b, ube4b_not_ss_df_3000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
