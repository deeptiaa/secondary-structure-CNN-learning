{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0718f70",
   "metadata": {},
   "source": [
    "# Sorting Protein Mutations Using STRIDE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0758cbdf",
   "metadata": {},
   "source": [
    "This notebook divides the dataset into seperate datasets depended on a mutations secondary structure assignment. It is used for Part 1 of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed88bc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from Bio import SeqIO\n",
    "from io import StringIO\n",
    "import Bio.PDB.Polypeptide\n",
    "import random\n",
    "import itertools\n",
    "import more_itertools as mit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d443211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting jupyter notebook viewing options\n",
    "max_rows = 1000\n",
    "max_cols = 1000\n",
    "pd.set_option(\"display.max_rows\", max_rows, \"display.max_columns\", max_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0748eb30",
   "metadata": {},
   "source": [
    "### Methods Used to Format Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f031f61a",
   "metadata": {},
   "source": [
    "Formatting protein sequence into form for machine learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54768902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters:\n",
    "#      \"uniprot_id\" - string representing uniprot id of desired protein.\n",
    "# This method uses a given uniprot id to query the uniprot data and \n",
    "# return a string respresention of the protein sequence. \n",
    "# E.g. MADIT\n",
    "def get_protein_seq(uniprot_id):\n",
    "    \n",
    "    # importing fasta file from uniprot.org and getting protein sequence\n",
    "    # taken from StackOverflow: \n",
    "    # https://stackoverflow.com/questions/52569622/protein-sequence-from-uniprot-protein-id-python\n",
    "    url = \"http://www.uniprot.org/uniprot/\"\n",
    "    complete_url = url + uniprot_id + \".fasta\"\n",
    "    response = requests.post(complete_url)\n",
    "    data =''.join(response.text)\n",
    "    sequence =StringIO(data)\n",
    "    protein_seq=list(SeqIO.parse(sequence,'fasta'))\n",
    "\n",
    "    # protein sequence as string (single-letter amino acids)\n",
    "    string_seq = str(protein_seq[0].seq)\n",
    "    \n",
    "    # protein sequence w/ three-letter convention\n",
    "    protein_seq = get_expanded_seq(string_seq)\n",
    "    return protein_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f0f7a7",
   "metadata": {},
   "source": [
    "Expanding protein sequence (1 letter AA -> 3 letter AA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feff7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter:\n",
    "#      \"seq\" - string representing protein sequence in 1-letter convention.\n",
    "# This method takes protein sequence string with 1-letter convention and returns\n",
    "# a protein sequence with 3-letter convention.\n",
    "# E.g. ADE -> ALA ASP GLU\n",
    "def get_expanded_seq(seq):\n",
    "    expanded_list = []\n",
    "    split_seq = list(seq)\n",
    "    for letter in split_seq:\n",
    "        three_letter_abbr = Bio.PDB.Polypeptide.one_to_three(letter)\n",
    "        expanded_list.append(three_letter_abbr)\n",
    "    exanded_string = \" \".join(expanded_list)\n",
    "    return(exanded_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b58ef07",
   "metadata": {},
   "source": [
    "Returning index range of protein domain within protein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec3f7d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters: \n",
    "#      \"full_protein_split\" - list of amino acids in full protein in 3 letter convention.\n",
    "#                             E.g. [\"ALA\", \"GLY\", \"TYR\"]\n",
    "#      \"domain_split\" - list of amino acids in protein domain in 3 letter convention.\n",
    "#                       E.g. [\"ALA\", \"GLY\"]\n",
    "# This method prints the index of the given domain within the given protein.\n",
    "# Starting value is inclusive and the ending value is exclusive. \n",
    "# E.g. [(0, 3)]\n",
    "def get_index_range(full_protein_split, domain_split):\n",
    "    indexes = []\n",
    "    for i in range(len(full_protein_split)):\n",
    "        if full_protein_split[i:i+len(domain_split)] == domain_split:\n",
    "            indexes.append((i, i+len(domain_split)))\n",
    "    print(indexes)\n",
    "    indexes.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0190a9f0",
   "metadata": {},
   "source": [
    "Get variant in mutation-position form from wild-type-position-mutation form: (E.g. G126A -> 126ALA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0954fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter: \n",
    "#      \"split_mutation_column\" - list of mutations, split by comma if there are multiple.\n",
    "# This method returns a list with wild-type residue (first letter) from variant.\n",
    "def get_wild_type(split_mutation_column):\n",
    "    wild_type_list = []\n",
    "    w_letters = []\n",
    "    for string in split_mutation_column:\n",
    "        if \"wild-type\" in string[0]:\n",
    "            wild_type = \"wild_type\"\n",
    "        elif \"-\" in string[0] or len(string) == 0:\n",
    "            wild_type = np.nan\n",
    "        else:\n",
    "            for val in string:\n",
    "                mutation_name = val.strip(\" \")\n",
    "                w_letters.append(mutation_name[0])\n",
    "                wild_type = \",\".join(w_letters)\n",
    "        wild_type_list.append(wild_type)\n",
    "        w_letters.clear()\n",
    "    return wild_type_list\n",
    "\n",
    "\n",
    "# parameter: \n",
    "#      \"split_mutation_column\" - list of mutations, split by comma if there are multiple.\n",
    "# This method returns a list with mutation residue (last letter) from variant.\n",
    "def get_mutation_type(split_mutation_column):\n",
    "    mutation_list = []\n",
    "    m_letters = []\n",
    "    for string in split_mutation_column:\n",
    "        if \"wild-type\" in string[0]:\n",
    "            mutation = \"wild-type\"\n",
    "        elif \"-\" in string[0] or len(string) == 0:\n",
    "            mutation = np.nan\n",
    "        else:\n",
    "            for val in string:\n",
    "                mutation_name = val.strip(\" \")\n",
    "                m_letters.append(mutation_name[-1])\n",
    "                mutation = \",\".join(m_letters)\n",
    "        mutation_list.append(mutation)\n",
    "        m_letters.clear()\n",
    "    return mutation_list\n",
    "\n",
    "\n",
    "# parameter: \n",
    "#      \"split_mutation_column\" - list of mutations, split by comma if there are multiple.\n",
    "# This method returns a list with the position of mutation (number) from variant.\n",
    "def get_position(split_mutation_column):\n",
    "    position_list = []\n",
    "    p_letters = []\n",
    "    for string in split_mutation_column:\n",
    "        if \"wild-type\" in string[0]:\n",
    "            position = \"wild-type\"\n",
    "        elif \"-\" in string[0] or len(string) == 0:\n",
    "            position = np.nan\n",
    "        else:\n",
    "            for val in string:\n",
    "                mutation_name = val.strip(\" \")\n",
    "                p_letters.append(mutation_name[1:-1])\n",
    "                position = \",\".join(p_letters)\n",
    "        position_list.append(position)\n",
    "        p_letters.clear()\n",
    "    return(position_list)\n",
    "\n",
    "\n",
    "# parameter:\n",
    "#      \"df\" - dataframe of protein data with \"MUTATED_RES\" and \"POSITION\" columns.\n",
    "# This method returns a list with the correctly formatted variant (mutation-position form).\n",
    "def get_mutations_names_list(df):\n",
    "    formatted_list = []\n",
    "    expanded_abbv = []\n",
    "    for mutation, position in zip(df[\"MUTATED_RES\"], df[\"POSITION\"]):\n",
    "        split_mutations = mutation.split(\",\")\n",
    "        split_positions = position.split(\",\")\n",
    "        if \"wild-type\" in split_mutations[0].lower() or \"wild-type\" in split_positions[0].lower():\n",
    "            abbv_names = \"WT\"\n",
    "        else:  \n",
    "            for mut, pos in zip(split_mutations, split_positions):\n",
    "                three_letter_mut = Bio.PDB.Polypeptide.one_to_three(mut.upper())\n",
    "                position = str(int(pos))\n",
    "                combined_name = position + three_letter_mut\n",
    "                expanded_abbv.append(combined_name)\n",
    "                abbv_names = \", \".join(expanded_abbv)\n",
    "        expanded_abbv.clear()\n",
    "        formatted_list.append(abbv_names)\n",
    "    return(formatted_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508fb13e",
   "metadata": {},
   "source": [
    "Splits positions in intermediary \"POSITION\" column to help remove mutations with a certain position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93b6ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "#      \"df\" - protein data dataframe with \"POSITION\" column \n",
    "# This method takes the position column in the dataframe and splits it in order\n",
    "# to help remove or keep mutatations depending on their position.\n",
    "def get_positions_split(df):\n",
    "    position_list_split = []\n",
    "\n",
    "    for item in df[\"POSITION\"]:\n",
    "        item = item.split(\",\") # splits positions into list\n",
    "        int_item = [int(i) for i in item]\n",
    "        position_list_split.append(int_item)\n",
    "    \n",
    "    return position_list_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60f8f6e",
   "metadata": {},
   "source": [
    "Getting Secondary Structure assignment from STRIDE file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75a6ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters: \n",
    "#      \"stride file\" - stride file of protein\n",
    "#      \"is_sec_struc\" - list of boolean values for each secondary structure value\n",
    "#                       if it is, true, else false\n",
    "# returns list of boolean values indicating if position is secondary strcuture or not\n",
    "def get_sec_struc_boolean(stride_file):\n",
    "    is_sec_struc = []\n",
    "    sec_struc_assign = []\n",
    "\n",
    "    for line in stride_file:\n",
    "        if line.startswith('ASG'):\n",
    "            split_line = line.split();\n",
    "            sec_struc_assign.append(split_line[5])\n",
    "\n",
    "    for sec_struc in sec_struc_assign:\n",
    "        if (sec_struc =='C' or sec_struc =='T'):\n",
    "            is_sec_struc.append(False)\n",
    "        else:\n",
    "            is_sec_struc.append(True)\n",
    "            \n",
    "    return is_sec_struc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf14f381",
   "metadata": {},
   "source": [
    "Getting Dataset of Mutations within Domain in PDB File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4772de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "#      \"orig_df\" - \n",
    "#      \"start\" -\n",
    "#      \"end\" - \n",
    "#      \"not_included_list\"\n",
    "# This method does even more helpful stuff\n",
    "def get_domain_dataset(orig_df, start, end, not_included_list):\n",
    "    in_domain_list = []\n",
    "    \n",
    "    for val in orig_df[\"positions_split\"]:\n",
    "        for position in val:\n",
    "            if not_included_list.count(position - start) == 0: # if value is not in the list of values to exclude\n",
    "                if position >= start and position < end:\n",
    "                    in_domain = True\n",
    "                else:\n",
    "                    in_domain = False\n",
    "            else:\n",
    "                in_domain = False\n",
    "        in_domain_list.append(in_domain)\n",
    "    \n",
    "    orig_df['in_domain'] = in_domain_list\n",
    "    # print(in_domain_list)\n",
    "    condition = orig_df['in_domain'] == True\n",
    "    rows = orig_df.loc[condition, :]\n",
    "    \n",
    "    in_domain_df = pd.DataFrame(columns=orig_df.columns)\n",
    "    in_domain_df = in_domain_df.append(rows, ignore_index=True)\n",
    "    in_domain_df = in_domain_df.drop(['in_domain'], axis=1)\n",
    "    return in_domain_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5107976f",
   "metadata": {},
   "source": [
    "Getting Dataset of Mutations _in_ Secondary Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "105cc5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "# - orig_df: original dataframe with all mutations and \"positions_split\" column which has mutation positions in split list\n",
    "#            as ints\n",
    "# - sec_st_df: new dataframe with all rows that have mutations in the secondary structure of protein\n",
    "# - mixed_df: new dataframe with all rows that have mutations in both in and out of the secondary stucture of the protein\n",
    "# - start: (inclusive) index where the domain of the protein in PDB file starts\n",
    "# - end: (inclusive) index where the domain of the protein in PDB file ends\n",
    "def get_ss_dataset(orig_df, bool_ss_list, domain_start_index):\n",
    "    \n",
    "    has_sec_str = []\n",
    "    \n",
    "    for val in orig_df[\"positions_split\"]:\n",
    "        # list of boolean values that are true if all mutation positions in line are sec. strc.\n",
    "        all_pos_sec_struc = []\n",
    "        \n",
    "        for position in val:\n",
    "            # print(position - domain_start_index)\n",
    "            # print(str(position) + \" \" + str(domain_start_index))\n",
    "            if (bool_ss_list[position - domain_start_index] == False): # line up ss_indexes w/ position\n",
    "                all_pos_sec_struc.append(False)\n",
    "            else:\n",
    "                all_pos_sec_struc.append(True)\n",
    "        \n",
    "        # all pos sec struc should match val list\n",
    "        # if there's a value in all_pos_sec_struc that's false, append false\n",
    "        # otherwise, append true\n",
    "        # print(\"val\")\n",
    "        # print(val)\n",
    "        # print(\"bool\")\n",
    "        # print(all_pos_sec_struc)\n",
    "        if (all_pos_sec_struc.count(False) == 0):\n",
    "            has_only_sec_str = True\n",
    "        else:\n",
    "            has_only_sec_str = False\n",
    "        \n",
    "        # print(has_only_sec_str)\n",
    "        has_sec_str.append(has_only_sec_str)\n",
    "        all_pos_sec_struc.clear()\n",
    "        \n",
    "        \n",
    "    # print(len(has_sec_str)) # should match dataframe length\n",
    "    orig_df['has_sec_str'] = has_sec_str\n",
    "    \n",
    "    condition = orig_df['has_sec_str'] == True\n",
    "    rows = orig_df.loc[condition, :]\n",
    "    \n",
    "    sec_str_df = pd.DataFrame(columns=orig_df.columns)\n",
    "    sec_str_df = sec_str_df.append(rows, ignore_index=True)\n",
    "    # print(sec_str_df.head)\n",
    "    sec_str_df = sec_str_df.drop(['has_sec_str'], axis=1)\n",
    "    orig_df = orig_df.drop(['has_sec_str'], axis=1)\n",
    "    \n",
    "    return sec_str_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebcd87b",
   "metadata": {},
   "source": [
    "Getting Dataset of Mutations _not_ in Secondary Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c91576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_not_ss_dataset(orig_df, bool_ss_list, domain_start_index):\n",
    "    is_not_sec_str = []\n",
    "    \n",
    "    for val in orig_df[\"positions_split\"]:\n",
    "        \n",
    "        all_pos_sec_struc = []\n",
    "        \n",
    "        for position in val:\n",
    "            # print(position - domain_start_index)\n",
    "            # print(str(position) + \" \" + str(domain_start_index))\n",
    "            if (bool_ss_list[position - domain_start_index] == False):\n",
    "                all_pos_sec_struc.append(False)\n",
    "            else:\n",
    "                all_pos_sec_struc.append(True)\n",
    "    \n",
    "        \n",
    "        if (all_pos_sec_struc.count(True) == 0):\n",
    "            has_no_sec_str = True\n",
    "        else:\n",
    "            has_no_sec_str = False\n",
    "        \n",
    "        is_not_sec_str.append(has_no_sec_str)\n",
    "        all_pos_sec_struc.clear()\n",
    "        \n",
    "    orig_df['is_not_sec_str'] = is_not_sec_str\n",
    "     \n",
    "    condition = orig_df['is_not_sec_str'] == True\n",
    "    rows = orig_df.loc[condition, :]\n",
    "    \n",
    "    not_sec_str_df = pd.DataFrame(columns=orig_df.columns)\n",
    "    not_sec_str_df = not_sec_str_df.append(rows, ignore_index=True)\n",
    "    not_sec_str_df = not_sec_str_df.drop(['is_not_sec_str'], axis=1)\n",
    "    orig_df = orig_df.drop(['is_not_sec_str'], axis=1)\n",
    "    \n",
    "    return not_sec_str_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a73920",
   "metadata": {},
   "source": [
    "Writing formatted data to txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0047251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters:\n",
    "#      \"txt_name\" - desired name of formatted txt file for network. E.g. \"pab1\"\n",
    "#      \"protein_seq\" - string of protein sequence in 3 letter convention. E.g. ALA GLU TYR\n",
    "#      \"df\" - dataframe with cleaned protein data. Must contain \"variant\" and \"score\" \n",
    "#             columns.\n",
    "# This method cleans the protein data and formats it into a txt that can be processed by the \n",
    "# network. It also prints the name of the file out for reference.\n",
    "def write_data_file(txt_name, protein_seq, df):\n",
    "    file_name = txt_name + \".txt\"\n",
    "    path_name = \"../ML Script Data Files/\" + file_name\n",
    "    print(\"Filename: \" + file_name)\n",
    "    \n",
    "    datafile = open(path_name, \"w+\")\n",
    "    datafile.write(protein_seq + \"\\n\")\n",
    "    for index in range(len(df)-1):\n",
    "        datafile.write(df[\"variant\"].iloc[index] + \": \" + str(df[\"score\"].iloc[index]) + \"\\n\")\n",
    "    datafile.write(df[\"variant\"].iloc[len(df) - 1] + \": \" + str(df[\"score\"].iloc[len(df) - 1]))\n",
    "    datafile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d879d11f",
   "metadata": {},
   "source": [
    "Getting dataset of mutations that are in alpha helices: (H, G, I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2874018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters: \n",
    "#      \"stride file\" - stride file of protein\n",
    "#      \"is_sec_struc\" - list of boolean values for each secondary structure value\n",
    "#                       if it is, true, else false\n",
    "# returns list of boolean values indicating if position is in an alpha helix or not\n",
    "def get_alpha_boolean(stride_file):\n",
    "    # print('hi')\n",
    "    is_alpha = []\n",
    "    alpha_assign = []\n",
    "\n",
    "    for line in stride_file:\n",
    "        # print(line)\n",
    "        # print(\"why isn't this working\")\n",
    "        if line.startswith('ASG'):\n",
    "            split_line = line.split();\n",
    "            # print(split_line[5])\n",
    "            alpha_assign.append(split_line[5])\n",
    "    \n",
    "#     print(alpha_assign)\n",
    "    \n",
    "    alpha_letters = ['H','G','I']\n",
    "    for alpha in alpha_assign:\n",
    "        if (alpha_letters.count(alpha) != 0):\n",
    "            is_alpha.append(True)\n",
    "        else:\n",
    "            is_alpha.append(False)\n",
    "    \n",
    "#     print(alpha_assign)\n",
    "#     print(is_alpha)\n",
    "    \n",
    "    return is_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab006f3",
   "metadata": {},
   "source": [
    "Getting dataset of mutations that are in beta sheets: (E, B or b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "bf1c76e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beta_boolean(stride_file):\n",
    "    is_beta = []\n",
    "    beta_assign = []\n",
    "\n",
    "    for line in stride_file:\n",
    "        if line.startswith('ASG'):\n",
    "            split_line = line.split();\n",
    "            beta_assign.append(split_line[5])\n",
    "    \n",
    "    beta_letters = ['E','B','b']\n",
    "    for beta in beta_assign:\n",
    "        if (beta_letters.count(beta) != 0):\n",
    "            is_beta.append(True)\n",
    "        else:\n",
    "            is_beta.append(False)\n",
    "    \n",
    "#     print(beta_assign)\n",
    "#     print(is_beta)\n",
    "#     print(len(is_beta))\n",
    "    \n",
    "    return is_beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6458b0cf",
   "metadata": {},
   "source": [
    "Getting dataset of mutations that are turns: (T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c142c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_turns_boolean(stride_file):\n",
    "    is_turn = []\n",
    "    turn_assign = []\n",
    "\n",
    "    for line in stride_file:\n",
    "        if line.startswith('ASG'):\n",
    "            split_line = line.split();\n",
    "            turn_assign.append(split_line[5])\n",
    "\n",
    "    for turn in turn_assign:\n",
    "        if (turn == \"T\"):\n",
    "            is_turn.append(True)\n",
    "        else:\n",
    "            is_turn.append(False)\n",
    "    \n",
    "    print(turn_assign)\n",
    "    print(is_turn)\n",
    "    \n",
    "    return is_turn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f0c59b",
   "metadata": {},
   "source": [
    "Getting dataset of mutations in secondary structure **including turns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6228b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters: \n",
    "#      \"stride file\" - stride file of protein\n",
    "#      \"is_sec_struc\" - list of boolean values for each secondary structure value\n",
    "#                       if it is, true, else false\n",
    "# returns list of boolean values indicating if position is secondary strcuture or not\n",
    "def get_all_sec_struc_boolean(stride_file):\n",
    "    is_sec_struc = []\n",
    "    sec_struc_assign = []\n",
    "\n",
    "    for line in stride_file:\n",
    "        if line.startswith('ASG'):\n",
    "            split_line = line.split();\n",
    "            sec_struc_assign.append(split_line[5])\n",
    "\n",
    "    for sec_struc in sec_struc_assign:\n",
    "        if (sec_struc =='C'):\n",
    "            is_sec_struc.append(False)\n",
    "        else:\n",
    "            is_sec_struc.append(True)\n",
    "            \n",
    "    return is_sec_struc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e7dfdd",
   "metadata": {},
   "source": [
    "Matching Segments of Non Secondary Structure to Secondary Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5db1760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit number of mutations to some number\n",
    "# **use after get_domain dataset\n",
    "\n",
    "# Parameters:\n",
    "#    \"indexes\" - a boolean list indicating positions with secondary structure (True - in ss, False - not in ss)\n",
    "# This method returns a list of indexes to exclude in order to match the number of positions in secondary structure\n",
    "# and out of secondary structure\n",
    "def get_excluded_res(indexes):\n",
    "    \n",
    "    # find the groups of secondary structure\n",
    "    ss_ind = [i for i,val in enumerate(indexes) if val==True]\n",
    "    ss_ind_groups = list(find_index_range(ss_ind))\n",
    "    \n",
    "    # find the groups of non secondary structure\n",
    "    not_ss_ind = [i for i,val in enumerate(indexes) if val==False]\n",
    "    not_ss_ind_groups = list(find_index_range(not_ss_ind))\n",
    "\n",
    "    ind_to_remove = []\n",
    "    \n",
    "    num_false = indexes.count(False)\n",
    "    num_true = indexes.count(True)\n",
    "    \n",
    "    if (num_false < num_true): #is mostly ss\n",
    "        ind_to_remove = remove_indices_helper(not_ss_ind_groups, ss_ind_groups) # chunk with not_ss groups\n",
    "    elif (num_false > num_true): # NOT mostly ss\n",
    "        ind_to_remove = remove_indices_helper(ss_ind_groups, not_ss_ind_groups)\n",
    "    \n",
    "    print(\"Num True Indices: \" + str(num_true))\n",
    "    print(\"Num False Indices: \" +  str(num_false))\n",
    "    print(\"Difference: \" + str(abs(num_true - num_false)))\n",
    "    print(\"Num Indices to Remove: \" + str(len(ind_to_remove)))\n",
    "\n",
    "    \n",
    "    return ind_to_remove\n",
    "    # return list of indices to NOT include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5f62804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "#    \"chunked_list\" - list of ints/tuples representing either ss/not-ss regions that should be matched by corresponding\n",
    "#                     ss/not-ss regions\n",
    "#    \"to_chunk_list\" - list of regions representing regions with excess values that is matched to regions in chunked list\n",
    "# This method is a helper method that returns a list of indices to remove in order to match the groups of secondary \n",
    "# structure and non-secondary structure\n",
    "def remove_indices_helper(chunked_list, to_chunk_list):\n",
    "    remainder = []\n",
    "    count_to_remove = 0\n",
    "    \n",
    "#     print(\"chunked len: \" + str(len(chunked_list)))\n",
    "\n",
    "#     print(\"to_chunk len: \" + str(len(to_chunk_list)))\n",
    "\n",
    "    for chunk, to_chunk in zip(chunked_list, to_chunk_list): # zip goes through the smallest of the lists\n",
    "        \n",
    "        chunk_exp_list = expand_list(chunk)   \n",
    "        to_chunk_exp_list = expand_list(to_chunk)\n",
    "        \n",
    "        if (len(chunk_exp_list) < len(to_chunk_exp_list)):\n",
    "            remainder.append(to_chunk_exp_list[len(chunk_exp_list):]) # will add indices to remove to remainder list\n",
    "        elif (len(chunk_exp_list) > len(to_chunk_exp_list)): \n",
    "            count_to_remove =  count_to_remove + (len(chunk_exp_list) - len(to_chunk_exp_list))\n",
    "            \n",
    "    if (len(chunked_list) > len(to_chunk_list)): #idk if this works\n",
    "         count_to_remove =  count_to_remove + len(expand_list(chunked_list[-1]))\n",
    "    \n",
    "    \n",
    "    remainder = list(itertools.chain.from_iterable(remainder))\n",
    "    if (len(to_chunk_list) > len(chunked_list)):\n",
    "        remainder_copy = remainder.copy()\n",
    "        print(\"remainder before: \" + str(len(remainder_copy)))\n",
    "        remainder.extend(expand_list(to_chunk_list[-1]))\n",
    "        print(\"remainder after: \" + str(len(remainder)))\n",
    "    \n",
    "    \n",
    "    remainder = delete_random_elems(remainder, count_to_remove)\n",
    "    \n",
    "    return remainder         \n",
    "    # returns indices of values that are not to be included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18f7d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "#    \"val\" - integer or tuple to be cast as a list\n",
    "# This method is a helper method that either casts a single integer as a list or expands the range of a tuple\n",
    "# (inclusive, inclusive)\n",
    "def expand_list(val):\n",
    "    val_list = []\n",
    "    if isinstance(val, int):\n",
    "        val_list.append(val)\n",
    "    else:\n",
    "        val_list = list(range(val[0], val[-1]))\n",
    "        val_list.append(val[-1])\n",
    "    \n",
    "    return val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "071c6b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.codegrepper.com/code-examples/python/python+remove+n+random+elements+from+a+list\n",
    "# Parameters:\n",
    "#    \"input_list\" - list of values\n",
    "#    \"n\" - number of random elements to delete from the list\n",
    "# This method is a helper method that removes a given number of random elements from a list\n",
    "def delete_random_elems(input_list, n):\n",
    "    to_delete = set(random.sample(range(len(input_list)), n))\n",
    "    return [x for i,x in enumerate(input_list) if not i in to_delete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "209085f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining the ranges of false values \n",
    "# https://stackoverflow.com/questions/2154249/identify-groups-of-continuous-numbers-in-a-list\n",
    "\n",
    "# Parameters:\n",
    "#    \"int_indexes\" - list containing a location values for a protein\n",
    "# This method is a helper method which determines consecutive values in list in order to group regions of \n",
    "# secondary structure and non-secondary structure. It returns a list with integers and tuples (inclusive, inclusive)\n",
    "# representing where a given type of region starts and stops in the protein.\n",
    "def find_index_range(int_indexes):\n",
    "    for segment in mit.consecutive_groups(int_indexes):\n",
    "        segment = list(segment)\n",
    "        if len(segment) == 1:\n",
    "            yield segment[0] # yield is like return, except that it\n",
    "                             # retains state to enable function to resume where\n",
    "                             # it left off (sequenve of vals vs. 1)\n",
    "        else:\n",
    "            yield segment[0], segment[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3192b31a",
   "metadata": {},
   "source": [
    "## Pab1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d91e646",
   "metadata": {},
   "source": [
    "Formatting Pab1 Data to Split Dataset into Values in Secondary Structure and NOT in Secondary Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9d6c77b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE - stride files + jupyter notebook in winter dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fbb4029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../PDB and STRIDE Files/\" + 'pab1_stride.txt'\n",
    "pab1_stride_file = open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a106180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pab1_ss_indexes = get_sec_struc_boolean(pab1_stride_file) # boolean list of secondary structure assignements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "de4fc2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "[False, True, True, True, True, True, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, False, False, True, True, True, True, True, True, False]\n"
     ]
    }
   ],
   "source": [
    "print(len(pab1_ss_indexes)) # <- domain is 75 AA long\n",
    "print(pab1_ss_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "662e0506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "# number of mutations not in secondary structure\n",
    "count_false = pab1_ss_indexes.count(False)\n",
    "print(count_false)\n",
    "count_true = pab1_ss_indexes.count(True)\n",
    "print(count_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc3d41b",
   "metadata": {},
   "source": [
    "Getting Alpha Helices and Beta Sheets Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19403677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pab1_alpha_indices = get_alpha_boolean(pab1_stride_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7632a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # alpha helices \n",
    "# # pab1_alpha_indices = get_alpha_boolean(pab1_stride_file)\n",
    "# is_alpha = pab1_alpha_indices.count(True)\n",
    "# not_alpha = pab1_alpha_indices.count(False)\n",
    "# print(is_alpha)\n",
    "# print(not_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36d2c468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_excluded_res(pab1_alpha_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2a35dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # beta sheets\n",
    "# pab1_beta_indices = get_beta_boolean(pab1_stride_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "734e064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_beta = pab1_beta_indices.count(True)\n",
    "# not_beta = pab1_beta_indices.count(False)\n",
    "# print(is_beta)\n",
    "# print(not_beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7315ca",
   "metadata": {},
   "source": [
    "- Pab1 has 23 Mutations not in Secondary Structure, so limiting Number of Secondary Structure Mutations to 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e32610b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # index of 23rd true\n",
    "\n",
    "# highest_true_index = [i for i, n in enumerate(pab1_ss_indexes) if n == True][23]\n",
    "# print(highest_true_index)\n",
    "# # need list of indices in secondary structure past this index in order to remove them from dataset\n",
    "\n",
    "# true_indices = [i for i,val in enumerate(pab1_ss_indexes) if val==True]\n",
    "# print(true_indices)\n",
    "\n",
    "# not_included_pab1 = [i for i in true_indices if i > 39]\n",
    "# print(not_included_pab1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "11f4b5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num True Indices: 52\n",
      "Num False Indices: 23\n",
      "Difference: 29\n",
      "Num Indices to Remove: 29\n"
     ]
    }
   ],
   "source": [
    "# changing not included to matching secondary structure + random elements\n",
    "\n",
    "not_included_pab1 = get_excluded_res(pab1_ss_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0a8e55",
   "metadata": {},
   "source": [
    "Limiting Number of Secondary Structure Mutations and Number in alpha helices versus out of it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f30d923",
   "metadata": {},
   "source": [
    "### Sorting Pab1 Mutations Into 2 Datasets (w & w/o mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "de5b607e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40852\n",
      "Index(['variant', 'num_mutations', 'score'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# importing pab1 data from Gelman et al.\n",
    "pab1_df1 = pd.read_csv(\"../Raw Data/pab1.tsv.txt\", sep=\"\\t\")\n",
    "pab1_df = pab1_df1.dropna()\n",
    "print(len(pab1_df))\n",
    "print(pab1_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "92bdfb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40852\n",
      "37710\n"
     ]
    }
   ],
   "source": [
    "# rounding score column to 2 decimal points\n",
    "pab1_df[\"score\"] = pab1_df[\"score\"].round(6)\n",
    "print(len(pab1_df))\n",
    "\n",
    "# remove values with wildcard star thing cause idk what it means\n",
    "pab1_df = pab1_df[pab1_df[\"variant\"].str.contains(\"\\*\") == False]\n",
    "\n",
    "# pab1_df = pab1_df.head(37600)\n",
    "print(len(pab1_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "82cef935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split variant name into wild-type, position, and mutation type\n",
    "pab1_mut = pab1_df[\"variant\"].str.split(\",\")\n",
    "pab1_df[\"WILD_TYPE_RES\"] = get_wild_type(pab1_mut)\n",
    "pab1_df[\"MUTATED_RES\"] = get_mutation_type(pab1_mut)\n",
    "pab1_df[\"POSITION\"] = get_position(pab1_mut)\n",
    "pab1_df[\"positions_split\"] = get_positions_split(pab1_df)\n",
    "# pab1_df[\"positions_split\"] = positions_split_subtracted\n",
    "\n",
    "positions_split_subtracted = []\n",
    "for pos_list in pab1_df[\"positions_split\"]:\n",
    "    pos_list = [x - 126 for x in pos_list]\n",
    "    positions_split_subtracted.append(pos_list)  \n",
    "\n",
    "pab1_df[\"positions_split\"] = positions_split_subtracted    \n",
    "    \n",
    "new_positions = []\n",
    "pos_string = \"\"\n",
    "for pos_list in pab1_df[\"positions_split\"]:\n",
    "    pos_string = \",\".join(map(str, pos_list))\n",
    "    # print(pos_string)\n",
    "    new_positions.append(pos_string)\n",
    "    pos_string = \"\"\n",
    "# print(len(new_positions))\n",
    "# print(len(pab1_df[\"POSITION\"]))\n",
    "\n",
    "pab1_df[\"POSITION\"] = new_positions # changes positions into new adjusted values (0 index)\n",
    "pab1_df[\"variant\"] = get_mutations_names_list(pab1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c0629c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [0]\n",
      "1    [0]\n",
      "2    [0]\n",
      "3    [0]\n",
      "4    [0]\n",
      "5    [0]\n",
      "6    [0]\n",
      "7    [0]\n",
      "8    [0]\n",
      "9    [1]\n",
      "Name: positions_split, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(pab1_df[\"positions_split\"].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5d4f6b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40842    25,38\n",
      "40843    38,43\n",
      "40844    33,38\n",
      "40845    29,38\n",
      "40846    38,40\n",
      "40847    38,49\n",
      "40848    38,48\n",
      "40849    38,48\n",
      "40850    38,47\n",
      "40851    35,38\n",
      "Name: POSITION, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(pab1_df[\"POSITION\"].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "96f5364b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['variant', 'num_mutations', 'score', 'WILD_TYPE_RES', 'MUTATED_RES',\n",
      "       'POSITION', 'positions_split'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print(pab1_df.head)\n",
    "print(pab1_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1418269c",
   "metadata": {},
   "source": [
    "Moving rows with Secondary Structure position into a different dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2e529c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [0]\n",
      "1     [0]\n",
      "2     [0]\n",
      "3     [0]\n",
      "4     [0]\n",
      "5     [0]\n",
      "6     [0]\n",
      "7     [0]\n",
      "8     [0]\n",
      "9     [1]\n",
      "10    [1]\n",
      "11    [1]\n",
      "12    [1]\n",
      "13    [1]\n",
      "14    [1]\n",
      "15    [1]\n",
      "16    [1]\n",
      "17    [1]\n",
      "18    [1]\n",
      "19    [1]\n",
      "Name: positions_split, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pab1_df[\"positions_split\"] = get_positions_split(pab1_df)\n",
    "print(pab1_df[\"positions_split\"].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7134aba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pab_in_domain_df = get_domain_dataset(pab1_df, 0, 75, not_included_pab1) # now that positions split has changed, domain should not matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "49bbf2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24507\n"
     ]
    }
   ],
   "source": [
    "print(len(pab_in_domain_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "40275ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7501\n"
     ]
    }
   ],
   "source": [
    "pab1_ss_df = get_ss_dataset(pab_in_domain_df, pab1_ss_indexes, 0)\n",
    "print(len(pab1_ss_df))\n",
    "# 5828 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9572202c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3927\n"
     ]
    }
   ],
   "source": [
    "pab1_not_ss_df = get_not_ss_dataset(pab_in_domain_df, pab1_ss_indexes, 0)\n",
    "print(len(pab1_not_ss_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646d4fc6",
   "metadata": {},
   "source": [
    "1000 Value Test dataset in SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f9b26348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find random test set, concat orig df and new test df, remove dups\n",
    "# DO NOT RERUN THIS BLOCK\n",
    "pab1_ss_1000_test_df = pab1_ss_df.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "978b8e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8501\n",
      "6501\n"
     ]
    }
   ],
   "source": [
    "pab1_temp_df = pd.concat([pab1_ss_1000_test_df, pab1_ss_df])\n",
    "print(len(pab1_temp_df))\n",
    "pab1_ss_df = pab1_temp_df[~pab1_temp_df.index.duplicated(keep=False)]\n",
    "print(len(pab1_ss_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9206ad5",
   "metadata": {},
   "source": [
    "1000 Value Test dataset not in SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ccef9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find random test set, concat orig df and new test df, remove dups\n",
    "# DO NOT RERUN THIS BLOCK\n",
    "pab1_not_ss_1000_test_df = pab1_not_ss_df.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fd5e0c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4927\n",
      "2927\n"
     ]
    }
   ],
   "source": [
    "pab1_temp_df = pd.concat([pab1_not_ss_1000_test_df, pab1_not_ss_df])\n",
    "print(len(pab1_temp_df))\n",
    "pab1_not_ss_df = pab1_temp_df[~pab1_temp_df.index.duplicated(keep=False)]\n",
    "print(len(pab1_not_ss_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd002f2a",
   "metadata": {},
   "source": [
    "Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6b7b5975",
   "metadata": {},
   "outputs": [],
   "source": [
    "pab1_ss_df_500_t1 = pab1_ss_df.sample(n=500)\n",
    "pab1_ss_df_500_t2 = pab1_ss_df.sample(n=500)\n",
    "pab1_ss_df_500_t3 = pab1_ss_df.sample(n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b18f1596",
   "metadata": {},
   "outputs": [],
   "source": [
    "pab1_ss_df_1000_t1 = pab1_ss_df.sample(n=1000)\n",
    "pab1_ss_df_1000_t2 = pab1_ss_df.sample(n=1000)\n",
    "pab1_ss_df_1000_t3 = pab1_ss_df.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae7e1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pab1_ss_df_2000_t1 = pab1_ss_df.sample(n=2000)\n",
    "pab1_ss_df_2000_t2 = pab1_ss_df.sample(n=2000)\n",
    "pab1_ss_df_2000_t3 = pab1_ss_df.sample(n=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "613a1296",
   "metadata": {},
   "outputs": [],
   "source": [
    "pab1_not_ss_df_500_t1 = pab1_not_ss_df.sample(n=500)\n",
    "pab1_not_ss_df_500_t2 = pab1_not_ss_df.sample(n=500)\n",
    "pab1_not_ss_df_500_t3 = pab1_not_ss_df.sample(n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "880ad0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pab1_not_ss_df_1000_t1 = pab1_not_ss_df.sample(n=1000)\n",
    "pab1_not_ss_df_1000_t2 = pab1_not_ss_df.sample(n=1000)\n",
    "pab1_not_ss_df_1000_t3 = pab1_not_ss_df.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f1ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "pab1_not_ss_df_2000_t1 = pab1_not_ss_df.sample(n=2000)\n",
    "pab1_not_ss_df_2000_t2 = pab1_not_ss_df.sample(n=2000)\n",
    "pab1_not_ss_df_2000_t3 = pab1_not_ss_df.sample(n=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed227be",
   "metadata": {},
   "source": [
    "### Putting Pab1 Datasets into Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a561f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein_seq_pab1 = get_protein_seq(\"P04147\")\n",
    "# protein_seq_pab1_split = protein_seq_pab1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "133f655f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MET ALA ASP ILE THR ASP LYS THR ALA GLU GLN LEU GLU ASN LEU ASN ILE GLN ASP ASP GLN LYS GLN ALA ALA THR GLY SER GLU SER GLN SER VAL GLU ASN SER SER ALA SER LEU TYR VAL GLY ASP LEU GLU PRO SER VAL SER GLU ALA HIS LEU TYR ASP ILE PHE SER PRO ILE GLY SER VAL SER SER ILE ARG VAL CYS ARG ASP ALA ILE THR LYS THR SER LEU GLY TYR ALA TYR VAL ASN PHE ASN ASP HIS GLU ALA GLY ARG LYS ALA ILE GLU GLN LEU ASN TYR THR PRO ILE LYS GLY ARG LEU CYS ARG ILE MET TRP SER GLN ARG ASP PRO SER LEU ARG LYS LYS GLY SER GLY ASN ILE PHE ILE LYS ASN LEU HIS PRO ASP ILE ASP ASN LYS ALA LEU TYR ASP THR PHE SER VAL PHE GLY ASP ILE LEU SER SER LYS ILE ALA THR ASP GLU ASN GLY LYS SER LYS GLY PHE GLY PHE VAL HIS PHE GLU GLU GLU GLY ALA ALA LYS GLU ALA ILE ASP ALA LEU ASN GLY MET LEU LEU ASN GLY GLN GLU ILE TYR VAL ALA PRO HIS LEU SER ARG LYS GLU ARG ASP SER GLN LEU GLU GLU THR LYS ALA HIS TYR THR ASN LEU TYR VAL LYS ASN ILE ASN SER GLU THR THR ASP GLU GLN PHE GLN GLU LEU PHE ALA LYS PHE GLY PRO ILE VAL SER ALA SER LEU GLU LYS ASP ALA ASP GLY LYS LEU LYS GLY PHE GLY PHE VAL ASN TYR GLU LYS HIS GLU ASP ALA VAL LYS ALA VAL GLU ALA LEU ASN ASP SER GLU LEU ASN GLY GLU LYS LEU TYR VAL GLY ARG ALA GLN LYS LYS ASN GLU ARG MET HIS VAL LEU LYS LYS GLN TYR GLU ALA TYR ARG LEU GLU LYS MET ALA LYS TYR GLN GLY VAL ASN LEU PHE VAL LYS ASN LEU ASP ASP SER VAL ASP ASP GLU LYS LEU GLU GLU GLU PHE ALA PRO TYR GLY THR ILE THR SER ALA LYS VAL MET ARG THR GLU ASN GLY LYS SER LYS GLY PHE GLY PHE VAL CYS PHE SER THR PRO GLU GLU ALA THR LYS ALA ILE THR GLU LYS ASN GLN GLN ILE VAL ALA GLY LYS PRO LEU TYR VAL ALA ILE ALA GLN ARG LYS ASP VAL ARG ARG SER GLN LEU ALA GLN GLN ILE GLN ALA ARG ASN GLN MET ARG TYR GLN GLN ALA THR ALA ALA ALA ALA ALA ALA ALA ALA GLY MET PRO GLY GLN PHE MET PRO PRO MET PHE TYR GLY VAL MET PRO PRO ARG GLY VAL PRO PHE ASN GLY PRO ASN PRO GLN GLN MET ASN PRO MET GLY GLY MET PRO LYS ASN GLY MET PRO PRO GLN PHE ARG ASN GLY PRO VAL TYR GLY VAL PRO PRO GLN GLY GLY PHE PRO ARG ASN ALA ASN ASP ASN ASN GLN PHE TYR GLN GLN LYS GLN ARG GLN ALA LEU GLY GLU GLN LEU TYR LYS LYS VAL SER ALA LYS THR SER ASN GLU GLU ALA ALA GLY LYS ILE THR GLY MET ILE LEU ASP LEU PRO PRO GLN GLU VAL PHE PRO LEU LEU GLU SER ASP GLU LEU PHE GLU GLN HIS TYR LYS GLU ALA SER ALA ALA TYR GLU SER PHE LYS LYS GLU GLN GLU GLN GLN THR GLU GLN ALA\n",
      "ASN\n"
     ]
    }
   ],
   "source": [
    "# print(protein_seq_pab1)\n",
    "# print(protein_seq_pab1_split[126])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b09da365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLY ASN ILE PHE ILE LYS ASN LEU HIS PRO ASP ILE ASP ASN LYS ALA LEU TYR ASP THR PHE SER VAL PHE GLY ASP ILE LEU SER SER LYS ILE ALA THR ASP GLU ASN GLY LYS SER LYS GLY PHE GLY PHE VAL HIS PHE GLU GLU GLU GLY ALA ALA LYS GLU ALA ILE ASP ALA LEU ASN GLY MET LEU LEU ASN GLY GLN GLU ILE TYR VAL ALA PRO\n"
     ]
    }
   ],
   "source": [
    "string_seq_pab1 = \"GNIFIKNLHPDIDNKALYDTFSVFGDILSSKIATDENGKSKGFGFVHFEEEGAAKEAIDALNGMLLNGQEIYVAP\"\n",
    "protein_seq_pab1 = get_expanded_seq(string_seq_pab1)\n",
    "print(protein_seq_pab1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "149349f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE - 3000 vals is actually 2880"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "60d6556d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "pab1_ss_500_df_t1 = pd.concat([pab1_ss_df_500_t1, pab1_ss_1000_test_df])\n",
    "pab1_not_ss_500_df_t1 = pd.concat([pab1_not_ss_df_500_t1, pab1_not_ss_1000_test_df])\n",
    "pab1_ss_500_df_t2 = pd.concat([pab1_ss_df_500_t2, pab1_ss_1000_test_df])\n",
    "pab1_not_ss_500_df_t2 = pd.concat([pab1_not_ss_df_500_t2, pab1_not_ss_1000_test_df])\n",
    "pab1_ss_500_df_t3 = pd.concat([pab1_ss_df_500_t3, pab1_ss_1000_test_df])\n",
    "# print(len(pab1_ss_500_df_t3))\n",
    "pab1_not_ss_500_df_t3 = pd.concat([pab1_not_ss_df_500_t3, pab1_not_ss_1000_test_df])\n",
    "# print(len(pab1_not_ss_500_df_t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d3de6c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pab1_ss_1000_df_t1 = pd.concat([pab1_ss_df_1000_t1, pab1_ss_1000_test_df])\n",
    "pab1_not_ss_1000_df_t1 = pd.concat([pab1_not_ss_df_1000_t1, pab1_not_ss_1000_test_df])\n",
    "pab1_ss_1000_df_t2 = pd.concat([pab1_ss_df_1000_t2, pab1_ss_1000_test_df])\n",
    "pab1_not_ss_1000_df_t2 = pd.concat([pab1_not_ss_df_1000_t2, pab1_not_ss_1000_test_df])\n",
    "pab1_ss_1000_df_t3 = pd.concat([pab1_ss_df_1000_t3, pab1_ss_1000_test_df])\n",
    "pab1_not_ss_1000_df_t3 = pd.concat([pab1_not_ss_df_1000_t3, pab1_not_ss_1000_test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7b880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pab1_ss_2000_df_t1 = pd.concat([pab1_ss_df_2000_t1, pab1_ss_1000_test_df])\n",
    "pab1_not_ss_2000_df_t1 = pd.concat([pab1_not_ss_df_2000_t1, pab1_not_ss_1000_test_df])\n",
    "pab1_ss_2000_df_t2 = pd.concat([pab1_ss_df_2000_t2, pab1_ss_1000_test_df])\n",
    "pab1_not_ss_2000_df_t2 = pd.concat([pab1_not_ss_df_2000_t2, pab1_not_ss_1000_test_df])\n",
    "pab1_ss_2000_df_t3 = pd.concat([pab1_ss_df_2000_t3, pab1_ss_1000_test_df])\n",
    "# print(len(pab1_ss_2000_df_t3))\n",
    "pab1_not_ss_2000_df_t3 = pd.concat([pab1_not_ss_df_2000_t3, pab1_not_ss_1000_test_df])\n",
    "# print(len(pab1_not_ss_2000_df_t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3aa2bc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: pab1_MLformat_ss_500_train_1000_test_t1.txt\n",
      "Filename: pab1_MLformat_not_ss_500_train_1000_test_t1.txt\n"
     ]
    }
   ],
   "source": [
    "# write data to formatted txt file\n",
    "\n",
    "write_data_file(\"pab1_MLformat_ss_500_train_1000_test_t1\", protein_seq_pab1, pab1_ss_500_df_t1)\n",
    "write_data_file(\"pab1_MLformat_not_ss_500_train_1000_test_t1\", protein_seq_pab1, pab1_not_ss_500_df_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feea517",
   "metadata": {},
   "source": [
    "## Bgl3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f3127",
   "metadata": {},
   "source": [
    "Formatting Bgl3 Data to Split Dataset into Values in Secondary Structure and NOT in Secondary Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0cdf7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../PDB and STRIDE Files/\" + 'bgl3_stride.txt'\n",
    "bgl3_stride_file = open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "09af26c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgl3_ss_indexes = get_sec_struc_boolean(bgl3_stride_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2f0e47d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, True, True, True, True, True, False, False, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, False, False, True, True, True, True, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, False, False, False, False, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, True, True, False, False, False, True, True, True, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, False, False, False, False, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, True, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, False, True, True, True, False, False, False, True, True, True, True, True, False, False, False, True, False, True, True, True, True, True, True, False, False, False, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "print(len(bgl3_ss_indexes))\n",
    "print(bgl3_ss_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb70c4bb",
   "metadata": {},
   "source": [
    "Getting Alpha and Beta Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ead1006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bgl3_alpha_indices = get_alpha_boolean(bgl3_stride_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4c700c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bgl3_beta_indices = get_beta_boolean(bgl3_stride_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f82c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_alpha_bgl3 = bgl3_alpha_indices.count(True)\n",
    "# not_alpha_bgl3 = bgl3_alpha_indices.count(False)\n",
    "# print(is_alpha_bgl3)\n",
    "# print(not_alpha_bgl3) # diff of 115\n",
    "\n",
    "# is_beta_bgl3 = bgl3_beta_indices.count(True)\n",
    "# not_beta_bgl3 = bgl3_beta_indices.count(False)\n",
    "# print(is_beta_bgl3)\n",
    "# # print(not_beta_bgl3) # diff of 343"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2531cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get residues to exlude\n",
    "\n",
    "# not_included_alpha_bgl3 = get_excluded_res(bgl3_alpha_indices)\n",
    "# not_included_beta_bgl3 = get_excluded_res(bgl3_beta_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3983dd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229\n",
      "272\n"
     ]
    }
   ],
   "source": [
    "# number of mutations in secondary structure (True), and not in secondary structure (False)\n",
    "count_false = bgl3_ss_indexes.count(False)\n",
    "print(count_false)\n",
    "\n",
    "count_true = bgl3_ss_indexes.count(True)\n",
    "print(count_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e933d060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # index of 416 true\n",
    "\n",
    "# highest_true_index = [i for i, n in enumerate(bgl3_ss_indexes) if n == True][229]\n",
    "# print(highest_true_index)\n",
    "# # need list of indices past this index\n",
    "\n",
    "# true_indices = [i for i,val in enumerate(bgl3_ss_indexes) if val==True]\n",
    "# # print(true_indices)\n",
    "\n",
    "# not_included_bgl3 = [i for i in true_indices if i > highest_true_index]\n",
    "# # print(not_included_bgl3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "98ee043b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num True Indices: 272\n",
      "Num False Indices: 229\n",
      "Difference: 43\n",
      "Num Indices to Remove: 43\n"
     ]
    }
   ],
   "source": [
    "# changing not included to matching secondary structure + random elements\n",
    "not_included_bgl3 = get_excluded_res(bgl3_ss_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b4fd710b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26653\n",
      "Index(['variant', 'num_mutations', 'inp', 'sel', 'score'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# importing bgl3 data from Gelman et al.\n",
    "bgl3_df1 = pd.read_csv(\"../Raw Data/bgl3.tsv.txt\", sep=\"\\t\")\n",
    "bgl3_df = bgl3_df1.dropna()\n",
    "print(len(bgl3_df))\n",
    "print(bgl3_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4bb31c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26653\n",
      "25737\n"
     ]
    }
   ],
   "source": [
    "# rounding score column to 6 decimal points\n",
    "bgl3_df[\"score\"] = bgl3_df[\"score\"].round(6)\n",
    "print(len(bgl3_df))\n",
    "\n",
    "# remove values with wildcard star\n",
    "bgl3_df = bgl3_df[bgl3_df[\"variant\"].str.contains(\"\\*\") == False]\n",
    "# bgl3_df = bgl3_df.head(25600)\n",
    "print(len(bgl3_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d48be577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bgl3 protein sequence\n",
    "string_seq = \"MVPAAQQTAMAPDAALTFPEGFLWGSATASYQIEGAAAEDGRTPSIWDTYARTPGRVRNGDTGDVATDHYHRWREDVALMAELGLGAYRFSLAWPRIQPTGRGPALQKGLDFYRRLADELLAKGIQPVATLYHWDLPQELENAGGWPERATAERFAEYAAIAADALGDRVKTWTTLNEPWCSAFLGYGSGVHAPGRTDPVAALRAAHHLNLGHGLAVQALRDRLPADAQCSVTLNIHHVRPLTDSDADADAVRRIDALANRVFTGPMLQGAYPEDLVKDTAGLTDWSFVRDGDLRLAHQKLDFLGVNYYSPTLVSEADGSGTHNSDGHGRSAHSPWPGADRVAFHQPPGETTAMGWAVDPSGLYELLRRLSSDFPALPLVITENGAAFHDYADPEGNVNDPERIAYVRDHLAAVHRAIKDGSDVRGYFLWSLLDNFEWAHGYSKRFGAVYVDYPTGTRIPKASARWYAEVARTGVLPTAGDPNSSSVDKLAAALEHHHHHH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "712c0b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n"
     ]
    }
   ],
   "source": [
    "print(len(string_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ebf68fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MET VAL PRO ALA ALA GLN GLN THR ALA MET ALA PRO ASP ALA ALA LEU THR PHE PRO GLU GLY PHE LEU TRP GLY SER ALA THR ALA SER TYR GLN ILE GLU GLY ALA ALA ALA GLU ASP GLY ARG THR PRO SER ILE TRP ASP THR TYR ALA ARG THR PRO GLY ARG VAL ARG ASN GLY ASP THR GLY ASP VAL ALA THR ASP HIS TYR HIS ARG TRP ARG GLU ASP VAL ALA LEU MET ALA GLU LEU GLY LEU GLY ALA TYR ARG PHE SER LEU ALA TRP PRO ARG ILE GLN PRO THR GLY ARG GLY PRO ALA LEU GLN LYS GLY LEU ASP PHE TYR ARG ARG LEU ALA ASP GLU LEU LEU ALA LYS GLY ILE GLN PRO VAL ALA THR LEU TYR HIS TRP ASP LEU PRO GLN GLU LEU GLU ASN ALA GLY GLY TRP PRO GLU ARG ALA THR ALA GLU ARG PHE ALA GLU TYR ALA ALA ILE ALA ALA ASP ALA LEU GLY ASP ARG VAL LYS THR TRP THR THR LEU ASN GLU PRO TRP CYS SER ALA PHE LEU GLY TYR GLY SER GLY VAL HIS ALA PRO GLY ARG THR ASP PRO VAL ALA ALA LEU ARG ALA ALA HIS HIS LEU ASN LEU GLY HIS GLY LEU ALA VAL GLN ALA LEU ARG ASP ARG LEU PRO ALA ASP ALA GLN CYS SER VAL THR LEU ASN ILE HIS HIS VAL ARG PRO LEU THR ASP SER ASP ALA ASP ALA ASP ALA VAL ARG ARG ILE ASP ALA LEU ALA ASN ARG VAL PHE THR GLY PRO MET LEU GLN GLY ALA TYR PRO GLU ASP LEU VAL LYS ASP THR ALA GLY LEU THR ASP TRP SER PHE VAL ARG ASP GLY ASP LEU ARG LEU ALA HIS GLN LYS LEU ASP PHE LEU GLY VAL ASN TYR TYR SER PRO THR LEU VAL SER GLU ALA ASP GLY SER GLY THR HIS ASN SER ASP GLY HIS GLY ARG SER ALA HIS SER PRO TRP PRO GLY ALA ASP ARG VAL ALA PHE HIS GLN PRO PRO GLY GLU THR THR ALA MET GLY TRP ALA VAL ASP PRO SER GLY LEU TYR GLU LEU LEU ARG ARG LEU SER SER ASP PHE PRO ALA LEU PRO LEU VAL ILE THR GLU ASN GLY ALA ALA PHE HIS ASP TYR ALA ASP PRO GLU GLY ASN VAL ASN ASP PRO GLU ARG ILE ALA TYR VAL ARG ASP HIS LEU ALA ALA VAL HIS ARG ALA ILE LYS ASP GLY SER ASP VAL ARG GLY TYR PHE LEU TRP SER LEU LEU ASP ASN PHE GLU TRP ALA HIS GLY TYR SER LYS ARG PHE GLY ALA VAL TYR VAL ASP TYR PRO THR GLY THR ARG ILE PRO LYS ALA SER ALA ARG TRP TYR ALA GLU VAL ALA ARG THR GLY VAL LEU PRO THR ALA GLY ASP PRO ASN SER SER SER VAL ASP LYS LEU ALA ALA ALA LEU GLU HIS HIS HIS HIS HIS HIS\n"
     ]
    }
   ],
   "source": [
    "protein_seq_bgl3 = get_expanded_seq(string_seq)\n",
    "print(protein_seq_bgl3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97b4d710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n"
     ]
    }
   ],
   "source": [
    "split = protein_seq_bgl3.split()\n",
    "print(len(split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "26360a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split variant name into wild-type, position, and mutation type\n",
    "bgl3_mut = bgl3_df[\"variant\"].str.split(\",\")\n",
    "bgl3_df[\"WILD_TYPE_RES\"] = get_wild_type(bgl3_mut)\n",
    "bgl3_df[\"MUTATED_RES\"] = get_mutation_type(bgl3_mut)\n",
    "bgl3_df[\"POSITION\"] = get_position(bgl3_mut)\n",
    "bgl3_df[\"variant\"] = get_mutations_names_list(bgl3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0863038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgl3_df[\"positions_split\"] = get_positions_split(bgl3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59e89a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [104]\n",
      "1    [104, 142]\n",
      "2    [104, 152]\n",
      "3    [104, 170]\n",
      "4         [104]\n",
      "Name: positions_split, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(bgl3_df[\"positions_split\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0cfb487a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          variant  num_mutations   inp    sel     score WILD_TYPE_RES  \\\n",
      "0          104GLU              1  90.0  248.0 -0.339828             A   \n",
      "1  104GLU, 142GLU              2   0.0    5.0  1.047974           A,A   \n",
      "2  104GLU, 152VAL              2   1.0    9.0  0.495906           A,E   \n",
      "3  104GLU, 170ARG              2   0.0    7.0  1.358129           A,K   \n",
      "4          104GLY              1  35.0   90.0 -0.414104             A   \n",
      "\n",
      "  MUTATED_RES POSITION positions_split  in_domain  \n",
      "0           E      104           [104]       True  \n",
      "1         E,E  104,142      [104, 142]       True  \n",
      "2         E,V  104,152      [104, 152]       True  \n",
      "3         E,R  104,170      [104, 170]       True  \n",
      "4           G      104           [104]       True  \n"
     ]
    }
   ],
   "source": [
    "print(bgl3_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2610e6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23768\n"
     ]
    }
   ],
   "source": [
    "bgl3_in_domain_df = get_domain_dataset(bgl3_df, 0, 550, not_included_bgl3) # ending is larger than sequence length bc. all mutations inside\n",
    "print(len(bgl3_in_domain_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d29a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "aa0e89c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18781\n"
     ]
    }
   ],
   "source": [
    "# bgl3_in_domain_alpha_df = get_domain_dataset(bgl3_df, 0, 550, not_included_alpha_bgl3)\n",
    "# print(len(bgl3_in_domain_alpha_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "491e2e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6915\n"
     ]
    }
   ],
   "source": [
    "# bgl3_in_domain_beta_df = get_domain_dataset(bgl3_df, 0, 550, not_included_beta_bgl3)\n",
    "# print(len(bgl3_in_domain_beta_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a043905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bgl3_alpha_df = get_ss_dataset(bgl3_in_domain_alpha_df, bgl3_alpha_indices, 0)\n",
    "# print(len(bgl3_alpha_df))\n",
    "# bgl3_alpha_df_2880 = bgl3_alpha_df.sample(n=2880)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "459ec3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bgl3_beta_df = get_ss_dataset(bgl3_in_domain_beta_df, bgl3_beta_indices, 0)\n",
    "# print(len(bgl3_beta_df))\n",
    "# bgl3_beta_df_2880 = bgl3_beta_df.sample(n=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "1f7e99bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5979\n"
     ]
    }
   ],
   "source": [
    "# bgl3_not_alpha_df = get_not_ss_dataset(bgl3_in_domain_alpha_df, bgl3_alpha_indices, 0)\n",
    "# print(len(bgl3_not_alpha_df))\n",
    "# bgl3_not_alpha_df_2880 = bgl3_not_alpha_df.sample(n=2880)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f99d15c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              variant num_mutations    inp    sel     score WILD_TYPE_RES  \\\n",
      "0     116THR, 128THR             2    1.0   30.0  1.662341           A,A   \n",
      "1     116THR, 118VAL             2    1.0    6.0  0.116416           A,E   \n",
      "2     116THR, 122GLU             2    0.0    5.0  1.047974           A,K   \n",
      "3     116THR, 125PRO             2    1.0    8.0  0.384680           A,Q   \n",
      "4     116THR, 137ARG             2    0.0    9.0  1.594518           A,Q   \n",
      "...              ...           ...    ...    ...       ...           ...   \n",
      "6734   87PHE, 129ALA             2    0.0    8.0  1.483292           Y,T   \n",
      "6735           87HIS             1  576.0  383.0 -1.757557             Y   \n",
      "6736           87ASN             1  425.0  211.0 -2.048961             Y   \n",
      "6737   87ASN, 136LEU             2    2.0    4.0 -0.762134           Y,P   \n",
      "6738           87SER             1  116.0  260.0 -0.545209             Y   \n",
      "\n",
      "     MUTATED_RES POSITION positions_split has_sec_str is_not_sec_str  \n",
      "0            T,T  116,128      [116, 128]        True          False  \n",
      "1            T,V  116,118      [116, 118]        True          False  \n",
      "2            T,E  116,122      [116, 122]        True          False  \n",
      "3            T,P  116,125      [116, 125]        True          False  \n",
      "4            T,R  116,137      [116, 137]        True          False  \n",
      "...          ...      ...             ...         ...            ...  \n",
      "6734         F,A   87,129       [87, 129]        True          False  \n",
      "6735           H       87            [87]        True          False  \n",
      "6736           N       87            [87]        True          False  \n",
      "6737         N,L   87,136       [87, 136]        True          False  \n",
      "6738           S       87            [87]        True          False  \n",
      "\n",
      "[6739 rows x 11 columns]>\n",
      "6739\n"
     ]
    }
   ],
   "source": [
    "bgl3_ss_df = get_ss_dataset(bgl3_in_domain_df, bgl3_ss_indexes, 0)\n",
    "print(len(bgl3_ss_df))\n",
    "# bgl3_ss_df_3000 = bgl3_ss_df.sample(n=2880)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "891c92e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['variant', 'num_mutations', 'inp', 'sel', 'score', 'WILD_TYPE_RES',\n",
      "       'MUTATED_RES', 'POSITION', 'positions_split', 'is_not_sec_str'],\n",
      "      dtype='object')\n",
      "False    6739\n",
      "Name: is_not_sec_str, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(bgl3_ss_df.columns)\n",
    "print(bgl3_ss_df['is_not_sec_str'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8b8d4ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7537\n"
     ]
    }
   ],
   "source": [
    "bgl3_not_ss_df = get_not_ss_dataset(bgl3_in_domain_df, bgl3_ss_indexes, 0)\n",
    "print(len(bgl3_not_ss_df))\n",
    "# bgl3_not_ss_df_3000 = bgl3_not_ss_df.sample(n=2880)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c899f8eb",
   "metadata": {},
   "source": [
    "1000 Value Test dataset in SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "daa49e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find random test set, concat orig df and new test df, remove dups\n",
    "# DO NOT RERUN THIS BLOCK\n",
    "bgl3_ss_1000_test_df = bgl3_ss_df.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0bc6da0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7739\n",
      "5739\n"
     ]
    }
   ],
   "source": [
    "bgl3_temp_df = pd.concat([bgl3_ss_1000_test_df, bgl3_ss_df])\n",
    "print(len(bgl3_temp_df))\n",
    "bgl3_ss_df = bgl3_temp_df[~bgl3_temp_df.index.duplicated(keep=False)]\n",
    "print(len(bgl3_ss_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5380f7b",
   "metadata": {},
   "source": [
    "1000 Value Test dataset not in SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "82bcde39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find random test set, concat orig df and new test df, remove dups\n",
    "# DO NOT RERUN THIS BLOCK\n",
    "bgl3_not_ss_1000_test_df = bgl3_not_ss_df.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e5ebb805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8537\n",
      "6537\n"
     ]
    }
   ],
   "source": [
    "bgl3_temp_df = pd.concat([bgl3_not_ss_1000_test_df, bgl3_not_ss_df])\n",
    "print(len(bgl3_temp_df))\n",
    "bgl3_not_ss_df = bgl3_temp_df[~bgl3_temp_df.index.duplicated(keep=False)]\n",
    "print(len(bgl3_not_ss_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd31216",
   "metadata": {},
   "source": [
    "Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "83d0b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgl3_ss_df_500_t1 = bgl3_ss_df.sample(n=500)\n",
    "bgl3_ss_df_500_t2 = bgl3_ss_df.sample(n=500)\n",
    "bgl3_ss_df_500_t3 = bgl3_ss_df.sample(n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7de29192",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgl3_ss_df_1000_t1 = bgl3_ss_df.sample(n=1000)\n",
    "bgl3_ss_df_1000_t2 = bgl3_ss_df.sample(n=1000)\n",
    "bgl3_ss_df_1000_t3 = bgl3_ss_df.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f5487f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgl3_ss_df_2000_t1 = bgl3_ss_df.sample(n=2000)\n",
    "bgl3_ss_df_2000_t2 = bgl3_ss_df.sample(n=2000)\n",
    "bgl3_ss_df_2000_t3 = bgl3_ss_df.sample(n=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "15967aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgl3_ss_df_3000_t1 = bgl3_ss_df.sample(n=3000)\n",
    "bgl3_ss_df_3000_t2 = bgl3_ss_df.sample(n=3000)\n",
    "bgl3_ss_df_3000_t3 = bgl3_ss_df.sample(n=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "21423c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgl3_not_ss_df_500_t1 = bgl3_not_ss_df.sample(n=500)\n",
    "bgl3_not_ss_df_500_t2 = bgl3_not_ss_df.sample(n=500)\n",
    "bgl3_not_ss_df_500_t3 = bgl3_not_ss_df.sample(n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d885be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgl3_not_ss_df_1000_t1 = bgl3_not_ss_df.sample(n=1000)\n",
    "bgl3_not_ss_df_1000_t2 = bgl3_not_ss_df.sample(n=1000)\n",
    "bgl3_not_ss_df_1000_t3 = bgl3_not_ss_df.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c89b99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgl3_not_ss_df_2000_t1 = bgl3_not_ss_df.sample(n=2000)\n",
    "bgl3_not_ss_df_2000_t2 = bgl3_not_ss_df.sample(n=2000)\n",
    "bgl3_not_ss_df_2000_t3 = bgl3_not_ss_df.sample(n=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "445b987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgl3_not_ss_df_3000_t1 = bgl3_not_ss_df.sample(n=3000)\n",
    "bgl3_not_ss_df_3000_t2 = bgl3_not_ss_df.sample(n=3000)\n",
    "bgl3_not_ss_df_3000_t3 = bgl3_not_ss_df.sample(n=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9cf36fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgl3_ss_500_df_t1 = pd.concat([bgl3_ss_df_500_t1, bgl3_ss_1000_test_df])\n",
    "bgl3_not_ss_500_df_t1 = pd.concat([bgl3_not_ss_df_500_t1, bgl3_not_ss_1000_test_df])\n",
    "bgl3_ss_500_df_t2 = pd.concat([bgl3_ss_df_500_t2, bgl3_ss_1000_test_df])\n",
    "bgl3_not_ss_500_df_t2 = pd.concat([bgl3_not_ss_df_500_t2, bgl3_not_ss_1000_test_df])\n",
    "bgl3_ss_500_df_t3 = pd.concat([bgl3_ss_df_500_t3, bgl3_ss_1000_test_df])\n",
    "bgl3_not_ss_500_df_t3 = pd.concat([bgl3_not_ss_df_500_t3, bgl3_not_ss_1000_test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e188118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgl3_ss_1000_df_t1 = pd.concat([bgl3_ss_df_1000_t1, bgl3_ss_1000_test_df])\n",
    "bgl3_not_ss_1000_df_t1 = pd.concat([bgl3_not_ss_df_1000_t1, bgl3_not_ss_1000_test_df])\n",
    "bgl3_ss_1000_df_t2 = pd.concat([bgl3_ss_df_1000_t2, bgl3_ss_1000_test_df])\n",
    "bgl3_not_ss_1000_df_t2 = pd.concat([bgl3_not_ss_df_1000_t2, bgl3_not_ss_1000_test_df])\n",
    "bgl3_ss_1000_df_t3 = pd.concat([bgl3_ss_df_1000_t3, bgl3_ss_1000_test_df])\n",
    "bgl3_not_ss_1000_df_t3 = pd.concat([bgl3_not_ss_df_1000_t3, bgl3_not_ss_1000_test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "001c9251",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgl3_ss_2000_df_t1 = pd.concat([bgl3_ss_df_2000_t1, bgl3_ss_1000_test_df])\n",
    "bgl3_not_ss_2000_df_t1 = pd.concat([bgl3_not_ss_df_2000_t1, bgl3_not_ss_1000_test_df])\n",
    "bgl3_ss_2000_df_t2 = pd.concat([bgl3_ss_df_2000_t2, bgl3_ss_1000_test_df])\n",
    "bgl3_not_ss_2000_df_t2 = pd.concat([bgl3_not_ss_df_2000_t2, bgl3_not_ss_1000_test_df])\n",
    "bgl3_ss_2000_df_t3 = pd.concat([bgl3_ss_df_2000_t3, bgl3_ss_1000_test_df])\n",
    "bgl3_not_ss_2000_df_t3 = pd.concat([bgl3_not_ss_df_2000_t3, bgl3_not_ss_1000_test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "164bf959",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgl3_ss_3000_df_t1 = pd.concat([bgl3_ss_df_3000_t1, bgl3_ss_1000_test_df])\n",
    "bgl3_not_ss_3000_df_t1 = pd.concat([bgl3_not_ss_df_3000_t1, bgl3_not_ss_1000_test_df])\n",
    "bgl3_ss_3000_df_t2 = pd.concat([bgl3_ss_df_3000_t2, bgl3_ss_1000_test_df])\n",
    "bgl3_not_ss_3000_df_t2 = pd.concat([bgl3_not_ss_df_3000_t2, bgl3_not_ss_1000_test_df])\n",
    "bgl3_ss_3000_df_t3 = pd.concat([bgl3_ss_df_3000_t3, bgl3_ss_1000_test_df])\n",
    "bgl3_not_ss_3000_df_t3 = pd.concat([bgl3_not_ss_df_3000_t3, bgl3_not_ss_1000_test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0c2be6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: bgl3_MLformat_ss_3000_train_1000_test_t3.txt\n",
      "Filename: bgl3_MLformat_not_ss_3000_train_1000_test_t3.txt\n"
     ]
    }
   ],
   "source": [
    "##### write data to formatted txt file\n",
    "\n",
    "write_data_file(\"bgl3_MLformat_ss_3000_train_1000_test_t3\", protein_seq_bgl3, bgl3_ss_3000_df_t3)\n",
    "write_data_file(\"bgl3_MLformat_not_ss_3000_train_1000_test_t3\", protein_seq_bgl3, bgl3_not_ss_3000_df_t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d27ff8",
   "metadata": {},
   "source": [
    "## Ube4B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a9a214a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../PDB and STRIDE Files/\" + 'ube4b_stride.txt'\n",
    "ube4b_stride_file = open(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "48cc9526",
   "metadata": {},
   "outputs": [],
   "source": [
    "ube4b_ss_indexes = get_sec_struc_boolean(ube4b_stride_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "95bcc598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "[False, False, False, False, False, False, False, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, False, False, False, False, True, True, False, False, False, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, True, True, False, False, False, False, True, True, False, False, False, False, False, False, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "print(len(ube4b_ss_indexes))\n",
    "print(ube4b_ss_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8974bc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "[7, 8, 9, 10, 11, 12, 13, 29, 30, 31, 32, 33, 38, 39, 43, 44, 45, 46, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 66, 67, 72, 73, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]\n",
      "[96, 97, 98]\n"
     ]
    }
   ],
   "source": [
    "# # index of 23rd true\n",
    "\n",
    "# highest_true_index = [i for i, n in enumerate(ube4b_ss_indexes) if n == True][49]\n",
    "# print(highest_true_index)\n",
    "# # need list of indices past this index\n",
    "\n",
    "# true_indices = [i for i,val in enumerate(ube4b_ss_indexes) if val==True]\n",
    "# print(true_indices)\n",
    "\n",
    "# not_included_ube4b = [i for i in true_indices if i > highest_true_index]\n",
    "# # [x for x in a if x <= 5]\n",
    "# print(not_included_ube4b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b752df",
   "metadata": {},
   "source": [
    "Getting Alpha and Beta Indices Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "42b04d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ube4b_alpha_indices = get_alpha_boolean(ube4b_stride_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "b5d9951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ube4b_beta_indices = get_beta_boolean(ube4b_stride_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5b5921d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not_included_alpha_ube4b = get_excluded_res(ube4b_alpha_indices)\n",
    "# not_included_beta_ube4b = get_excluded_res(ube4b_beta_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "62ad5583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num True Indices: 53\n",
      "Num False Indices: 49\n",
      "Difference: 4\n",
      "Num Indices to Remove: 4\n"
     ]
    }
   ],
   "source": [
    "# changing not included to matching secondary structure + random elements\n",
    "not_included_ube4b = get_excluded_res(ube4b_ss_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c071e5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "# number of mutations in secondary structure (True), and not in secondary structure (False)\n",
    "count_false = ube4b_ss_indexes.count(False)\n",
    "print(count_false)\n",
    "\n",
    "count_true = ube4b_ss_indexes.count(True)\n",
    "print(count_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6f5eada7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98297\n",
      "Index(['variant', 'num_mutations', 'score'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# importing Ube4b data from Gelman et al.\n",
    "ube4b_df1 = pd.read_csv(\"../Raw Data/ube4b.tsv.txt\", sep=\"\\t\")\n",
    "ube4b_df = ube4b_df1.dropna()\n",
    "print(len(ube4b_df))\n",
    "print(ube4b_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "08b1e5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98297\n",
      "91031\n"
     ]
    }
   ],
   "source": [
    "# rounding score column to 6 decimal points\n",
    "ube4b_df[\"score\"] = ube4b_df[\"score\"].round(6)\n",
    "print(len(ube4b_df))\n",
    "\n",
    "# remove values with wildcard star\n",
    "ube4b_df = ube4b_df[ube4b_df[\"variant\"].str.contains(\"\\*\") == False]\n",
    "print(len(ube4b_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "99e2ef8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n"
     ]
    }
   ],
   "source": [
    "# protein_seq_ube4b = get_protein_seq(\"Q9ES00\")\n",
    "# split_entire = protein_seq_ube4b.split()\n",
    "# # print(len(split_entire))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "97916a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "string_seq = \"IEKFKLLAEKVEEIVAKNARAEIDYSDAPDEFRDPLMDTLMTDPVRLPSGTVMDRSIILRHLLNSPTDPFNRQMLTESMLEPVPELKEQIQAWMREKQSSDH\"\n",
    "print(len(string_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "360f08e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILE GLU LYS PHE LYS LEU LEU ALA GLU LYS VAL GLU GLU ILE VAL ALA LYS ASN ALA ARG ALA GLU ILE ASP TYR SER ASP ALA PRO ASP GLU PHE ARG ASP PRO LEU MET ASP THR LEU MET THR ASP PRO VAL ARG LEU PRO SER GLY THR VAL MET ASP ARG SER ILE ILE LEU ARG HIS LEU LEU ASN SER PRO THR ASP PRO PHE ASN ARG GLN MET LEU THR GLU SER MET LEU GLU PRO VAL PRO GLU LEU LYS GLU GLN ILE GLN ALA TRP MET ARG GLU LYS GLN SER SER ASP HIS\n"
     ]
    }
   ],
   "source": [
    "protein_seq_ube4b = get_expanded_seq(string_seq)\n",
    "print(protein_seq_ube4b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9dd10e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split = protein_seq_ube4b_domain.split()\n",
    "# print(len(split)) \n",
    "# print(split[96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bfb86cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['variant', 'num_mutations', 'score', 'WILD_TYPE_RES', 'MUTATED_RES',\n",
      "       'POSITION'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ube4b_mut = ube4b_df[\"variant\"].str.split(\",\")\n",
    "\n",
    "ube4b_df[\"WILD_TYPE_RES\"] = get_wild_type(ube4b_mut)\n",
    "ube4b_df[\"MUTATED_RES\"] = get_mutation_type(ube4b_mut)\n",
    "ube4b_df[\"POSITION\"] = get_position(ube4b_mut)\n",
    "\n",
    "ube4b_df[\"variant\"] = get_mutations_names_list(ube4b_df)\n",
    "print(ube4b_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "14216eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ube4b_df[\"positions_split\"] = get_positions_split(ube4b_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e7e9c6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87554\n"
     ]
    }
   ],
   "source": [
    "# ube4b_in_domain_df = get_domain_dataset(ube4b_df, 0, 1200)\n",
    "ube4b_in_domain_df = get_domain_dataset(ube4b_df, 0, 2000, not_included_ube4b)\n",
    "print(len(ube4b_in_domain_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f0ceb6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ube4b_in_domain_alpha_df = get_domain_dataset(ube4b_df, 0, 2000, not_included_alpha_ube4b)\n",
    "# print(len(ube4b_in_domain_alpha_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "98412af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ube4b_in_domain_beta_df = get_domain_dataset(ube4b_df, 0, 2000, not_included_beta_ube4b)\n",
    "# print(len(ube4b_in_domain_beta_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d4d200c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13483\n"
     ]
    }
   ],
   "source": [
    "ube4b_ss_df = get_ss_dataset(ube4b_in_domain_df, ube4b_ss_indexes, 0)\n",
    "print(len(ube4b_ss_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c078d729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20301\n"
     ]
    }
   ],
   "source": [
    "ube4b_not_ss_df = get_not_ss_dataset(ube4b_in_domain_df, ube4b_ss_indexes, 0)\n",
    "print(len(ube4b_not_ss_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "0d6c956f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6947\n"
     ]
    }
   ],
   "source": [
    "# ube4b_alpha_df = get_ss_dataset(ube4b_in_domain_alpha_df, ube4b_alpha_indices, 0)\n",
    "# print(len(ube4b_alpha_df))\n",
    "# ube4b_alpha_df_2880 = ube4b_alpha_df.sample(n=2880)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "03b0b081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "939\n"
     ]
    }
   ],
   "source": [
    "# ube4b_beta_df = get_ss_dataset(ube4b_in_domain_beta_df, ube4b_beta_indices, 0)\n",
    "# print(len(ube4b_beta_df))\n",
    "# ube4b_beta_df_800 = ube4b_beta_df.sample(n=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1aa6d8",
   "metadata": {},
   "source": [
    "1000 Value Test dataset in SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "944c922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find random test set, concat orig df and new test df, remove dups\n",
    "# DO NOT RERUN THIS BLOCK\n",
    "ube4b_ss_1000_test_df = ube4b_ss_df.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1864c4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14483\n",
      "12483\n"
     ]
    }
   ],
   "source": [
    "ube4b_temp_df = pd.concat([ube4b_ss_1000_test_df, ube4b_ss_df])\n",
    "print(len(ube4b_temp_df))\n",
    "ube4b_ss_df = ube4b_temp_df[~ube4b_temp_df.index.duplicated(keep=False)]\n",
    "print(len(ube4b_ss_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba1fda",
   "metadata": {},
   "source": [
    "1000 Value Test dataset not in SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a3324dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find random test set, concat orig df and new test df, remove dups\n",
    "# DO NOT RERUN THIS BLOCK\n",
    "ube4b_not_ss_1000_test_df = ube4b_not_ss_df.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1b8b2bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21301\n",
      "19301\n"
     ]
    }
   ],
   "source": [
    "ube4b_temp_df = pd.concat([ube4b_not_ss_1000_test_df, ube4b_not_ss_df])\n",
    "print(len(ube4b_temp_df))\n",
    "ube4b_not_ss_df = ube4b_temp_df[~ube4b_temp_df.index.duplicated(keep=False)]\n",
    "print(len(ube4b_not_ss_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d19d3d9",
   "metadata": {},
   "source": [
    "Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1e4e05c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ube4b_ss_df_500_t1 = ube4b_ss_df.sample(n=500)\n",
    "ube4b_ss_df_500_t2 = ube4b_ss_df.sample(n=500)\n",
    "ube4b_ss_df_500_t3 = ube4b_ss_df.sample(n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "bc094546",
   "metadata": {},
   "outputs": [],
   "source": [
    "ube4b_ss_df_1000_t1 = ube4b_ss_df.sample(n=1000)\n",
    "ube4b_ss_df_1000_t2 = ube4b_ss_df.sample(n=1000)\n",
    "ube4b_ss_df_1000_t3 = ube4b_ss_df.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f1419131",
   "metadata": {},
   "outputs": [],
   "source": [
    "ube4b_ss_df_2000_t1 = ube4b_ss_df.sample(n=2000)\n",
    "ube4b_ss_df_2000_t2 = ube4b_ss_df.sample(n=2000)\n",
    "ube4b_ss_df_2000_t3 = ube4b_ss_df.sample(n=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "82363a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "ube4b_ss_df_3000_t1 = ube4b_ss_df.sample(n=3000)\n",
    "ube4b_ss_df_3000_t2 = ube4b_ss_df.sample(n=3000)\n",
    "ube4b_ss_df_3000_t3 = ube4b_ss_df.sample(n=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ba2bdb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ube4b_not_ss_df_500_t1 = ube4b_not_ss_df.sample(n=500)\n",
    "ube4b_not_ss_df_500_t2 = ube4b_not_ss_df.sample(n=500)\n",
    "ube4b_not_ss_df_500_t3 = ube4b_not_ss_df.sample(n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b73df06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ube4b_not_ss_df_1000_t1 = ube4b_not_ss_df.sample(n=1000)\n",
    "ube4b_not_ss_df_1000_t2 = ube4b_not_ss_df.sample(n=1000)\n",
    "ube4b_not_ss_df_1000_t3 = ube4b_not_ss_df.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "42fce5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ube4b_not_ss_df_2000_t1 = ube4b_not_ss_df.sample(n=2000)\n",
    "ube4b_not_ss_df_2000_t2 = ube4b_not_ss_df.sample(n=2000)\n",
    "ube4b_not_ss_df_2000_t3 = ube4b_not_ss_df.sample(n=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c7489269",
   "metadata": {},
   "outputs": [],
   "source": [
    "ube4b_not_ss_df_3000_t1 = ube4b_not_ss_df.sample(n=3000)\n",
    "ube4b_not_ss_df_3000_t2 = ube4b_not_ss_df.sample(n=3000)\n",
    "ube4b_not_ss_df_3000_t3 = ube4b_not_ss_df.sample(n=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "58e22f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ube4b_ss_500_df_t1 = pd.concat([ube4b_ss_df_500_t1, ube4b_ss_1000_test_df])\n",
    "ube4b_not_ss_500_df_t1 = pd.concat([ube4b_not_ss_df_500_t1, ube4b_not_ss_1000_test_df])\n",
    "ube4b_ss_500_df_t2 = pd.concat([ube4b_ss_df_500_t2, ube4b_ss_1000_test_df])\n",
    "ube4b_not_ss_500_df_t2 = pd.concat([ube4b_not_ss_df_500_t2, ube4b_not_ss_1000_test_df])\n",
    "ube4b_ss_500_df_t3 = pd.concat([ube4b_ss_df_500_t3, ube4b_ss_1000_test_df])\n",
    "ube4b_not_ss_500_df_t3 = pd.concat([ube4b_not_ss_df_500_t3, ube4b_not_ss_1000_test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "52845196",
   "metadata": {},
   "outputs": [],
   "source": [
    "ube4b_ss_1000_df_t1 = pd.concat([ube4b_ss_df_1000_t1, ube4b_ss_1000_test_df])\n",
    "ube4b_not_ss_1000_df_t1 = pd.concat([ube4b_not_ss_df_1000_t1, ube4b_not_ss_1000_test_df])\n",
    "ube4b_ss_1000_df_t2 = pd.concat([ube4b_ss_df_1000_t2, ube4b_ss_1000_test_df])\n",
    "ube4b_not_ss_1000_df_t2 = pd.concat([ube4b_not_ss_df_1000_t2, ube4b_not_ss_1000_test_df])\n",
    "ube4b_ss_1000_df_t3 = pd.concat([ube4b_ss_df_1000_t3, ube4b_ss_1000_test_df])\n",
    "ube4b_not_ss_1000_df_t3 = pd.concat([ube4b_not_ss_df_1000_t3, ube4b_not_ss_1000_test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "36c54ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ube4b_ss_2000_df_t1 = pd.concat([ube4b_ss_df_2000_t1, ube4b_ss_1000_test_df])\n",
    "ube4b_not_ss_2000_df_t1 = pd.concat([ube4b_not_ss_df_2000_t1, ube4b_not_ss_1000_test_df])\n",
    "ube4b_ss_2000_df_t2 = pd.concat([ube4b_ss_df_2000_t2, ube4b_ss_1000_test_df])\n",
    "ube4b_not_ss_2000_df_t2 = pd.concat([ube4b_not_ss_df_2000_t2, ube4b_not_ss_1000_test_df])\n",
    "ube4b_ss_2000_df_t3 = pd.concat([ube4b_ss_df_2000_t3, ube4b_ss_1000_test_df])\n",
    "ube4b_not_ss_2000_df_t3 = pd.concat([ube4b_not_ss_df_2000_t3, ube4b_not_ss_1000_test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "51c86c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ube4b_ss_3000_df_t1 = pd.concat([ube4b_ss_df_3000_t1, ube4b_ss_1000_test_df])\n",
    "ube4b_not_ss_3000_df_t1 = pd.concat([ube4b_not_ss_df_3000_t1, ube4b_not_ss_1000_test_df])\n",
    "ube4b_ss_3000_df_t2 = pd.concat([ube4b_ss_df_3000_t2, ube4b_ss_1000_test_df])\n",
    "ube4b_not_ss_3000_df_t2 = pd.concat([ube4b_not_ss_df_3000_t2, ube4b_not_ss_1000_test_df])\n",
    "ube4b_ss_3000_df_t3 = pd.concat([ube4b_ss_df_3000_t3, ube4b_ss_1000_test_df])\n",
    "ube4b_not_ss_3000_df_t3 = pd.concat([ube4b_not_ss_df_3000_t3, ube4b_not_ss_1000_test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "1181e22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: ube4b_MLformat_ss_3000_train_1000_test_t3.txt\n",
      "Filename: ube4b_MLformat_not_ss_3000_train_1000_test_t3.txt\n"
     ]
    }
   ],
   "source": [
    "# write data to formatted txt file\n",
    "\n",
    "write_data_file(\"ube4b_MLformat_ss_3000_train_1000_test_t3\", protein_seq_ube4b, ube4b_ss_3000_df_t3)\n",
    "write_data_file(\"ube4b_MLformat_not_ss_3000_train_1000_test_t3\", protein_seq_ube4b, ube4b_not_ss_3000_df_t3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
